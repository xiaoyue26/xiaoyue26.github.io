<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>hive笔记 | 笔记本</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="hive 小技巧GROUP BY xxx WITH CUBE的时候,要区分是维度是total_count还是null,可以用GROUPING__ID.当GROUPING__ID的二进制在某列为0,则为total_count,否则是具体值导致的null. (换句话说就是需要二进制操作,代码会很复杂,需要udf) hive 1.2.1 bug:12345678910111. alter table t">
<meta property="og:type" content="article">
<meta property="og:title" content="hive笔记">
<meta property="og:url" content="http://xiaoyue26.github.io/2017/01/22/hive%E7%AC%94%E8%AE%B0/index.html">
<meta property="og:site_name" content="笔记本">
<meta property="og:description" content="hive 小技巧GROUP BY xxx WITH CUBE的时候,要区分是维度是total_count还是null,可以用GROUPING__ID.当GROUPING__ID的二进制在某列为0,则为total_count,否则是具体值导致的null. (换句话说就是需要二进制操作,代码会很复杂,需要udf) hive 1.2.1 bug:12345678910111. alter table t">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://img.blog.csdn.net/20141115094556515?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZGNfNzI2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center">
<meta property="og:image" content="http://img.blog.csdn.net/20141115094806194?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZGNfNzI2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center">
<meta property="og:image" content="http://img.blog.csdn.net/20141115094934319?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZGNfNzI2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center">
<meta property="article:published_time" content="2017-01-22T11:34:41.000Z">
<meta property="article:modified_time" content="2020-04-18T15:38:11.294Z">
<meta property="article:author" content="风梦七">
<meta property="article:tag" content="hive">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://img.blog.csdn.net/20141115094556515?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZGNfNzI2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center">
  
    <link rel="alternate" href="/atom.xml" title="笔记本" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    
  
  
<link rel="stylesheet" href="/css/style.css">

  

<meta name="generator" content="Hexo 4.2.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    
    <div id="header-inner" class="inner">
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://xiaoyue26.github.io"></form>
      </div>
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">首页</a>
        
          <a class="main-nav-link" href="/archives">归档</a>
        
          <a class="main-nav-link" href="/about">关于</a>
        
      </nav>
      
    </div>
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">笔记本</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">风梦七</a>
        </h2>
      
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-hive笔记" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/01/22/hive%E7%AC%94%E8%AE%B0/" class="article-date">
  <time datetime="2017-01-22T11:34:41.000Z" itemprop="datePublished">2017-01-22</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/hadoop/">hadoop</a>►<a class="article-category-link" href="/categories/hadoop/hive/">hive</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      hive笔记
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
        
        <h1 id="hive-小技巧"><a href="#hive-小技巧" class="headerlink" title="hive 小技巧"></a>hive 小技巧</h1><p>GROUP BY xxx WITH CUBE的时候,要区分是维度是total_count还是null,<br>可以用GROUPING__ID.<br>当GROUPING__ID的二进制在某列为0,则为total_count,否则是具体值导致的null. (换句话说就是需要二进制操作,代码会很复杂,需要udf)</p>
<h1 id="hive-1-2-1-bug"><a href="#hive-1-2-1-bug" class="headerlink" title="hive 1.2.1 bug:"></a>hive 1.2.1 bug:</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">1. alter table temp.feng_test1  add COLUMNs (col2 string);</span><br><span class="line">增加一列后,无法读取新的一列的数据.</span><br><span class="line"></span><br><span class="line">现象: 使用alter语句增加一列,重新insert overwrite数据后,新增列的数据始终为null.</span><br><span class="line"></span><br><span class="line">解决方案: </span><br><span class="line">1. 对于外部表,可以通过重建整个表结构解决.</span><br><span class="line">首先保存建表语句,然后drop table,最后重建整个表即可.</span><br><span class="line"></span><br><span class="line">2. 对于有分区的内部表,可以通过重建分区解决,首先使用drop partition语句删除分区和数据,然后重跑这个分区的数据(或者事先备份好数据然后add partition). 注意,区别于直接使用insert overwrite partition语句.</span><br><span class="line">3. 对于无分区的内部表,暂无特别好的办法,只能先把表数据备份到另一个目录,(备份表结构和数据)然后drop table,最后重建表即可.注意,区别于直接使用insert overwrite table语句.</span><br></pre></td></tr></table></figure>

<h1 id="hive传参数"><a href="#hive传参数" class="headerlink" title="hive传参数:"></a>hive传参数:</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive -d DATE&#x3D;1 -e &#39;select $&#123;DATE&#125;&#39;</span><br></pre></td></tr></table></figure>

<h1 id="hive-更新函数"><a href="#hive-更新函数" class="headerlink" title="hive 更新函数:"></a>hive 更新函数:</h1><blockquote>
<p>注意事项: DROP function xxx时,得保证创建函数时用的jar还在,不然可能导致更新函数不成功,每次运行时还是会加载原有的jar包.</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">SELECT thriftparser(answerresults, &quot;com.fenbi.ape.hive.serde.thriftobject.conan.AnswerResults&quot;)</span><br><span class="line">FROM ape.ori_mysql_ape_conan_task_task_report_da</span><br><span class="line">limit 10</span><br><span class="line">;</span><br><span class="line"></span><br><span class="line">drop function thriftparser;</span><br><span class="line"></span><br><span class="line">create function thriftparser AS &#39;com.fenbi.ape.hive.serde.ThriftSerdeUniversalUDF&#39; USING JAR &#39;hdfs:&#x2F;&#x2F;f04&#x2F;lib&#x2F;ape-serde-1.1-SNAPSHOT.jar&#39;;</span><br><span class="line"></span><br><span class="line">reload function;</span><br><span class="line">reload functions;</span><br></pre></td></tr></table></figure>


<p>从8088获取hive查询的详细语句：<br><a href="http://f04:8088/proxy/application_1465276959835_417313/mapreduce/conf/job_1465276959835_417313" target="_blank" rel="noopener">http://f04:8088/proxy/application_1465276959835_417313/mapreduce/conf/job_1465276959835_417313</a><br>具体操作方法是先进入job的ApplicationMaster，具体jobid链接，左侧configuration，然后在右侧下方小字的key输入框，输入hive.query.string进行查询即可。</p>
<p>突然想到，对数据量小的表可以先做Distinct,数据量大的表可能得用group by。<br>前者用一个reduce即可，后者可以用多个reduce,跑得快一点。<br><a href="http://idea.lanyus.com/" target="_blank" rel="noopener">http://idea.lanyus.com/</a><br>需要看的教程:<br>[<a href="https://issues.apache.org/jira/browse/HIVE-591]" target="_blank" rel="noopener">https://issues.apache.org/jira/browse/HIVE-591]</a><br><a href="http://git-scm.com/book/zh/v2" target="_blank" rel="noopener">http://git-scm.com/book/zh/v2</a><br><a href="http://pcottle.github.io/learnGitBranching/?demo" target="_blank" rel="noopener">http://pcottle.github.io/learnGitBranching/?demo</a><br><code>smartGit</code><br><code>derby</code>数据库是什么? 就是一个轻量级的数据库 好多apache项目都默认自带。</p>
<p>查看所有函数/查看指定函数用法。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SHOW FUNCTIONS; </span><br><span class="line">desc function find_in_set;</span><br></pre></td></tr></table></figure>

<ul>
<li><code>sql code style flow</code>:<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span></span><br><span class="line"><span class="keyword">FROM</span></span><br><span class="line"><span class="keyword">WHERE</span></span><br><span class="line"><span class="keyword">GROUP</span></span><br><span class="line"><span class="keyword">HAVING</span></span><br></pre></td></tr></table></figure>

</li>
</ul>
<p><code>hbase</code>是直接查询(KV)；<br><code>hive</code>会转化为<code>map-reduce</code>任务。<br><code>pig</code>是定制<code>reduce</code>部分。</p>
<p><code>hive</code>使用列式存储，使用<code>dt=?</code>指定<code>partition</code>会加快查询速度，像索引一样。<a href="http://blog.csdn.net/dc_726/article/details/41143175" target="_blank" rel="noopener">列式存储基础知识</a><br><img src="http://img.blog.csdn.net/20141115094556515?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZGNfNzI2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="列式存储天生适合压缩"></p>
<ul>
<li>列式存储天生适合压缩(相同数据类型)</li>
<li>列式存储数据库对分布式支持友好</li>
</ul>
<p><img src="http://img.blog.csdn.net/20141115094806194?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZGNfNzI2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="投影等操作的对比"></p>
<ul>
<li>自然连接是一种去重复列后的等值连接，它要求两个关系中进行比较的分量必须是相同的属性组，并且在结果中把重复的属性列去掉。而等值连接并不去掉重复的属性列。</li>
<li>选择-&gt;限制-&gt;<code>where</code>—&gt;指定行;投影-&gt;<code>select</code>-&gt;指定列。</li>
</ul>
<p>列式存储查询流程:<br><img src="http://img.blog.csdn.net/20141115094934319?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZGNfNzI2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="列式存储查询流程"></p>
<ol>
<li>根据<code>where</code>的行限制,去字典表里找到字符串对应数字(只进行一次字符串比较)。</li>
<li>用数字去列表里匹配，匹配上的位置设为1。</li>
<li>把不同列的匹配结果进行位运算得到符合所有条件的记录下标。</li>
<li>使用这个下标，再根据<code>select</code>语句中指定的列,组装出最终的结果集。</li>
</ol>
<hr>
<p><code>$HOME/.hiverc</code>目录下可设定启动脚本。<br>如<code>set hive.metastore.warehouse.dir/=...</code></p>
<p>查看<code>hive</code>版本：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">hive&gt;</span><span class="bash"><span class="built_in">set</span> hive.hwi.war.file;</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">echo</span> <span class="variable">$HIVE_HOME</span></span></span><br><span class="line">/home/maintain/hive/apache-hive-0.14.0-bin</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">终止:</span></span><br><span class="line">ctrl+c (不是win+c)</span><br><span class="line">两次。</span><br><span class="line">若未执行完毕则终止的是jvm;</span><br><span class="line">若执行完毕则返回结果在文件系统里，切断的是与文件系统的联系。</span><br></pre></td></tr></table></figure>

<p>设定变量:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">set foo=bar2;</span><br><span class="line">set hivevar:foo=bar2; #等效</span><br><span class="line">set foo;# 查看结果</span><br></pre></td></tr></table></figure>

<p><code>hive</code>中可使用<code>shell</code>命令等:（也是分号结尾）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">! /bin/echo "hello world";</span><br><span class="line">! pwd</span><br><span class="line">dfs -ls / ;</span><br><span class="line">-- copyright ... #注释以`--`开头</span><br></pre></td></tr></table></figure>

<p>注释以<code>--</code>开头 比较特殊。</p>
<p>各种分隔符<code>p46</code>。</p>
<p>一个概念：<code>读时模式</code>：<br>传统数据库是<code>写时模式</code>，在写入的时候进行模式检查、有效性验证。<br><code>hive</code>是<code>读时模式</code>，就是加载数据的时候才进行验证，尽可能恢复数据的有效性和合法性。对于错误的类型返回<code>null</code>,如数值类型中存放了字符串。</p>
<p><code>hive</code>不支持行级操作、不支持事务。</p>
<p>可以重复使用<code>Use</code>指令，<code>hive</code>没有嵌套数据库。</p>
<p>递归删除数据库<br><code>drop database if exists xxxbase cascade;</code></p>
<p>支持正则:(<code>show databases</code>里用不了)<br><code>show tables &#39;empl.*&#39;;</code><br>mysql 里是:<code>show tables like &#39;%empl%&#39; ;</code></p>
<p>输出表信息:<br><code>describe formatted mydb.employees;</code></p>
<p><code>set hive.stats.reliable=false</code>是什么含义，设定为暂时不可用?<br>这个是把状态收集器关掉，效果是在insert overwrite的时候，不去重。</p>
<p> 查看是管理表还是外部表:<br> <code>describe formatted mydb.employees;</code><br>输出信息的中部有这一项(<code>table_type</code>).</p>
<p>创建相同表结构但没有数据的表:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">not</span> <span class="keyword">exists</span> mydb.employees3</span><br><span class="line"><span class="keyword">Like</span> mydb.employees</span><br><span class="line">Location <span class="string">'/path/to/data'</span>;</span><br></pre></td></tr></table></figure>

<p>创建带分区的表:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> employees(</span><br><span class="line"><span class="keyword">name</span> <span class="keyword">STRING</span>,</span><br><span class="line">salary <span class="built_in">Float</span>,</span><br><span class="line">subordinates <span class="built_in">Array</span>&lt;<span class="keyword">String</span>&gt;,</span><br><span class="line">deductions <span class="keyword">map</span>&lt;<span class="keyword">string</span>,<span class="built_in">float</span>&gt;,</span><br><span class="line">address <span class="keyword">struct</span>&lt;street:<span class="keyword">string</span>,</span><br><span class="line">               city:<span class="keyword">string</span>,</span><br><span class="line">               state:<span class="keyword">string</span>,</span><br><span class="line">               zip:<span class="built_in">int</span>&gt;</span><br><span class="line">)</span><br><span class="line">partitioned <span class="keyword">by</span> (country <span class="keyword">string</span>,state <span class="keyword">string</span>);</span><br></pre></td></tr></table></figure>
<p><code>hive</code>会按照分区创建目录。然后不在字段中存储分区信息。</p>
<p>查看已有的分区设置:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">show</span> <span class="keyword">partitions</span> tmp_tutor_user_profile;</span><br></pre></td></tr></table></figure>

<p>设置查询时是否必须指定分区:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.mapred.mode=<span class="keyword">strict</span>;</span><br><span class="line"><span class="keyword">set</span> hive.mapred.mode=nonstrict;</span><br></pre></td></tr></table></figure>

<p>载入数据的方式创建分区:<code>p60</code></p>
<p><code>hive</code>不储存建表语句?（<code>Navicat for MySQL</code>中的对象信息）。<br><code>show create table test1</code> 里有.</p>
<p>增加分区信息：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> log_messages </span><br><span class="line"><span class="keyword">add</span> <span class="keyword">partition</span></span><br><span class="line">(<span class="keyword">year</span>=<span class="number">2015</span>,<span class="keyword">month</span>=<span class="number">1</span>,<span class="keyword">day</span>=<span class="number">2</span>)</span><br><span class="line">location <span class="string">'hdfs://master_server/data/log/2012/01/02'</span>;</span><br></pre></td></tr></table></figure>

<p><code>emailUtils</code></p>
<ul>
<li>大部分<code>alter</code>操作不会改变数据，只改变元数据。<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> log_messages</span><br><span class="line"><span class="keyword">partition</span>(<span class="keyword">year</span>=<span class="number">2012</span>,<span class="keyword">month</span>=<span class="number">12</span>,<span class="keyword">day</span>=<span class="number">2</span>)</span><br><span class="line"><span class="keyword">set</span> location <span class="string">'s3n://ourbucket/logs/2011/01/02'</span>;</span><br></pre></td></tr></table></figure>
上述命令不会把数据从旧的路径转移或者删除。</li>
</ul>
<hr>
<ul>
<li><p>例外：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> log_messages </span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">if</span> <span class="keyword">exists</span> <span class="keyword">partition</span></span><br><span class="line">(<span class="keyword">year</span>=<span class="number">2012</span>,<span class="keyword">month</span>=<span class="number">12</span>,<span class="keyword">day</span>=<span class="number">2</span>);</span><br></pre></td></tr></table></figure>
<p>上述语句会删除管理表中的数据，而不会删除外部表中的数据。</p>
</li>
<li><p>对字段进行重命名、修改位置、类型和注释：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> log_messages</span><br><span class="line"><span class="keyword">change</span> <span class="keyword">column</span> hms hours_minutes_secends <span class="built_in">INT</span></span><br><span class="line"><span class="keyword">comment</span> <span class="string">'the hours,minutes and seconds part of the timestamp'</span></span><br><span class="line"><span class="keyword">after</span> severity;</span><br></pre></td></tr></table></figure>
</li>
<li><p>装载数据:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">load</span> <span class="keyword">data</span> <span class="keyword">local</span> inpath <span class="string">'$&#123;env:HOME&#125;/california-employees'</span></span><br><span class="line">overwrite <span class="keyword">into</span> <span class="keyword">table</span> employees</span><br><span class="line"><span class="keyword">partition</span> (country=<span class="string">'US'</span>,state=<span class="string">'CA'</span>);</span><br></pre></td></tr></table></figure>
<p>如果分区目录不存在，命令会先创建分区目录然后再将目录装载(拷贝)到该目录下。<code>hive</code>会检查文件格式是否与表结构相符，但不会检查数据是否和表模式匹配。(读时模式)</p>
</li>
</ul>
<p>从<code>hdfs</code>中装载数据时,不使用<code>local</code>关键字。</p>
<p><code>p133</code>中? 存疑. <code>into</code>? <code>table</code>?<br>应该是into.</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">load</span> <span class="keyword">data</span> <span class="keyword">local</span> inpath <span class="string">'log2.txt'</span> <span class="keyword">into</span> weblogs </span><br><span class="line"><span class="keyword">partition</span>(<span class="number">20110102</span>);</span><br></pre></td></tr></table></figure>

<ul>
<li><p>动态分区</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> employees</span><br><span class="line"><span class="keyword">partition</span> (country,state)</span><br><span class="line"><span class="keyword">select</span> ..., se.cnty, se.st</span><br><span class="line"><span class="keyword">from</span> staged_employees se;</span><br></pre></td></tr></table></figure>
<p>混合动态和静态分区:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> employees</span><br><span class="line"><span class="keyword">partition</span> (country=<span class="string">'US'</span>,state)</span><br><span class="line"><span class="keyword">select</span> ..., se.cnty, se.st</span><br><span class="line"><span class="keyword">from</span> staged_employees se</span><br><span class="line"><span class="keyword">where</span> se.cnty=<span class="string">'US'</span></span><br><span class="line">;</span><br></pre></td></tr></table></figure>
<p>静态分区必须在动态分区前。</p>
</li>
<li><p>属性设定:</p>
<table>
   <tr>
    <td>属性名称</td>
    <td>缺省值</td>
    <td>描述</td>
 </tr>
 <tr>
    <td>hive.exec.dynamic</td>
    <td>false</td>
    <td>设置true即开启动态分区功能</td>
 </tr>
 <tr>
    <td>hive.exec.dynamic.mode</td>
    <td>strict</td>
    <td>nonstrict表示运行所有分区都是动态的</td>
 </tr>
 <tr>
    <td>hive.exec.max.dynamic.partitions.pernode</td>
    <td>100</td>
    <td>每个mapper或reducer可以创建的最大动态分区个数</td>
 </tr>
 <tr>
    <td>hive.exec.max.dynamic.partitions</td>
    <td>+1000</td>
    <td>一个语句可以创建的最大动态分区个数</td>
 </tr>
 <tr>
    <td>hive.exec.max.created.files</td>
    <td>100000</td>
    <td>全局可以创建的最大文件个数</td>
 </tr>
</table>
</li>
<li><p>导出数据</p>
</li>
</ul>
<ol>
<li>格式相同:<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -cp source_path target_path</span><br></pre></td></tr></table></figure></li>
<li>格式不同:<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">local</span> <span class="keyword">directory</span> <span class="string">'tmp/ca_employees'</span></span><br><span class="line"><span class="keyword">select</span> <span class="keyword">name</span>, salary, address</span><br><span class="line"><span class="keyword">from</span> employees</span><br><span class="line"><span class="keyword">where</span> se.state=<span class="string">'CA'</span></span><br><span class="line">;</span><br></pre></td></tr></table></figure></li>
<li>多输出目录:<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">from staged_employees se</span><br><span class="line">    <span class="keyword">insert</span> overwrite <span class="keyword">directory</span> <span class="string">'/tmp/or_employees'</span></span><br><span class="line">     <span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">where</span> se.cty=<span class="string">'US'</span> <span class="keyword">and</span> se.st=<span class="string">'OR'</span></span><br><span class="line">    <span class="keyword">insert</span> overwrite <span class="keyword">directory</span> <span class="string">'/tmp/ca_employees'</span></span><br><span class="line">     <span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">where</span> se.cty=<span class="string">'US'</span> <span class="keyword">and</span> se.st=<span class="string">'CA'</span></span><br><span class="line">    <span class="keyword">insert</span> overwrite <span class="keyword">directory</span> <span class="string">'/tmp/il_employees'</span></span><br><span class="line">     <span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">where</span> se.cty=<span class="string">'US'</span> <span class="keyword">and</span> se.st=<span class="string">'IL'</span></span><br><span class="line">;</span><br></pre></td></tr></table></figure>


</li>
</ol>
<ul>
<li>查看结果文件内容:<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">! ls /tmp/ca_employees;</span><br><span class="line">! cat /tmp/ca_employees/000000_0 ;</span><br></pre></td></tr></table></figure>

</li>
</ul>
<p>取整:<code>round (salary)</code><br>数学函数<code>p82</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">byte</span> <span class="keyword">int</span> <span class="keyword">short</span> <span class="keyword">long</span> <span class="number">1</span>,<span class="number">2</span>,<span class="number">4</span>,<span class="number">8</span></span><br><span class="line"><span class="keyword">boolean</span> <span class="keyword">char</span> <span class="keyword">float</span> <span class="keyword">double</span> <span class="number">1</span>,<span class="number">2</span>,<span class="number">4</span>,<span class="number">8</span></span><br></pre></td></tr></table></figure>

<ul>
<li>部分内置函数<table>
   <tr>
    <td>返回值类型</td>
    <td>样式</td>
    <td>描述</td>
 </tr>
 <tr>
    <td>type</td>
    <td>cast(expr as type)</td>
    <td>把expr转换为type类型</td>
 </tr>
  <tr>
    <td>string</td>
    <td>concat(binary s1,binary s2,...)</td>
    <td>拼接字符串</td>
 </tr>
 <tr>
    <td>string</td>
    <td>concat_ws(string separator, string s1,string s2,...)</td>
    <td>使用指定分隔符拼接字符串</td>
 </tr>
</table>

</li>
</ul>
<p><code>set hive.exec.mode.local.auto;</code>这个值为什么是<code>false</code>?</p>
<p>由于浮点数的不准确性，与钱有关或者涉及到比较的关键数字都不使用浮点数，使用<code>string</code>.</p>
<ul>
<li>正则<ul>
<li><code>like</code>使用<code>sql</code>通配符(<code>%abc%</code> )</li>
<li><code>Rlike</code>使用<code>java</code>正则表达式(<code>.*(abc).*</code>)</li>
</ul>
</li>
</ul>
<hr>
<ul>
<li><p>聚合函数、表连接:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="keyword">year</span>(ymd), <span class="keyword">avg</span>(price_close) <span class="keyword">from</span> stocks</span><br><span class="line"><span class="keyword">where</span> <span class="keyword">exchange</span>=<span class="string">'NASDAQ'</span> <span class="keyword">AND</span> symbol=<span class="string">'AAPL'</span></span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> <span class="keyword">year</span>(ymd)</span><br><span class="line"><span class="keyword">having</span> <span class="keyword">avg</span>(price_close)&gt;<span class="number">50.0</span></span><br><span class="line">;</span><br><span class="line"><span class="comment"># 注释:'--'</span></span><br><span class="line"><span class="comment">-- inner join: 表应从小到大排列以便hive优化;</span></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> a.ymd, b.price_close</span><br><span class="line"><span class="keyword">from</span> stocks a <span class="keyword">join</span> stocks b <span class="keyword">on</span> a.ymd=b.ymd</span><br><span class="line"><span class="keyword">where</span> a.symbol=<span class="string">'APPL'</span> </span><br><span class="line"><span class="keyword">AND</span> b.symbol=<span class="string">'IBM'</span></span><br><span class="line">;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- left outer join 左外连接</span></span><br><span class="line"><span class="comment"># 左表中符合where子句的所有记录将返回</span></span><br><span class="line"><span class="comment"># 右表中不符合on连接的列将返回NULL</span></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> a.ymd, b.price_close</span><br><span class="line"><span class="keyword">from</span> stocks a <span class="keyword">left</span> <span class="keyword">outer</span> <span class="keyword">join</span> dividend b <span class="keyword">on</span> a.ymd=b.ymd</span><br><span class="line"><span class="keyword">where</span> a.symbol=<span class="string">'APPL'</span> </span><br><span class="line">;</span><br><span class="line"><span class="comment">-- 执行顺序, 先执行join,再使用where进行过滤。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 嵌套select:</span></span><br><span class="line"><span class="keyword">select</span> s.*, d.* <span class="keyword">from</span></span><br><span class="line">(<span class="keyword">select</span> * <span class="keyword">from</span> stocks <span class="keyword">where</span> ...) s</span><br><span class="line"><span class="keyword">left</span> <span class="keyword">outer</span> <span class="keyword">join</span></span><br><span class="line">(<span class="keyword">select</span> * <span class="keyword">from</span> dividend where...) d</span><br><span class="line"><span class="keyword">on</span> s.ymd=d.ymd</span><br><span class="line">;</span><br><span class="line"></span><br><span class="line"><span class="comment">--类似的, 右外连接 right outer join</span></span><br><span class="line"><span class="comment">-- 全连接 full outer join</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 左半开连接: left semi-join</span></span><br><span class="line"><span class="keyword">select</span> s.* <span class="keyword">from</span> stocks s</span><br><span class="line"><span class="keyword">left</span> <span class="keyword">semi</span> <span class="keyword">join</span></span><br><span class="line">dividends d </span><br><span class="line"><span class="keyword">on</span> s.ymd=d.ymd <span class="keyword">and</span> s.symbol=d.symbol</span><br><span class="line">;</span><br><span class="line"><span class="comment">#返回左边表的记录，用on中的条件进行过滤。</span></span><br><span class="line"><span class="comment">#比inner join(直接join)更高效，但不能返回右表中的数据。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 笛卡尔积: 没有on语句的join</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><code>map-side join</code><br>通过设置<code>set hive.auto.convert.join=true;</code>开启。</p>
</li>
<li><p><code>distribute by</code><br><code>distribute by</code>控制<code>mapper</code>的输出在<code>reducer</code>中是如何划分的。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> stocks s</span><br><span class="line"><span class="keyword">distribute</span> <span class="keyword">by</span> s.symbol</span><br><span class="line"><span class="keyword">sort</span> <span class="keyword">by</span> s.symbol <span class="keyword">asc</span>, s.ymd <span class="keyword">asc</span></span><br><span class="line">;</span><br></pre></td></tr></table></figure>
<p>此处<code>distribute by</code>指定具有相同股票交易码的记录会分发到同一个<code>reducer</code>中进行处理。<code>cluster by s.symbol</code>相当于<code>distribute by s.symbol sort by s.symbol desc</code>的简写,只支持降序。</p>
</li>
</ul>
<p><code>order by</code>保证全局有序;<br><code>sort by</code>只保证每个<code>reducer</code>的任务局部有序。</p>
<ul>
<li><p>抽样查询</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> numbers </span><br><span class="line"><span class="keyword">tableSample</span>(<span class="keyword">bucket</span> <span class="number">3</span> <span class="keyword">out</span> <span class="number">10</span> <span class="keyword">on</span> <span class="keyword">rand</span>())</span><br><span class="line">s;</span><br><span class="line"><span class="comment">-- 指定列分桶:</span></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> numbers </span><br><span class="line"><span class="keyword">tableSample</span>(<span class="keyword">bucket</span> <span class="number">3</span> <span class="keyword">out</span> <span class="number">10</span> <span class="keyword">on</span> <span class="built_in">number</span>)</span><br><span class="line">s;</span><br></pre></td></tr></table></figure>
</li>
<li><p>数据块抽样(百分比)</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> numbersflat <span class="keyword">TableSample</span>(<span class="number">0.1</span> <span class="keyword">percent</span>)</span><br><span class="line">s;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 最小抽样单元是一个hdfs数据，所以数据大小小于128MB时会返回所有数据</span></span><br><span class="line"><span class="comment">-- 不一定适用于所有文件格式</span></span><br></pre></td></tr></table></figure>

</li>
</ul>
<p>哈斯分区是什么? <code>p115</code><br>分隔符的可读性为何这么低还是不清楚。（?）</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 两种顺序调换的意义?</span></span><br><span class="line">from...insert...select...</span><br><span class="line">from...select...</span><br></pre></td></tr></table></figure>


<p>示例文件夹:<br><code>/Users/xiaoyue26/Documents/pipe_warehouse/solar/dwSolarUserStat</code></p>
<ul>
<li>索引<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">Index</span> employees_index</span><br><span class="line"><span class="keyword">on</span> <span class="keyword">Table</span> employees (country)</span><br><span class="line"><span class="keyword">as</span> <span class="string">'org.apache.hadoop.hive.ql.index.compact.CompactIndexHandler'</span></span><br><span class="line"><span class="keyword">with</span> <span class="keyword">Deferred</span> <span class="keyword">Rebuild</span> <span class="comment">#意思不要立刻开始创建索引的数据,只是先声明一个索引</span></span><br><span class="line"><span class="comment">-- 新索引呈空白状态</span></span><br><span class="line">IDXproperties (<span class="string">'creator'</span>=<span class="string">'me'</span>, <span class="string">'created_at'</span>=<span class="string">'some_time'</span>)</span><br><span class="line"><span class="keyword">in</span> <span class="keyword">table</span> employees_index_table <span class="comment">#可选 也可以把索引建成一个文件</span></span><br><span class="line">partitioned <span class="keyword">by</span> (country, <span class="keyword">name</span>)</span><br><span class="line"><span class="keyword">comment</span> <span class="string">'Employees indexed by country and name.'</span></span><br><span class="line">;</span><br></pre></td></tr></table></figure></li>
</ul>
<ol>
<li>排重后值较少的列可使用<code>Bitmap</code>索引(<code>As &#39;BITMAP&#39;</code>)；</li>
<li>重建索引:<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">index</span> employees_index</span><br><span class="line"><span class="keyword">on</span> <span class="keyword">table</span> employees</span><br><span class="line"><span class="keyword">partition</span> (country=<span class="string">'US'</span>)<span class="comment">#指定重建某分区的索引,如果省略会重建所有分区的索引。</span></span><br><span class="line"><span class="keyword">rebuild</span></span><br><span class="line">;</span><br></pre></td></tr></table></figure></li>
<li>显示索引:<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">show</span> formatted <span class="keyword">index</span> <span class="keyword">on</span> employees</span><br><span class="line">;</span><br></pre></td></tr></table></figure></li>
<li>删除索引<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">drop</span> <span class="keyword">index</span> <span class="keyword">if</span> <span class="keyword">exists</span> employees_index</span><br><span class="line"><span class="keyword">on</span> <span class="keyword">table</span> employees</span><br><span class="line">;</span><br></pre></td></tr></table></figure>
如果原表被删除了，对其建立的对应的索引和索引表也会被删除。<br>如果原始表的某个分区被删除了，这个分区对应的分区索引也会被删除。</li>
</ol>
<p>?:书上日期用的是数字’20110102’（<code>int</code>）,为何咱们用的是字符串’2015-11-02’?</p>
<blockquote>
<p><code>NameNode</code>将所有系统元数据信息保存在内存中。一个<code>hdfs</code>实例所能管理的文件总数是有上限的，而<code>MapR</code>和<code>Amazon S3</code>则没有这个限制。</p>
</blockquote>
<p><code>hive</code>数据库和关系型数据库区别:</p>
<table>
<tr>
 <td>关系型</td>
 <td>hive</td>
</tr>
<tr>
 <td>唯一键\主键\自增键</td>
 <td>无</td>
</tr>
<tr>
 <td>三范式(ACID)</td>
 <td>单行中存储一对多关系，一致性较差，但I/O性能高(连续存储)</td>
</tr>
<tr>
 <td>普通数据结构</td>
 <td>集合结构(array,map,struct)</td>
</tr>
</table>
`ACID`:原子性、一致性、隔离性、持久性。


<ul>
<li>一次扫描多次输出<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from history</span><br><span class="line"><span class="keyword">insert</span> overwrite sales </span><br><span class="line">    <span class="keyword">select</span> * <span class="keyword">where</span> <span class="keyword">action</span>=<span class="string">'purchased'</span></span><br><span class="line"><span class="keyword">insert</span> overwrite credits</span><br><span class="line">    <span class="keyword">select</span> * <span class="keyword">where</span> <span class="keyword">action</span>=<span class="string">'returned'</span></span><br><span class="line">;</span><br></pre></td></tr></table></figure>

</li>
</ul>
<blockquote>
<p>ETL，Extraction-Transformation-Loading的缩写，<br>中文名称为数据提取、转换和加载。 </p>
</blockquote>
<blockquote>
<p>ETL工具有：<br>OWB(Oracle Warehouse Builder)、ODI(Oracle Data Integrator)、Informatic PowerCenter、Trinity、AICloudETL、DataStage、Repository Explorer、Beeload、Kettle、DataSpider</p>
</blockquote>
<blockquote>
<p>ETL负责将分散的、异构数据源中的数据如关系数据、平面数据文件等抽取到临时中间层后进行清洗、转换、集成，最后加载到数据仓库或数据集市中，成为联机分析处理、数据挖掘的基础。</p>
</blockquote>
<ul>
<li>引用<code>hiveconf</code>变量:<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ hive -hiveconf dt=2011-01-01</span><br><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> distinct_ip_in_logs</span><br><span class="line"><span class="keyword">partition</span> (hit_data=$&#123;dt&#125;)</span><br><span class="line"><span class="keyword">select</span> <span class="keyword">distinct</span>(ip) <span class="keyword">as</span> ip <span class="keyword">from</span> weblogs</span><br><span class="line"><span class="keyword">where</span> hit_date=<span class="string">'$&#123;hiveconf:dt&#125;'</span></span><br><span class="line">;</span><br></pre></td></tr></table></figure>

</li>
</ul>
<p>如何获得表中已有数据的规模信息(不用<code>count</code>)?<br>先用<code>show create table test1</code>查询到表在hdfs上的location,<br>然后用<code>dfs -du -h hdfs://location1</code>查询到文件大小。</p>
<ul>
<li>分桶数据存储</li>
</ul>
<ol>
<li>建表:<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> weblog (user_id <span class="built_in">INT</span>,<span class="keyword">url</span> <span class="keyword">String</span>, source_ip <span class="keyword">String</span>)</span><br><span class="line">Partitioned <span class="keyword">by</span> (dt <span class="keyword">string</span>)</span><br><span class="line">clustered <span class="keyword">by</span> (user_id) <span class="keyword">into</span> <span class="number">96</span> buckets</span><br><span class="line">;</span><br></pre></td></tr></table></figure>
使用<code>user_id</code>字段作为分桶字段，表数据按字段值哈希值分发到桶中。同一个<code>user_id</code>下的记录通常会存储到同一个桶内。假设用户数比桶数要多，那么桶内就将会包含多个用户的记录。</li>
</ol>
<p><em>结合<code>p109</code>的<code>map-side join</code>学习。</em></p>
<p>2.分桶后插入数据:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.enforce.bucketing=<span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line">From raw_logs</span><br><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> weblog</span><br><span class="line"><span class="keyword">partition</span> (dt=<span class="string">'2009-02-25'</span>)</span><br><span class="line"><span class="keyword">select</span> user_id,<span class="keyword">url</span>,source_ip </span><br><span class="line"><span class="keyword">where</span> dt=<span class="string">'2009-02-25'</span></span><br><span class="line">;</span><br></pre></td></tr></table></figure>

<p>3.分桶表连接优化开启:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.optimize.bucketmapJOIN=<span class="literal">true</span>;</span><br><span class="line"><span class="comment">#待连接的两个表分桶数量呈倍数关系时可优化。</span></span><br><span class="line"><span class="comment"># 且on语句中连接键与分桶键相同。</span></span><br><span class="line"><span class="comment">#sort-merge JOIN:</span></span><br><span class="line"><span class="comment">#分桶数完全相同时:</span></span><br><span class="line"><span class="keyword">set</span> hive.input.format=org.apache.hadoop.hive.ql.io.BucketizedHiveInputFormat;</span><br><span class="line"><span class="keyword">set</span> hive.optimize.bucketmapjoin=<span class="literal">true</span>;</span><br><span class="line"><span class="keyword">set</span> hive.optimize.bucketmapjoin.sortedmerge=<span class="literal">true</span>;</span><br></pre></td></tr></table></figure>

<hr>
<p><a href="http://www.coder4.com/archives/4031" target="_blank" rel="noopener">SerDe</a> 全称是 <code>Serializer and Deserializer</code><br>HDFS files –&gt; InputFileFormat –&gt; ‘&lt;’key, value&gt; –&gt; Deserializer –&gt; Row object<br>Row object –&gt; Serializer –&gt; ‘&lt;’key, value&gt; –&gt; OutputFileFormat –&gt; HDFS files</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">st&#x3D;&gt;start: HDFS files</span><br><span class="line">e&#x3D;&gt;end: 结束 </span><br><span class="line">op1&#x3D;&gt;operation: InputFileFormat</span><br><span class="line">op2&#x3D;&gt;operation: &#39;&lt;&#39;key,value&gt;</span><br><span class="line">op3&#x3D;&gt;operation: Deserializer </span><br><span class="line">op4&#x3D;&gt;operation: Row object</span><br><span class="line">st-&gt;op1-&gt;op2-&gt;op3-&gt;op4-&gt;e</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">explain</span> <span class="keyword">select</span> * <span class="keyword">from</span> tmp_table1 <span class="keyword">limit</span> <span class="number">100</span>;</span><br><span class="line">OK <span class="comment">#执行返回码</span></span><br><span class="line">STAGE DEPENDENCIES:</span><br><span class="line">  Stage-0 is a root stage</span><br><span class="line"></span><br><span class="line">STAGE PLANS:</span><br><span class="line">  Stage: Stage-0</span><br><span class="line">    Fetch Operator</span><br><span class="line">      limit: 100</span><br><span class="line">      Processor Tree:</span><br><span class="line">        TableScan</span><br><span class="line">          alias: tmp_table1</span><br><span class="line">          Statistics: Num rows: 0 Data size: 72 Basic stats: PARTIAL Column stats: NONE</span><br><span class="line">          <span class="keyword">Select</span> <span class="keyword">Operator</span></span><br><span class="line">            expressions: <span class="keyword">id</span> (<span class="keyword">type</span>: <span class="keyword">string</span>), perf (<span class="keyword">type</span>: <span class="keyword">map</span>&lt;<span class="keyword">string</span>,<span class="built_in">int</span>&gt;)</span><br><span class="line">            outputColumnNames: _col0, _col1</span><br><span class="line">            <span class="keyword">Statistics</span>: <span class="keyword">Num</span> <span class="keyword">rows</span>: <span class="number">0</span> <span class="keyword">Data</span> <span class="keyword">size</span>: <span class="number">72</span> Basic stats: <span class="keyword">PARTIAL</span> <span class="keyword">Column</span> stats: <span class="keyword">NONE</span></span><br><span class="line">            <span class="keyword">Limit</span></span><br><span class="line">              <span class="built_in">Number</span> <span class="keyword">of</span> <span class="keyword">rows</span>: <span class="number">100</span></span><br><span class="line">              <span class="keyword">Statistics</span>: <span class="keyword">Num</span> <span class="keyword">rows</span>: <span class="number">0</span> <span class="keyword">Data</span> <span class="keyword">size</span>: <span class="number">72</span> Basic stats: <span class="keyword">PARTIAL</span> <span class="keyword">Column</span> stats: <span class="keyword">NONE</span></span><br><span class="line">              ListSink</span><br><span class="line"></span><br><span class="line"><span class="built_in">Time</span> taken: <span class="number">0.11</span> <span class="keyword">seconds</span>, Fetched: <span class="number">20</span> <span class="keyword">row</span>(s)</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; explain select count(*) from tmp_table1 limit 100;</span><br><span class="line">OK</span><br><span class="line">STAGE DEPENDENCIES:</span><br><span class="line">  Stage-1 is a root stage</span><br><span class="line">  Stage-0 depends on stages: Stage-1</span><br><span class="line"></span><br><span class="line">STAGE PLANS:</span><br><span class="line">  Stage: Stage-1</span><br><span class="line">    Map Reduce</span><br><span class="line">      Map Operator Tree:</span><br><span class="line">          TableScan</span><br><span class="line">            alias: tmp_table1</span><br><span class="line">            Statistics: Num rows: 0 Data size: 72 Basic stats: PARTIAL Column stats: COMPLETE</span><br><span class="line">            <span class="keyword">Select</span> <span class="keyword">Operator</span></span><br><span class="line">              <span class="keyword">Statistics</span>: <span class="keyword">Num</span> <span class="keyword">rows</span>: <span class="number">0</span> <span class="keyword">Data</span> <span class="keyword">size</span>: <span class="number">72</span> Basic stats: <span class="keyword">PARTIAL</span> <span class="keyword">Column</span> stats: <span class="keyword">COMPLETE</span></span><br><span class="line">              <span class="keyword">Group</span> <span class="keyword">By</span> <span class="keyword">Operator</span></span><br><span class="line">                aggregations: <span class="keyword">count</span>()</span><br><span class="line">                <span class="keyword">mode</span>: <span class="keyword">hash</span></span><br><span class="line">                outputColumnNames: _col0</span><br><span class="line">                <span class="keyword">Statistics</span>: <span class="keyword">Num</span> <span class="keyword">rows</span>: <span class="number">1</span> <span class="keyword">Data</span> <span class="keyword">size</span>: <span class="number">8</span> Basic stats: <span class="keyword">COMPLETE</span> <span class="keyword">Column</span> stats: <span class="keyword">COMPLETE</span></span><br><span class="line">                Reduce <span class="keyword">Output</span> <span class="keyword">Operator</span></span><br><span class="line">                  <span class="keyword">sort</span> <span class="keyword">order</span>:</span><br><span class="line">                  <span class="keyword">Statistics</span>: <span class="keyword">Num</span> <span class="keyword">rows</span>: <span class="number">1</span> <span class="keyword">Data</span> <span class="keyword">size</span>: <span class="number">8</span> Basic stats: <span class="keyword">COMPLETE</span> <span class="keyword">Column</span> stats: <span class="keyword">COMPLETE</span></span><br><span class="line">                  TopN <span class="keyword">Hash</span> <span class="keyword">Memory</span> <span class="keyword">Usage</span>: <span class="number">0.3</span></span><br><span class="line">                  <span class="keyword">value</span> expressions: _col0 (<span class="keyword">type</span>: <span class="built_in">bigint</span>)</span><br><span class="line">      Reduce <span class="keyword">Operator</span> Tree:</span><br><span class="line">        <span class="keyword">Group</span> <span class="keyword">By</span> <span class="keyword">Operator</span></span><br><span class="line">          aggregations: <span class="keyword">count</span>(VALUE._col0)</span><br><span class="line">          <span class="keyword">mode</span>: mergepartial</span><br><span class="line">          outputColumnNames: _col0</span><br><span class="line">          <span class="keyword">Statistics</span>: <span class="keyword">Num</span> <span class="keyword">rows</span>: <span class="number">1</span> <span class="keyword">Data</span> <span class="keyword">size</span>: <span class="number">8</span> Basic stats: <span class="keyword">COMPLETE</span> <span class="keyword">Column</span> stats: <span class="keyword">COMPLETE</span></span><br><span class="line">          <span class="keyword">Select</span> <span class="keyword">Operator</span></span><br><span class="line">            expressions: _col0 (<span class="keyword">type</span>: <span class="built_in">bigint</span>)</span><br><span class="line">            outputColumnNames: _col0</span><br><span class="line">            <span class="keyword">Statistics</span>: <span class="keyword">Num</span> <span class="keyword">rows</span>: <span class="number">1</span> <span class="keyword">Data</span> <span class="keyword">size</span>: <span class="number">8</span> Basic stats: <span class="keyword">COMPLETE</span> <span class="keyword">Column</span> stats: <span class="keyword">COMPLETE</span></span><br><span class="line">            <span class="keyword">Limit</span></span><br><span class="line">              <span class="built_in">Number</span> <span class="keyword">of</span> <span class="keyword">rows</span>: <span class="number">100</span></span><br><span class="line">              <span class="keyword">Statistics</span>: <span class="keyword">Num</span> <span class="keyword">rows</span>: <span class="number">1</span> <span class="keyword">Data</span> <span class="keyword">size</span>: <span class="number">8</span> Basic stats: <span class="keyword">COMPLETE</span> <span class="keyword">Column</span> stats: <span class="keyword">COMPLETE</span></span><br><span class="line">              <span class="keyword">File</span> <span class="keyword">Output</span> <span class="keyword">Operator</span></span><br><span class="line">                compressed: <span class="literal">false</span></span><br><span class="line">                <span class="keyword">Statistics</span>: <span class="keyword">Num</span> <span class="keyword">rows</span>: <span class="number">1</span> <span class="keyword">Data</span> <span class="keyword">size</span>: <span class="number">8</span> Basic stats: <span class="keyword">COMPLETE</span> <span class="keyword">Column</span> stats: <span class="keyword">COMPLETE</span></span><br><span class="line">                <span class="keyword">table</span>:</span><br><span class="line">                    <span class="keyword">input</span> <span class="keyword">format</span>: org.apache.hadoop.mapred.TextInputFormat</span><br><span class="line">                    <span class="keyword">output</span> <span class="keyword">format</span>: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</span><br><span class="line">                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</span><br><span class="line"></span><br><span class="line">  Stage: Stage<span class="number">-0</span></span><br><span class="line">    <span class="keyword">Fetch</span> <span class="keyword">Operator</span></span><br><span class="line">      <span class="keyword">limit</span>: <span class="number">100</span></span><br><span class="line">      Processor Tree:</span><br><span class="line">        ListSink</span><br><span class="line"></span><br><span class="line"><span class="built_in">Time</span> taken: <span class="number">0.055</span> <span class="keyword">seconds</span>, Fetched: <span class="number">50</span> <span class="keyword">row</span>(s)</span><br></pre></td></tr></table></figure>

<p><code>explain extended</code>：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">explain</span> <span class="keyword">extended</span> <span class="keyword">select</span> <span class="keyword">count</span>(*) <span class="keyword">from</span> tmp_table1 <span class="keyword">limit</span> <span class="number">100</span>;</span><br><span class="line">OK</span><br><span class="line">ABSTRACT SYNTAX TREE:</span><br><span class="line"></span><br><span class="line">TOK_QUERY</span><br><span class="line">   TOK_FROM</span><br><span class="line">      TOK_TABREF</span><br><span class="line">         TOK_TABNAME</span><br><span class="line">            tmp_table1</span><br><span class="line">   TOK_INSERT</span><br><span class="line">      TOK_DESTINATION</span><br><span class="line">         TOK_DIR</span><br><span class="line">            TOK_TMP_FILE</span><br><span class="line">      TOK_SELECT</span><br><span class="line">         TOK_SELEXPR</span><br><span class="line">            TOK_FUNCTIONSTAR</span><br><span class="line">               count</span><br><span class="line">      TOK_LIMIT</span><br><span class="line">         100</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">STAGE DEPENDENCIES:</span><br><span class="line">  Stage-1 is a root stage</span><br><span class="line">  Stage-0 depends on stages: Stage-1</span><br><span class="line"></span><br><span class="line">STAGE PLANS:</span><br><span class="line">  Stage: Stage-1</span><br><span class="line">    Map Reduce</span><br><span class="line">      Map Operator Tree:</span><br><span class="line">          TableScan</span><br><span class="line">            alias: tmp_table1</span><br><span class="line">            Statistics: Num rows: 0 Data size: 72 Basic stats: PARTIAL Column stats: COMPLETE</span><br><span class="line">            GatherStats: false</span><br><span class="line">            <span class="keyword">Select</span> <span class="keyword">Operator</span></span><br><span class="line">              <span class="keyword">Statistics</span>: <span class="keyword">Num</span> <span class="keyword">rows</span>: <span class="number">0</span> <span class="keyword">Data</span> <span class="keyword">size</span>: <span class="number">72</span> Basic stats: <span class="keyword">PARTIAL</span> <span class="keyword">Column</span> stats: <span class="keyword">COMPLETE</span></span><br><span class="line">              <span class="keyword">Group</span> <span class="keyword">By</span> <span class="keyword">Operator</span></span><br><span class="line">                aggregations: <span class="keyword">count</span>()</span><br><span class="line">                <span class="keyword">mode</span>: <span class="keyword">hash</span></span><br><span class="line">                outputColumnNames: _col0</span><br><span class="line">                <span class="keyword">Statistics</span>: <span class="keyword">Num</span> <span class="keyword">rows</span>: <span class="number">1</span> <span class="keyword">Data</span> <span class="keyword">size</span>: <span class="number">8</span> Basic stats: <span class="keyword">COMPLETE</span> <span class="keyword">Column</span> stats: <span class="keyword">COMPLETE</span></span><br><span class="line">                Reduce <span class="keyword">Output</span> <span class="keyword">Operator</span></span><br><span class="line">                  <span class="keyword">sort</span> <span class="keyword">order</span>:</span><br><span class="line">                  <span class="keyword">Statistics</span>: <span class="keyword">Num</span> <span class="keyword">rows</span>: <span class="number">1</span> <span class="keyword">Data</span> <span class="keyword">size</span>: <span class="number">8</span> Basic stats: <span class="keyword">COMPLETE</span> <span class="keyword">Column</span> stats: <span class="keyword">COMPLETE</span></span><br><span class="line">                  tag: <span class="number">-1</span></span><br><span class="line">                  TopN: <span class="number">100</span></span><br><span class="line">                  TopN <span class="keyword">Hash</span> <span class="keyword">Memory</span> <span class="keyword">Usage</span>: <span class="number">0.3</span></span><br><span class="line">                  <span class="keyword">value</span> expressions: _col0 (<span class="keyword">type</span>: <span class="built_in">bigint</span>)</span><br><span class="line">                  <span class="keyword">auto</span> parallelism: <span class="literal">false</span></span><br><span class="line">      <span class="keyword">Path</span> -&gt; <span class="keyword">Alias</span>:</span><br><span class="line">        hdfs://f04/<span class="keyword">user</span>/hive/warehouse/temp.db/tmp_table1 [tmp_table1]</span><br><span class="line">      <span class="keyword">Path</span> -&gt; <span class="keyword">Partition</span>:</span><br><span class="line">        hdfs://f04/<span class="keyword">user</span>/hive/warehouse/temp.db/tmp_table1</span><br><span class="line">          <span class="keyword">Partition</span></span><br><span class="line">            base <span class="keyword">file</span> <span class="keyword">name</span>: tmp_table1</span><br><span class="line">            <span class="keyword">input</span> <span class="keyword">format</span>: org.apache.hadoop.mapred.TextInputFormat</span><br><span class="line">            <span class="keyword">output</span> <span class="keyword">format</span>: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</span><br><span class="line">            properties:</span><br><span class="line">              COLUMN_STATS_ACCURATE <span class="literal">true</span></span><br><span class="line">              bucket_count <span class="number">-1</span></span><br><span class="line">              colelction.delim ,</span><br><span class="line">              <span class="keyword">columns</span> <span class="keyword">id</span>,perf</span><br><span class="line">              columns.comments</span><br><span class="line">              columns.types <span class="keyword">string</span>:<span class="keyword">map</span>&lt;<span class="keyword">string</span>,<span class="built_in">int</span>&gt;</span><br><span class="line">              field.delim</span><br><span class="line">              file.inputformat org.apache.hadoop.mapred.TextInputFormat</span><br><span class="line">              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</span><br><span class="line">              location hdfs://f04/<span class="keyword">user</span>/hive/warehouse/temp.db/tmp_table1</span><br><span class="line">              mapkey.delim :</span><br><span class="line">              <span class="keyword">name</span> temp.tmp_table1</span><br><span class="line">              numFiles <span class="number">1</span></span><br><span class="line">              serialization.ddl <span class="keyword">struct</span> tmp_table1 &#123; <span class="keyword">string</span> <span class="keyword">id</span>, <span class="keyword">map</span>&lt;<span class="keyword">string</span>,i32&gt; perf&#125;</span><br><span class="line">              serialization.format</span><br><span class="line">              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</span><br><span class="line">              totalSize <span class="number">72</span></span><br><span class="line">              transient_lastDdlTime <span class="number">1438742089</span></span><br><span class="line">            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</span><br><span class="line"></span><br><span class="line">              <span class="keyword">input</span> <span class="keyword">format</span>: org.apache.hadoop.mapred.TextInputFormat</span><br><span class="line">              <span class="keyword">output</span> <span class="keyword">format</span>: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</span><br><span class="line">              properties:</span><br><span class="line">                COLUMN_STATS_ACCURATE <span class="literal">true</span></span><br><span class="line">                bucket_count <span class="number">-1</span></span><br><span class="line">                colelction.delim ,</span><br><span class="line">                <span class="keyword">columns</span> <span class="keyword">id</span>,perf</span><br><span class="line">                columns.comments</span><br><span class="line">                columns.types <span class="keyword">string</span>:<span class="keyword">map</span>&lt;<span class="keyword">string</span>,<span class="built_in">int</span>&gt;</span><br><span class="line">                field.delim</span><br><span class="line">                file.inputformat org.apache.hadoop.mapred.TextInputFormat</span><br><span class="line">                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</span><br><span class="line">                location hdfs://f04/<span class="keyword">user</span>/hive/warehouse/temp.db/tmp_table1</span><br><span class="line">                mapkey.delim :</span><br><span class="line">                <span class="keyword">name</span> temp.tmp_table1</span><br><span class="line">                numFiles <span class="number">1</span></span><br><span class="line">                serialization.ddl <span class="keyword">struct</span> tmp_table1 &#123; <span class="keyword">string</span> <span class="keyword">id</span>, <span class="keyword">map</span>&lt;<span class="keyword">string</span>,i32&gt; perf&#125;</span><br><span class="line">                serialization.format</span><br><span class="line">                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</span><br><span class="line">                totalSize <span class="number">72</span></span><br><span class="line">                transient_lastDdlTime <span class="number">1438742089</span></span><br><span class="line">              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</span><br><span class="line">              <span class="keyword">name</span>: temp.tmp_table1</span><br><span class="line">            <span class="keyword">name</span>: temp.tmp_table1</span><br><span class="line">      Truncated <span class="keyword">Path</span> -&gt; <span class="keyword">Alias</span>:</span><br><span class="line">        /temp.db/tmp_table1 [tmp_table1]</span><br><span class="line">      Needs Tagging: <span class="literal">false</span></span><br><span class="line">      Reduce <span class="keyword">Operator</span> Tree:</span><br><span class="line">        <span class="keyword">Group</span> <span class="keyword">By</span> <span class="keyword">Operator</span></span><br><span class="line">          aggregations: <span class="keyword">count</span>(VALUE._col0)</span><br><span class="line">          <span class="keyword">mode</span>: mergepartial</span><br><span class="line">          outputColumnNames: _col0</span><br><span class="line">          <span class="keyword">Statistics</span>: <span class="keyword">Num</span> <span class="keyword">rows</span>: <span class="number">1</span> <span class="keyword">Data</span> <span class="keyword">size</span>: <span class="number">8</span> Basic stats: <span class="keyword">COMPLETE</span> <span class="keyword">Column</span> stats: <span class="keyword">COMPLETE</span></span><br><span class="line">          <span class="keyword">Select</span> <span class="keyword">Operator</span></span><br><span class="line">            expressions: _col0 (<span class="keyword">type</span>: <span class="built_in">bigint</span>)</span><br><span class="line">            outputColumnNames: _col0</span><br><span class="line">            <span class="keyword">Statistics</span>: <span class="keyword">Num</span> <span class="keyword">rows</span>: <span class="number">1</span> <span class="keyword">Data</span> <span class="keyword">size</span>: <span class="number">8</span> Basic stats: <span class="keyword">COMPLETE</span> <span class="keyword">Column</span> stats: <span class="keyword">COMPLETE</span></span><br><span class="line">            <span class="keyword">Limit</span></span><br><span class="line">              <span class="built_in">Number</span> <span class="keyword">of</span> <span class="keyword">rows</span>: <span class="number">100</span></span><br><span class="line">              <span class="keyword">Statistics</span>: <span class="keyword">Num</span> <span class="keyword">rows</span>: <span class="number">1</span> <span class="keyword">Data</span> <span class="keyword">size</span>: <span class="number">8</span> Basic stats: <span class="keyword">COMPLETE</span> <span class="keyword">Column</span> stats: <span class="keyword">COMPLETE</span></span><br><span class="line">              <span class="keyword">File</span> <span class="keyword">Output</span> <span class="keyword">Operator</span></span><br><span class="line">                compressed: <span class="literal">false</span></span><br><span class="line">                GlobalTableId: <span class="number">0</span></span><br><span class="line">                <span class="keyword">directory</span>: hdfs://f04/home/maintain/hive/hive/tmp/hive-maintain/maintain/<span class="number">13951</span>f1a<span class="number">-3</span>bd6<span class="number">-481</span>f-a901<span class="number">-1</span>b2c185ec877/hive_2015<span class="number">-11</span><span class="number">-05</span>_14<span class="number">-37</span><span class="number">-47</span>_859_3395572406114851553<span class="number">-1</span>/-ext<span class="number">-10001</span></span><br><span class="line">                NumFilesPerFileSink: <span class="number">1</span></span><br><span class="line">                <span class="keyword">Statistics</span>: <span class="keyword">Num</span> <span class="keyword">rows</span>: <span class="number">1</span> <span class="keyword">Data</span> <span class="keyword">size</span>: <span class="number">8</span> Basic stats: <span class="keyword">COMPLETE</span> <span class="keyword">Column</span> stats: <span class="keyword">COMPLETE</span></span><br><span class="line">                Stats Publishing <span class="keyword">Key</span> Prefix: hdfs://f04/home/maintain/hive/hive/tmp/hive-maintain/maintain/<span class="number">13951</span>f1a<span class="number">-3</span>bd6<span class="number">-481</span>f-a901<span class="number">-1</span>b2c185ec877/hive_2015<span class="number">-11</span><span class="number">-05</span>_14<span class="number">-37</span><span class="number">-47</span>_859_3395572406114851553<span class="number">-1</span>/-ext<span class="number">-10001</span>/</span><br><span class="line">                <span class="keyword">table</span>:</span><br><span class="line">                    <span class="keyword">input</span> <span class="keyword">format</span>: org.apache.hadoop.mapred.TextInputFormat</span><br><span class="line">                    <span class="keyword">output</span> <span class="keyword">format</span>: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</span><br><span class="line">                    properties:</span><br><span class="line">                      <span class="keyword">columns</span> _col0</span><br><span class="line">                      columns.types <span class="built_in">bigint</span></span><br><span class="line">                      escape.delim \</span><br><span class="line">                      hive.serialization.extend.nesting.levels <span class="literal">true</span></span><br><span class="line">                      serialization.format <span class="number">1</span></span><br><span class="line">                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</span><br><span class="line">                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</span><br><span class="line">                TotalFiles: <span class="number">1</span></span><br><span class="line">                GatherStats: <span class="literal">false</span></span><br><span class="line">                MultiFileSpray: <span class="literal">false</span></span><br><span class="line"></span><br><span class="line">  Stage: Stage<span class="number">-0</span></span><br><span class="line">    <span class="keyword">Fetch</span> <span class="keyword">Operator</span></span><br><span class="line">      <span class="keyword">limit</span>: <span class="number">100</span></span><br><span class="line">      Processor Tree:</span><br><span class="line">        ListSink</span><br><span class="line"></span><br><span class="line"><span class="built_in">Time</span> taken: <span class="number">0.059</span> <span class="keyword">seconds</span>, Fetched: <span class="number">143</span> <span class="keyword">row</span>(s)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive.exec.reducers.max&#x3D;</span><br><span class="line">(集群总reduce槽位个数*1.5)&#x2F;(执行中的查询平均个数)</span><br></pre></td></tr></table></figure>

<p>若小任务多可开启优化：推测执行和<code>JVM</code>重用。 </p>
<p>虚拟列?</p>
<p>I/O密集型该使用压缩；CPU密集型任务则不然。</p>
<p><code>sequence file</code>存储格式: 压缩且可分。</p>
<p><code>CLI</code>会话中通过<code>set</code>命令设置的属性在同一个会话中会一直生效的。</p>
<hr>
<p><code>show functions;</code>列出所有函数(包括用户自定义函数(<code>UDF</code>))。<br><code>describe function extended concat;</code>展示函数的简单介绍。<br><code>UDTF</code>自定义表生成函数；<br><code>UDAF</code>自定义聚合函数。</p>
<hr>
<p><code>python</code>版<code>map-reduce</code>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># mapper.py:</span></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    words=line.strip().split()</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> words:</span><br><span class="line">        <span class="keyword">print</span> <span class="string">"%s\t"</span> % (word.lower())</span><br><span class="line"><span class="comment">#reducer.py:</span></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line">(last_key, last_count)=(<span class="literal">None</span>,<span class="number">0</span>)</span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    (key,count)=linde.strip().split(<span class="string">"\t"</span>)</span><br><span class="line">    <span class="keyword">if</span> last_key <span class="keyword">and</span> last_key!=key:</span><br><span class="line">        <span class="keyword">print</span> <span class="string">"%s\t%d"</span> % (last_key, last_count)</span><br><span class="line">        (last_key, last_count)=(key, int(count))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        last_key=key</span><br><span class="line">        last_count+=int(count)</span><br><span class="line"><span class="keyword">if</span> last_key:</span><br><span class="line">    <span class="keyword">print</span> <span class="string">"%s\t%d"</span> % (last_key, last_count)</span><br></pre></td></tr></table></figure>
<p>使用<code>transform</code>关键字调用脚本，省得写<code>UDF</code>:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> docs (line <span class="keyword">String</span>)</span><br><span class="line">;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> word_count (word <span class="keyword">String</span>, <span class="keyword">count</span> <span class="built_in">Int</span>)</span><br><span class="line"><span class="keyword">Row</span> <span class="keyword">format</span> <span class="keyword">delimited</span> <span class="keyword">fields</span> teminated <span class="keyword">by</span> <span class="string">'\t'</span></span><br><span class="line">;</span><br><span class="line">from(</span><br><span class="line">    from docs</span><br><span class="line">    <span class="keyword">select</span> transform (line) <span class="keyword">using</span> <span class="string">'$&#123;env:HOME&#125;/mapper.py'</span></span><br><span class="line">    <span class="keyword">as</span> word,<span class="keyword">count</span></span><br><span class="line">    cluster <span class="keyword">by</span> word) wc</span><br><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> word_count</span><br><span class="line"><span class="keyword">select</span> transform (wc.word,wc.count)</span><br><span class="line">    <span class="keyword">using</span> <span class="string">'$&#123;env:HOME&#125;/reducer.py'</span></span><br><span class="line">    <span class="keyword">as</span> word, <span class="keyword">count</span></span><br><span class="line">;</span><br></pre></td></tr></table></figure>

<hr>
<ul>
<li>自定义序列化：<br><code>json SerDe</code>:<code>P214</code><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">external</span> <span class="keyword">table</span> messages(</span><br><span class="line">msg_id <span class="built_in">bigint</span>,</span><br><span class="line">tstamp <span class="keyword">string</span>,</span><br><span class="line"><span class="built_in">text</span> <span class="keyword">string</span>,</span><br><span class="line">user_id <span class="built_in">bigint</span>,</span><br><span class="line">user_name <span class="keyword">string</span></span><br><span class="line">)</span><br><span class="line"><span class="keyword">row</span> <span class="keyword">format</span> SerDe <span class="string">"org.apache.hadoop.hive.contrib.serde2.JsonSerde"</span></span><br><span class="line"><span class="keyword">with</span> serdeProperties(</span><br><span class="line"><span class="string">"msg_id"</span>=<span class="string">"$.id"</span>,</span><br><span class="line"><span class="string">"tstamp"</span>=<span class="string">"$.created_at"</span>,</span><br><span class="line"><span class="string">"text"</span>=<span class="string">"$.text"</span>,</span><br><span class="line"><span class="string">"user_id"</span>=<span class="string">"$.user.id"</span>,</span><br><span class="line"><span class="string">"user_name"</span>=<span class="string">"$.user.name"</span></span><br><span class="line">)</span><br><span class="line">Location <span class="string">'/data/messages'</span></span><br><span class="line">;</span><br></pre></td></tr></table></figure>

</li>
</ul>
<hr>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hive -hiveconf start_date&#x3D;&#39;2015-11-15&#39; -hiveconf end_date&#x3D;&#39;2015-11-21&#39; -f .&#x2F;comments_data.hql</span><br><span class="line"></span><br><span class="line">solarWarehouse</span><br><span class="line">userstat函数</span><br></pre></td></tr></table></figure>


<p>这个地方错好多次了：</p>
<blockquote>
<p>left join 不在on里使用where</p>
</blockquote>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://xiaoyue26.github.io/2017/01/22/hive%E7%AC%94%E8%AE%B0/" data-id="ck96cxpl60026maam3gli7lie" class="article-share-link">分享</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/hive/" rel="tag">hive</a></li></ul>

    </footer>
  </div>
  
    
 
<script src="/jquery/jquery.min.js"></script>

  <div id="random_posts">
    <h2>推荐文章</h2>
    <div class="random_posts_ul">
      <script>
          var random_count =4
          var site = {BASE_URI:'/'};
          function load_random_posts(obj) {
              var arr=site.posts;
              if (!obj) return;
              // var count = $(obj).attr('data-count') || 6;
              for (var i, tmp, n = arr.length; n; i = Math.floor(Math.random() * n), tmp = arr[--n], arr[n] = arr[i], arr[i] = tmp);
              arr = arr.slice(0, random_count);
              var html = '<ul>';
            
              for(var j=0;j<arr.length;j++){
                var item=arr[j];
                html += '<li><strong>' + 
                item.date + ':&nbsp;&nbsp;<a href="' + (site.BASE_URI+item.uri) + '">' + 
                (item.title || item.uri) + '</a></strong>';
                if(item.excerpt){
                  html +='<div class="post-excerpt">'+item.excerpt+'</div>';
                }
                html +='</li>';
                
              }
              $(obj).html(html + '</ul>');
          }
          $('.random_posts_ul').each(function () {
              var c = this;
              if (!site.posts || !site.posts.length){
                  $.getJSON(site.BASE_URI + 'js/posts.js',function(json){site.posts = json;load_random_posts(c)});
              } 
               else{
                load_random_posts(c);
              }
          });
      </script>
    </div>
  </div>

    
<nav id="article-nav">
  
    <a href="/2017/02/04/HTTP-method-%E8%A7%84%E8%8C%83/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">上一篇</strong>
      <div class="article-nav-title">
        
          HTTP method 规范
        
      </div>
    </a>
  
  
    <a href="/2017/01/15/hive-udf/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">下一篇</strong>
      <div class="article-nav-title">hive udf</div>
    </a>
  
</nav>

  
</article>
 
     
  <div class="comments" id="comments">
    
     
       
      <div id="cloud-tie-wrapper" class="cloud-tie-wrapper"></div>
    
       
      
      
  </div>
 
  

</section>
           
    <aside id="sidebar">
  
    

  
    
    <div class="widget-wrap">
    
      <div class="widget" id="toc-widget-fixed">
      
        <strong class="toc-title">文章目录</strong>
        <div class="toc-widget-list">
              <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#hive-小技巧"><span class="toc-number">1.</span> <span class="toc-text">hive 小技巧</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#hive-1-2-1-bug"><span class="toc-number">2.</span> <span class="toc-text">hive 1.2.1 bug:</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#hive传参数"><span class="toc-number">3.</span> <span class="toc-text">hive传参数:</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#hive-更新函数"><span class="toc-number">4.</span> <span class="toc-text">hive 更新函数:</span></a></li></ol>
          </div>
      </div>
    </div>

  
    

  
    
  
    
  
    

  
</aside>

      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-left">
      &copy; 2014 - 2020 风梦七&nbsp;|&nbsp;
      主题 <a href="https://github.com/giscafer/hexo-theme-cafe/" target="_blank">Cafe</a>
    </div>
     <div id="footer-right">
      联系方式&nbsp;|&nbsp;296671657@qq.com
    </div>
  </div>
</footer>
 
<script src="/jquery/jquery.min.js"></script>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">首页</a>
  
    <a href="/archives" class="mobile-nav-link">归档</a>
  
    <a href="/about" class="mobile-nav-link">关于</a>
  
</nav>
    <img class="back-to-top-btn" src="/images/fly-to-top.png"/>
<script>
// Elevator script included on the page, already.
window.onload = function() {
  var elevator = new Elevator({
    selector:'.back-to-top-btn',
    element: document.querySelector('.back-to-top-btn'),
    duration: 1000 // milliseconds
  });
}
</script>
      

  
    <script>
      var cloudTieConfig = {
        url: document.location.href, 
        sourceId: "",
        productKey: "e2fb4051c49842688ce669e634bc983f",
        target: "cloud-tie-wrapper"
      };
    </script>
    <script src="https://img1.ws.126.net/f2e/tie/yun/sdk/loader.js"></script>
    

  







<!-- author:forvoid begin -->
<!-- author:forvoid begin -->

<!-- author:forvoid end -->

<!-- author:forvoid end -->


  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      })
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      })
    </script>
    <script type="text/javascript" src="https://cdn.rawgit.com/mathjax/MathJax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


 
<script src="/js/is.js"></script>



  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>


<script src="/js/elevator.js"></script>

  </div>
</body>
</html>