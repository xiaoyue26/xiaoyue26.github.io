<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>笔记本</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="笔记本">
<meta property="og:url" content="http://xiaoyue26.github.io/page/16/index.html">
<meta property="og:site_name" content="笔记本">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="风梦七">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="笔记本" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    
  
  
<link rel="stylesheet" href="/css/style.css">

  

<meta name="generator" content="Hexo 4.2.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    
    <div id="header-inner" class="inner">
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://xiaoyue26.github.io"></form>
      </div>
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">首页</a>
        
          <a class="main-nav-link" href="/archives">归档</a>
        
          <a class="main-nav-link" href="/about">关于</a>
        
      </nav>
      
    </div>
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">笔记本</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">风梦七</a>
        </h2>
      
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-kafka学习笔记" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/03/01/kafka%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" class="article-date">
  <time datetime="2017-03-01T11:53:02.000Z" itemprop="datePublished">2017-03-01</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/">消息队列</a>►<a class="article-category-link" href="/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/kafka/">kafka</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/03/01/kafka%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">kafka学习笔记</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
        
        <p>原理:(与rocketMQ对比,理解更深刻)<br><a href="http://blog.csdn.net/chunlongyu/article/details/54018010" target="_blank" rel="noopener">http://blog.csdn.net/chunlongyu/article/details/54018010</a></p>
<p>quickStart:<br><a href="http://kafka.apache.org/quickstart" target="_blank" rel="noopener">http://kafka.apache.org/quickstart</a></p>
<p>照着官网做就好了.起步简单.</p>
<p>#Master/Slave概念差异<br>Kafka:</p>
<blockquote>
<p>Master/Slave是个逻辑概念，1台机器，同时具有Master角色和Slave角色。 </p>
</blockquote>
<p>RocketMQ:</p>
<blockquote>
<p>Master/Slave是个物理概念，1台机器，只能是Master或者Slave。在集群初始配置的时候，指定死的。其中Master的broker id = 0，Slave的broker id &gt; 0。</p>
</blockquote>
<p>#Broker概念差异<br>Kafka:</p>
<blockquote>
<p>Broker是个物理概念，1个broker就对应1台机器。 </p>
</blockquote>
<p>RocketMQ：</p>
<blockquote>
<p>Broker是个逻辑概念，1个broker = 1个master + 多个slave。所以才有master broker, slave broker这样的概念。<br>那这里，master和slave是如何配对的呢？ 答案是通过broker name。具有同1个broker name的master和slave进行配对。</p>
</blockquote>
<p>RocketMQ不依赖ZK,是因为设计上进行了简化,不需要那么多选举.<br>用个简单的NameServer就搞定了，很轻量，还无状态，可靠性也能得到很好保证。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://xiaoyue26.github.io/2017/03/01/kafka%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" data-id="ck96cxpli003emaam1bqx92of" class="article-share-link">分享</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/kafka/" rel="tag">kafka</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-java并发编程实战笔记-6-7章" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/02/25/java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98%E7%AC%94%E8%AE%B0-6-7%E7%AB%A0/" class="article-date">
  <time datetime="2017-02-25T11:45:43.000Z" itemprop="datePublished">2017-02-25</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/java/">java</a>►<a class="article-category-link" href="/categories/java/%E5%B9%B6%E5%8F%91/">并发</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/02/25/java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98%E7%AC%94%E8%AE%B0-6-7%E7%AB%A0/">java并发编程实战笔记-6-7章</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
        
        <h1 id="6-1节-背景"><a href="#6-1节-背景" class="headerlink" title="6.1节 背景"></a>6.1节 背景</h1><p>(为了引出Executor框架)<br>任务执行方式:</p>
<ol>
<li>串行; 单线程,太慢;</li>
<li>完全并行; 每个任务一个线程,开销太大.</li>
<li>使用Executor框架. OK </li>
</ol>
<h1 id="6-2-Executor框架"><a href="#6-2-Executor框架" class="headerlink" title="6.2 Executor框架"></a>6.2 Executor框架</h1><p><code>java.util.concurrent</code>提供的线程池.<br>可以通过实现Executor接口,自定义执行策略:</p>
<ol>
<li>谁来执行;</li>
<li>执行顺序;(FIFO,LIFO,优先级)</li>
<li>并发度;</li>
<li>线程池容量(包括等待的);</li>
<li>什么时候拒绝任务,拒绝哪一个;</li>
<li>执行任务前后的操作.</li>
</ol>
<p>或者直接使用<code>Executors</code>中编写好的线程池/执行策略:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">newFixedThreadPool &#x2F;&#x2F; 定长</span><br><span class="line">newCachedThreadPool &#x2F;&#x2F; 无限增长,但会复用原来的</span><br><span class="line">newSingleThreadExecutor &#x2F;&#x2F; 单线程</span><br><span class="line">newScheduledThreadPool &#x2F;&#x2F; 定长,但可以定时\延迟执行.</span><br><span class="line">newWorkStealingPool &#x2F;&#x2F; 用fork-join的,工作觅取的 &#x2F;&#x2F; 1.8新增.</span><br></pre></td></tr></table></figure>

<h2 id="Executor的生命周期"><a href="#Executor的生命周期" class="headerlink" title="Executor的生命周期"></a>Executor的生命周期</h2><p>为了以各种方式关掉<code>Executor</code>,库中写了<code>ExecutorService</code>:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">public interface ExecutorService extends Executor &#123;</span><br><span class="line">        void shutdown();&#x2F;&#x2F;平缓得关闭,不再接收新任务,执行剩余的;</span><br><span class="line">        List&lt;Runnable&gt; shutdownNow();&#x2F;&#x2F;取消运行中的和未执行的;</span><br><span class="line">        boolean isShutdown();&#x2F;&#x2F;是否已经下达shutdown命令</span><br><span class="line">        boolean isTerminated();&#x2F;&#x2F;是否完成了shutdown命令</span><br><span class="line">        boolean awaitTermination(long timeout, TimeUnit unit)</span><br><span class="line">                throws InterruptedException;</span><br><span class="line">        &#x2F;&#x2F; ... 还有一些invoke和submit        </span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<p>ExecutorService生命周期有3种状态:<br>运行,关闭,已终止. </p>
<p>ExecutorService中的任务的生命周期:<br>创建,提交,开始,完成.</p>
<p>上述生命周期都是单向不可逆的.</p>
<h1 id="线程池的局限"><a href="#线程池的局限" class="headerlink" title="线程池的局限"></a>线程池的局限</h1><ol>
<li>适用于同构任务,异构任务分解粒度不够细,提升不够大;</li>
</ol>
<h1 id="第七章-取消与关闭"><a href="#第七章-取消与关闭" class="headerlink" title="第七章 取消与关闭"></a>第七章 取消与关闭</h1><h2 id="背景"><a href="#背景" class="headerlink" title="背景:"></a>背景:</h2><blockquote>
<p>java中无法简单\安全得停止取消某个线程;<br>需要使用中断(一种协作机制),从一个线程发出取消请求,中断另一个线程.因此其实需要被中断的线程预先提供安全停止\取消的方法,其中包括清理资源等操作.</p>
</blockquote>
<h2 id="取消策略"><a href="#取消策略" class="headerlink" title="取消策略:"></a>取消策略:</h2><ol>
<li>HOW: 其他线程如何请求取消;</li>
<li>WHEN: 本线程何时受理取消请求;</li>
<li>WHAT: 取消时具体要干什么.</li>
</ol>
<p>Thread中的中断方法:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">public class Thread&#123;</span><br><span class="line">public void interrupt()&#123;&#125;&#x2F;&#x2F; 中断此线程</span><br><span class="line">public boolean isInterrupted()&#123;&#125;&#x2F;&#x2F;查询中断状态</span><br><span class="line">public static boolean interrupted()&#123;&#125;&#x2F;&#x2F; 查询中断状态,且清除中断.</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="中断策略"><a href="#中断策略" class="headerlink" title="中断策略"></a>中断策略</h2><p>有些线程不支持取消,但可以支持中断. </p>
<p>中断的方法:</p>
<ol>
<li><p>直接中断:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Thread.currentThread().interrupt();</span><br></pre></td></tr></table></figure></li>
<li><p>限时任务:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Future&lt;?&gt;task&#x3D;exec.submit(r);</span><br><span class="line">task.get(timeout,unit);</span><br><span class="line">task.cancel();</span><br></pre></td></tr></table></figure>
</li>
<li><p>处理不可中断的阻塞:</p>
</li>
</ol>
<p>(1)java.io包中的同步Socket I/O:<br><code>InputStream</code>和<code>OutputStream</code>的read,write方法都不会响应中断.<br>中断方法: 关闭底层套接字,让read,write抛出SocketException. </p>
<p>(2)java.io包中的同步I/O:<br>中断方法:<br>中断<code>InterruptibleChannel</code>.抛出<code>ClosedByInterruptExeception</code>.<br>关闭<code>InterruptibleChannel</code>.抛出<code>AsynchronousCloseException</code>.</p>
<p>(3)Selector的异步I/O:(java.nio.channels)<br>中断方法:<br>close或wakeup方法. 抛出<code>ClosedSelectorException</code>.</p>
<p>(4)等待内置锁.<br>使用Lock类中的<code>lockInterruptible</code>方法.</p>
<h1 id="取消策略的设计"><a href="#取消策略的设计" class="headerlink" title="取消策略的设计"></a>取消策略的设计</h1><p>1.设置取消信号量.</p>
<blockquote>
<p>太山寨. 缺陷:<br>(1) while循环中不能有阻塞,否则无法取消.<br>因此需要检查while循环中的每一行代码,确保安全比较麻烦.</p>
</blockquote>
<p>2.捕获中断异常.自定义存盘操作.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; 用cancel接口封装后调用.</span><br><span class="line">public void cancel()&#123;this.interrupt();&#125;</span><br></pre></td></tr></table></figure>

<p>3.任务交给ExecutorService托管.// 本质上调了interrupt. </p>
<p>4.使用毒丸对象.</p>
<blockquote>
<p>缺陷: 仅当生产者消费者数量已知情况.无界队列场景下使用.</p>
</blockquote>
<h2 id="Executors保存进度"><a href="#Executors保存进度" class="headerlink" title="Executors保存进度"></a>Executors保存进度</h2><p>shutdownNow会返回尚未开始的线程列表. 无法获得中途取消的.<br>可以自己封装一遍ExecutorsService. 重写execute方法,捕获异常判断状态,记录取消的线程.<br>详见代码:<br><a href="https://github.com/xiaoyue26/july/blob/master/src/main/java/practice/chapter7/TrackingExecutor.java" target="_blank" rel="noopener">https://github.com/xiaoyue26/july/blob/master/src/main/java/practice/chapter7/TrackingExecutor.java</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://xiaoyue26.github.io/2017/02/25/java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98%E7%AC%94%E8%AE%B0-6-7%E7%AB%A0/" data-id="ck96cxpla002mmaam3khog7zl" class="article-share-link">分享</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/java/" rel="tag">java</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-java并发编程实战笔记-4-5章" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/02/25/java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98%E7%AC%94%E8%AE%B0-4-5%E7%AB%A0/" class="article-date">
  <time datetime="2017-02-25T11:44:30.000Z" itemprop="datePublished">2017-02-25</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/java/">java</a>►<a class="article-category-link" href="/categories/java/%E5%B9%B6%E5%8F%91/">并发</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/02/25/java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98%E7%AC%94%E8%AE%B0-4-5%E7%AB%A0/">java并发编程实战笔记-4-5章</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
        
        <h1 id="对象的组合"><a href="#对象的组合" class="headerlink" title="对象的组合"></a>对象的组合</h1><h1 id="设计线程安全类"><a href="#设计线程安全类" class="headerlink" title="设计线程安全类"></a>设计线程安全类</h1><p>三个步骤:</p>
<blockquote>
<ol>
<li>找出构成对象状态的所有变量;</li>
<li>找出约束状态变量的不变性条件;//收集同步需求,例如哪些操作必须是原子性的.</li>
<li>建立对象状态的并发访问管理策略.</li>
</ol>
</blockquote>
<h1 id="包装类"><a href="#包装类" class="headerlink" title="包装类"></a>包装类</h1><p>常见容器ArrayList不是线程安全的, 但可以通过Collections.synchronizedList方法转化成一个线程安全的容器.(实现上使用装饰器模式,封装对于底层对象的访问).<br>此时,只要这个包装类持有数据对象的唯一引用,则可以保证容器的安全.</p>
<h1 id="监视器模式"><a href="#监视器模式" class="headerlink" title="监视器模式"></a>监视器模式</h1><p>通过一个私有的锁保护状态:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PrivateLock</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Object myLock=<span class="keyword">new</span> Object();</span><br><span class="line">    <span class="meta">@GuardedBy</span>(<span class="string">"myLock"</span>)</span><br><span class="line">    JRSUIConstants.Widget widget;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">someMothode</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">synchronized</span> (myLock)&#123;</span><br><span class="line">            <span class="comment">// do some thing</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h1 id="对象的组合-1"><a href="#对象的组合-1" class="headerlink" title="对象的组合"></a>对象的组合</h1><ol>
<li>一个没有成员的对象A,无状态,因此是线程安全的;</li>
<li>当A中增加一个成员,如:<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">A</span></span>&#123;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> AtomicLong aa=<span class="keyword">new</span> AtomicLong(<span class="number">0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
因为引用不可变,且AtomicLong是线程安全的,因此A依然是安全的.<br>但如果增加多个线程安全成员,当且仅当它们独立的时候是安全的.<br>如果不独立,例如某些aa和bb的取值组合是不合法的,则是不安全的.<br>(例如上界下界都是AtomicLong.但不独立.)</li>
</ol>
<h2 id="委托"><a href="#委托" class="headerlink" title="委托:"></a>委托:</h2><blockquote>
<p>此时A是否线程安全取决于aa,换言之,A的安全性委托aa来保证. </p>
</blockquote>
<p>综上可知,尽量委托给一个线程安全的类或容器,避免所托非人.XD</p>
<h1 id="基础构建模块"><a href="#基础构建模块" class="headerlink" title="基础构建模块"></a>基础构建模块</h1><p>将线程安全委托给一个JDK实现好的同步容器后,如果需要进行复合操作,而且需要这几个操作具有原子性,依然需要自己加锁.这个时候就得知道底层的同步容器原先使用的锁是什么,才好照着写.</p>
<p>//每当遇到难题,都可以考虑生成一个静态镜像,线程局部变量,避开这个难题.实在不行只好升级手段,增加复杂度.</p>
<h2 id="迭代器与ConcurrentModificationException"><a href="#迭代器与ConcurrentModificationException" class="headerlink" title="迭代器与ConcurrentModificationException"></a>迭代器与ConcurrentModificationException</h2><blockquote>
<p>同步容器的迭代器在迭代之前会获取容器的锁,<br>如果迭代过程中,检测到容器有修改,则会抛这个异常.<br>(实现上,是通过计数器实现的,而且没有同步(性能考虑),因此也有可能没有意识到已经修改了,读了失效数据.)</p>
</blockquote>
<ul>
<li>隐藏迭代器<br>容器类的toString方法.直接打印容器的时候,会触发对容器内所有内容的迭代.<br>其他类似的方法有:<br>hashCode,equals,ContainsAll等等.<br>以及容器整体作为一个key,存入另一个容器时.</li>
</ul>
<h2 id="同步容器和并发容器"><a href="#同步容器和并发容器" class="headerlink" title="同步容器和并发容器"></a>同步容器和并发容器</h2><h3 id="同步容器"><a href="#同步容器" class="headerlink" title="同步容器:"></a>同步容器:</h3><blockquote>
<p>HashTable,Vector,Collections.synchronizedXxx包装的.</p>
</blockquote>
<ul>
<li>强一致性.</li>
<li>迭代时锁容器,不允许修改.</li>
</ul>
<h3 id="并发容器"><a href="#并发容器" class="headerlink" title="并发容器:"></a>并发容器:</h3><blockquote>
<p>ConcurrentMap,CopyOnWriteList,BlockingQueue,ConcurrentLinkedQueue.</p>
</blockquote>
<ul>
<li>弱一致性.(size,isEmpty只返回近似值)</li>
<li>迭代时一般只锁局部,容忍修改.</li>
<li>性能高.</li>
</ul>
<p>基本上应该使用并发容器代替同步容器. </p>
<h2 id="两种队列的使用场景"><a href="#两种队列的使用场景" class="headerlink" title="两种队列的使用场景"></a>两种队列的使用场景</h2><ol>
<li><code>BlockingQueue</code>:<br>生产者消费者,queue.put(xxx),queue.take();</li>
<li><code>BlockingDeque</code>:(双端队列)<br>工作队列\工作觅取(fork-join);完成了自己的工作队列后,从别人队列的尾巴觅取新的工作,均摊工作量.</li>
</ol>
<h2 id="阻塞方法与中断方法"><a href="#阻塞方法与中断方法" class="headerlink" title="阻塞方法与中断方法"></a>阻塞方法与中断方法</h2><p>阻塞状态:</p>
<blockquote>
<p>BLOCKED,WAITING,TIMED_WAITING</p>
</blockquote>
<p>如果一个方法签名抛出<code>InterruptedException</code>,则说明它是阻塞方法.<br>因为一个阻塞方法一般会被中断打断.</p>
<p>中断: Interrupt<br>查询线程是否中断: interrupt方法;<br>中断线程:   也是  interrupt方法. </p>
<p>当你的方法catch到了一个<code>InterruptedException</code>,两种处理方法:</p>
<ol>
<li>传递. 接着往外抛;</li>
<li>恢复中断.<br>当已经是最外层的时候,(在Runnable这一层了)<br>就不能往外抛了,再抛线程就挂了.<br>这个时候保持中断状态就好:(恢复中断)<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">catch</span>(InterruptedException e )&#123;</span><br><span class="line"></span><br><span class="line">Thread.currentThread().interrupt();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

</li>
</ol>
<h1 id="同步工具类"><a href="#同步工具类" class="headerlink" title="同步工具类"></a>同步工具类</h1><p>可以用于同步线程的工具类,包括:</p>
<blockquote>
<p>BlockingQueue 阻塞队列<br>Semephore 信号量<br>Barrier 栅栏<br>Latch 闭锁</p>
</blockquote>
<h2 id="闭锁-Latch"><a href="#闭锁-Latch" class="headerlink" title="闭锁 Latch"></a>闭锁 Latch</h2><p>作用相当于一道门,所有线程得等这扇门打开才能继续运行.<br>Latch是一次性的,打开后就不能再关上. </p>
<blockquote>
<ul>
<li>使用的时候就像主线程设定了好了一扇门挡住起跑线,把所有工作线程挨个释放,一头撞到门上卡住了;等到某个时机放下门,瞬间释放所有线程;</li>
</ul>
</blockquote>
<ul>
<li>设置一扇门挡住主线程,让主线程等待子线程跑完;</li>
<li>结束的时候,每一个线程到达终点就把计数器减一,直到大家都结束,再在终点释放主线程.</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">final</span> CountDownLatch startGate=<span class="keyword">new</span> CountDownLatch(<span class="number">1</span>);</span><br><span class="line"><span class="comment">// 开始的门,只需主线程一人下令countDown,因此计数器为1;</span></span><br><span class="line"><span class="keyword">final</span> CountDownLatch endGate=<span class="keyword">new</span> CountDownLatch(nThreads);</span><br><span class="line"><span class="comment">// 结束的门,需要n个子线程countDown,因此计数器为n.</span></span><br></pre></td></tr></table></figure>


<ul>
<li>完整代码<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestLatch</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">timeTasks</span><span class="params">(<span class="keyword">int</span> nThreads, <span class="keyword">final</span> Runnable task)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> CountDownLatch startGate = <span class="keyword">new</span> CountDownLatch(<span class="number">1</span>);<span class="comment">// countDown一次就能打开</span></span><br><span class="line">        <span class="keyword">final</span> CountDownLatch endGate = <span class="keyword">new</span> CountDownLatch(nThreads);<span class="comment">//countDown nThreads次才能打开(所有线程都countDown过)</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; nThreads; i++) &#123;<span class="comment">// 先全部放出去,然后一头撞在startGate上;</span></span><br><span class="line">            Thread t = <span class="keyword">new</span> Thread(() -&gt; &#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    startGate.await();<span class="comment">// 一头撞在startGate上</span></span><br><span class="line">                    <span class="keyword">try</span> &#123;</span><br><span class="line">                        task.run();</span><br><span class="line">                    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">                        endGate.countDown();<span class="comment">//每个线程countDown一次</span></span><br><span class="line">                    &#125;</span><br><span class="line">                &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                    e.printStackTrace();<span class="comment">//ignore</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">            t.start();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">long</span> start = System.currentTimeMillis();</span><br><span class="line">        System.out.println(<span class="string">"准备开始"</span>);</span><br><span class="line">        startGate.countDown();<span class="comment">// 打开开始的门</span></span><br><span class="line">        endGate.await();<span class="comment">// 主线程等待全部结束. (n次countDown结束)</span></span><br><span class="line">        System.out.println(<span class="string">"结束等待"</span>);</span><br><span class="line">        <span class="keyword">long</span> end = System.currentTimeMillis();</span><br><span class="line">        <span class="keyword">return</span> end - start;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        Runnable task = <span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">                &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                    e.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">                System.out.println(<span class="string">"running task"</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;;</span><br><span class="line">        TestLatch testLatch = <span class="keyword">new</span> TestLatch();</span><br><span class="line">        <span class="keyword">long</span> during = testLatch.timeTasks(<span class="number">10</span>, task);</span><br><span class="line">        System.out.println(<span class="string">"Runtime: "</span> + during);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h1 id="FutureTask-Callable-Runnable"><a href="#FutureTask-Callable-Runnable" class="headerlink" title="FutureTask\Callable\Runnable"></a>FutureTask<V>\Callable<V>\Runnable</h1><blockquote>
<p>FutureTask三种状态: waiting,running,completed.</p>
</blockquote>
<ul>
<li><p>Runnable</p>
<blockquote>
<p>顾名思义,有个run函数,可以run.</p>
</blockquote>
</li>
<li><p>Callable<V></p>
<blockquote>
<p>比Run多个返回值V.</p>
</blockquote>
</li>
<li><p>FutureTask<V></p>
<blockquote>
<p>声明实现的接口是Runnable和Future<V>.<br>但实际上里头有个适配器,把Runnable转成Callable.<br>而且它可以接收Callable作为构造函数的参数.<br>运行的时候直接ftask.run()即可.<br>取结果则是直接ftask.get()即可.</p>
</blockquote>
</li>
</ul>
<p>还可以把FutureTask传给Thread的构造函数\加入线程池接受调度.</p>
<p>感觉<code>FutureTask&lt;V&gt;</code>挺好用的.</p>
<p>第五章的原则总结:</p>
<blockquote>
<ol>
<li>尽量使用final;</li>
<li>不可变对象一定线程安全;<br>尽量使用不可变对象(空间换时间);</li>
<li>尽量封装,把数据封装到对象中,以便以后构造不可变或者同步策略;</li>
<li>每一个可变对象,都要考虑用锁保护;</li>
<li>保护同一个不变性条件的所有变量时,使用同一个锁;</li>
<li>注意在复合操作上加锁;</li>
<li>不武断得认为不需要同步;</li>
<li>明确地指出(注解或注释)每个类是否线程安全.</li>
</ol>
</blockquote>
<h1 id="疑问"><a href="#疑问" class="headerlink" title="疑问:"></a>疑问:</h1><ol>
<li>Collections.unmodifiableMap(xxx)<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">final</span> xxx;<span class="comment">//引用是不可变的,如果是基本类型,就是值.</span></span><br><span class="line"><span class="keyword">final</span> xxx = Collections.unmodifiableMap(xxx);</span><br><span class="line"><span class="comment">/**不但引用是不可变的,第一级寻址对象也是不可更改的.</span></span><br><span class="line"><span class="comment">调用map.put(xxx,xxx)会抛unSupported异常.</span></span><br><span class="line"><span class="comment">但显然这不是万能的,用户也可以先用get获取到对象,然后再把对象里的数据给改了.(类似于二级寻址)</span></span><br><span class="line"><span class="comment">因此里面如果存的是不可变对象,是可以的,否则还是可以改.</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure></li>
<li>ConcurrentMap: 一个线程安全的容器. 保证多线程都能访问一级寻址对象.</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://xiaoyue26.github.io/2017/02/25/java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98%E7%AC%94%E8%AE%B0-4-5%E7%AB%A0/" data-id="ck96cxpl9002jmaamftrndxcu" class="article-share-link">分享</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/java/" rel="tag">java</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-java并发编程实践笔记-1-3章" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/02/24/java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0-1-3%E7%AB%A0/" class="article-date">
  <time datetime="2017-02-24T11:42:54.000Z" itemprop="datePublished">2017-02-24</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/java/">java</a>►<a class="article-category-link" href="/categories/java/%E5%B9%B6%E5%8F%91/">并发</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/02/24/java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0-1-3%E7%AB%A0/">java并发编程实践笔记-1-3章</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
        
        <blockquote>
<p>避免多线程错误三个方法:<br>(1)不共享变量(ThreadLocal);//空间换时间<br>(2)共享变量设定为不可变(Immutable);//空间换时间<br>(3)使用同步(Synchronized).//时间换空间</p>
</blockquote>
<p>tips: </p>
<blockquote>
<p>java8stream在parallel中,不能操作非线程安全的类。</p>
</blockquote>
<h1 id="Synchronized"><a href="#Synchronized" class="headerlink" title="Synchronized"></a>Synchronized</h1><blockquote>
<p>内置锁.<br>非静态方法synchronized: 对当前对象加锁;<br>  静态方法synchronized: 对Class对象加锁.</p>
</blockquote>
<p>同步块:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">synchronized</span>(<span class="keyword">this</span>)&#123;</span><br><span class="line"><span class="comment">//do something</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>因为锁是加在某个对象上,所以叫做内置锁.线程在进入同步块的时候获得锁,出来的时候释放锁.</p>
<blockquote>
<p>释放锁的情况:</p>
</blockquote>
<ol>
<li>正常退出</li>
<li>异常退出.</li>
</ol>
<ul>
<li><p>优点:<br>同步块中的代码能作为一个原子操作.</p>
</li>
<li><p>缺点:<br>只有一个线程能获得锁.性能较低.</p>
</li>
</ul>
<h2 id="可重入"><a href="#可重入" class="headerlink" title="可重入"></a>可重入</h2><blockquote>
<p>重入: 当某个线程试图获取它自己已经持有的锁.<br><code>Synchronized</code>内置锁是可重入的,意味着线程可以多次获取自己持有的内置锁,都可以获得成功.</p>
</blockquote>
<h3 id="实现"><a href="#实现" class="headerlink" title="实现:"></a>实现:</h3><p>锁在对象里,锁中记录持有者的线程和获取计数器.<br>计数器为0时,锁被认为不被任何线程所持有;<br>当线程请求一个计数器为0的锁时,锁中记录下锁的持有者,并且将计数器置为1.如果再一次进入同步块,计数器+1,退出一次同步块计数器-1,当计数器为0,锁被释放.</p>
<h1 id="可见性"><a href="#可见性" class="headerlink" title="可见性"></a>可见性</h1><blockquote>
<p>不加任何同步控制的变量,由于指令重排,多线程等因素,可见性无法保证,读线程可能读到的不是最新的值(读到失效数据).这种级别是最低安全性.</p>
</blockquote>
<blockquote>
<p>对于大部分基本类型来说,最低安全性是可以容忍的.但对于double,long来说,由于被更新的可能是数据的一半,除非使用volatile关键字等机制,否则读出来的可能不仅是失效数据,而是一个混合了失效数据\最新数据的近乎随机的值,可能带来毁灭性的后果. </p>
</blockquote>
<h1 id="volatile"><a href="#volatile" class="headerlink" title="volatile"></a>volatile</h1><p>作用: 保持可见性<br>缺点: 不保证操作的原子性. (需要原子性,应该使用锁或原子类)<br>使用场景:</p>
<ol>
<li>boolean值,状态变量;</li>
<li>只有一个线程写,其他线程读.<br>或 写的时候不依赖原先的值(不是自增这种). </li>
</ol>
<h2 id="编译优化与变量"><a href="#编译优化与变量" class="headerlink" title="编译优化与变量"></a>编译优化与变量</h2><blockquote>
<p>jvm在server模式下对循环内没有改变的变量进行优化,将其提出循环.<br>;在client模式下则不会有这种优化.</p>
</blockquote>
<p>示例代码:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">boolean</span> otherDone;<span class="comment">//此处应该volatile</span></span><br><span class="line"><span class="keyword">while</span>(!otherDone)&#123;</span><br><span class="line"><span class="comment">//sleep</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上述代码如果不加volatile,则在server模式下可能会死锁,因为!otherDone的判断可能会被优化到循环外面.导致无限循环.</p>
<h1 id="线程封闭"><a href="#线程封闭" class="headerlink" title="线程封闭"></a>线程封闭</h1><p>不在线程间共享变量,因此可以达到线程安全.<br>例如使用ThreadLocal. </p>
<h2 id="栈封闭"><a href="#栈封闭" class="headerlink" title="栈封闭"></a>栈封闭</h2><p>线程封闭的特例.<br>由于每个线程有自己的栈,而局部变量在栈上,因此只使用局部变量的话,就是栈封闭.(达到线程安全)<br>由于基本类型无法获取引用,因此基本类型无法逸出,是安全的;<br>而对象引用可能逸出,因此需要编程人员自行保证不会逸出.<br>(不把引用乱传递)</p>
<h1 id="发布与逸出"><a href="#发布与逸出" class="headerlink" title="发布与逸出"></a>发布与逸出</h1><ol>
<li>线程安全的叫发布;</li>
<li>不安全的叫逸出.</li>
</ol>
<p>安全发布的两种途径:</p>
<blockquote>
<ol>
<li>发布的对象是不可变的;</li>
<li>发布的时候使用同步方法. </li>
</ol>
</blockquote>
<h2 id="途径1"><a href="#途径1" class="headerlink" title="途径1"></a>途径1</h2><p>其中,不可变的方法:</p>
<blockquote>
<p>private final,且返回clone或Arrays.copy的值.</p>
</blockquote>
<h2 id="途径2"><a href="#途径2" class="headerlink" title="途径2"></a>途径2</h2><p>把不可变对象安全发布的方法:</p>
<blockquote>
<ol>
<li>静态初始化函数中初始化一个对象引用;</li>
<li>把对象引用存放到volatile或AtomicReference;</li>
<li>把对象引用存放到正确构造对象的final类型域;</li>
<li>把对象引用存放到一个由锁保护的域中.(如放入同步容器中,包括HashTable,Vector,sychronizedMap,synchronizedMap,concurrentMap,CopyOnWriteArrayList,BlockingQueue,ConcurrentLinkedQueue).</li>
</ol>
</blockquote>
<ul>
<li>方法1: 静态初始化函数<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> Holder holder=<span class="keyword">new</span> Holder(<span class="number">42</span>);</span><br></pre></td></tr></table></figure>

</li>
</ul>
<p>对于不可变对象,安全发布后就可以用了;<br>对于可变对象,安全发布以后还需要安全得使用,也就是使用的时候也需要同步.</p>
<ul>
<li>总结:<blockquote>
<p>不可变对象: 任意发布<br>事实不可变: 安全发布<br>可变: 安全发布且安全使用.</p>
</blockquote>
</li>
</ul>
<h1 id="建议"><a href="#建议" class="headerlink" title="建议"></a>建议</h1><ol>
<li>尽量使用final,private.<br>其中final能保证初始化值过程中的安全性.</li>
</ol>
<h1 id="疑问"><a href="#疑问" class="headerlink" title="疑问"></a>疑问</h1><ol>
<li>immutable和threadLocal选哪个?</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://xiaoyue26.github.io/2017/02/24/java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0-1-3%E7%AB%A0/" data-id="ck96cxplb002rmaam7x6zgt9a" class="article-share-link">分享</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/java/" rel="tag">java</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-java泛型" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/02/12/java%E6%B3%9B%E5%9E%8B/" class="article-date">
  <time datetime="2017-02-12T11:41:36.000Z" itemprop="datePublished">2017-02-12</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/java/">java</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/02/12/java%E6%B3%9B%E5%9E%8B/">java泛型</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
        
        <blockquote>
<p>上界<code>&lt;? extends T&gt;</code><br>不能往里存，只能往外取</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Plate&lt;? extends Fruit&gt;p&#x3D; new Plate&lt;Apple&gt;(new Apple());</span><br><span class="line">&#x2F;&#x2F;  赋值后,p为一个容器,容器元素类型为CAP#1,是一种Fruit的子类.</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 写:</span><br><span class="line">&#x2F;&#x2F;不能存入任何元素:</span><br><span class="line">p.set(new Fruit());&#x2F;&#x2F;Error 无法确定CAP#1能否接住Fruit.</span><br><span class="line">p.set(new Apple());&#x2F;&#x2F;Error </span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 读:</span><br><span class="line">&#x2F;&#x2F; 读出来的东西只能存放在Fruit及其基类中:</span><br><span class="line">Fruit new1&#x3D;p.get(); &#x2F;&#x2F; 可以,CAP#1可以存放到Fruit中</span><br><span class="line">Object new2&#x3D;p.get(); &#x2F;&#x2F; 可以</span><br><span class="line">Apple new3&#x3D;p.get();&#x2F;&#x2F;Error</span><br></pre></td></tr></table></figure>

<blockquote>
<p>下界<code>&lt;? super T&gt;</code><br>不影响往里存，但往外取只能放在Object对象里</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Plate&lt;? super Fruit&gt;p&#x3D;new Plate&lt;Fruit&gt;(new Fruit());</span><br><span class="line">&#x2F;&#x2F;  赋值后,p为一个容器,容器元素类型为CAP#1,是一种Fruit的基类.</span><br><span class="line">&#x2F;&#x2F; 写:</span><br><span class="line">p.set(new Fruit());&#x2F;&#x2F; 可以, CAP#1可以接住Fruit</span><br><span class="line">p.set(new Apple());&#x2F;&#x2F;基类指针可以存放子类对象</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 读:</span><br><span class="line">Apple new1&#x3D;p.get();&#x2F;&#x2F;Error 不确定Apple能否接住CAP#1</span><br><span class="line">Fruit new2&#x3D;p.get();&#x2F;&#x2F;Error</span><br><span class="line">Object new3&#x3D;p.get();</span><br></pre></td></tr></table></figure>

<blockquote>
<p>PECS原则<br>（Producer Extends Consumer Super）原则</p>
</blockquote>
<ol>
<li>频繁往外读取内容的，适合用上界Extends。</li>
<li>经常往里插入的，适合用下界Super。</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://xiaoyue26.github.io/2017/02/12/java%E6%B3%9B%E5%9E%8B/" data-id="ck96cxpld002ymaamf5za4qe2" class="article-share-link">分享</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/java/" rel="tag">java</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-java-jdk源码阅读" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/02/11/java-jdk%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/" class="article-date">
  <time datetime="2017-02-11T11:40:34.000Z" itemprop="datePublished">2017-02-11</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/java/">java</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/02/11/java-jdk%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/">java jdk源码阅读</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
        
        <h1 id="Collections"><a href="#Collections" class="headerlink" title="Collections"></a>Collections</h1><p>sort,shuffle,等各种集合运算.<br>返回并发集合,同步容器,不可修改集合,等等.</p>
<h1 id="Arrays"><a href="#Arrays" class="headerlink" title="Arrays"></a>Arrays</h1><p>fill,等等. </p>
<h1 id="Math-StrictMath"><a href="#Math-StrictMath" class="headerlink" title="Math. StrictMath"></a>Math. StrictMath</h1><p>addExact<br>subExact<br>在加减溢出时可以抛异常.(Math.abs不抛异常)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; 位运算小技巧</span><br><span class="line">&#x2F;&#x2F; 1. x和y异号 &lt;&#x3D;&gt; 异或后&lt;0 </span><br><span class="line">(1)x^y &lt;0 </span><br><span class="line">&#x2F;&#x2F; 异号定义: 都不等于0, 异号.</span><br><span class="line"></span><br><span class="line">(2)x和y同号 &#x3D;&gt; x^y &gt;&#x3D;0 </span><br><span class="line">一般使用(1).</span><br><span class="line">&#x2F;&#x2F; 2. &amp;</span><br><span class="line">(1) x和y均小于0   &lt;&#x3D;&gt; x&amp;y &lt; 0 </span><br><span class="line">(2) x和y均大于0  &#x3D;&gt;  x&amp;y&gt;&#x3D;0</span><br><span class="line">(3) x和y异号 &#x3D;&gt; x&amp;y&gt;&#x3D;0</span><br><span class="line">&#x2F;&#x2F; (2),(3)难以区分,一般使用(1) .</span><br></pre></td></tr></table></figure>


      
    </div>
    <footer class="article-footer">
      <a data-url="http://xiaoyue26.github.io/2017/02/11/java-jdk%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/" data-id="ck96cxpl7002bmaam82b4e28b" class="article-share-link">分享</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/java/" rel="tag">java</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-HTTP-method-规范" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/02/04/HTTP-method-%E8%A7%84%E8%8C%83/" class="article-date">
  <time datetime="2017-02-04T11:36:12.000Z" itemprop="datePublished">2017-02-04</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/http/">http</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/02/04/HTTP-method-%E8%A7%84%E8%8C%83/">HTTP method 规范</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
        
        <h1 id="HTTP-method-规范"><a href="#HTTP-method-规范" class="headerlink" title="HTTP method 规范"></a>HTTP method 规范</h1><ul>
<li>创建题目<br>/api/questions<br>POST</li>
</ul>
<ul>
<li><p>更新题目<br>/api/questions<br>PUT</p>
</li>
<li><p>删除题目<br>/api/questions<br>DELETE</p>
</li>
</ul>
<ul>
<li>获取题目<br>/api/questions<br>GET</li>
</ul>
<h1 id="HTTP4种方法的用法规范"><a href="#HTTP4种方法的用法规范" class="headerlink" title="HTTP4种方法的用法规范"></a>HTTP4种方法的用法规范</h1><ul>
<li>POST(create) </li>
<li>PUT(createOrUpdate) </li>
<li>GET(get) </li>
<li>DELETE(delete)</li>
</ul>
<blockquote>
<p>解释一下PUT的createOrUpdate:<br>POST 和 PUT 都可以用于create, 不同的地方是PUT是指定id的, 如果该id对应的资源服务端已经存在则是update, 否则就是create. 而POST是不带id的， 每次POST都会创建一个新对象.</p>
</blockquote>
<p>PUT的例子如收藏功能<br>所以PUT是幂等的， POST不是幂等的.<br>另外DELETE也是幂等的.<br>GET, DELETE 不能带payload.</p>
<h2 id="层次化url"><a href="#层次化url" class="headerlink" title="层次化url:"></a>层次化url:</h2><blockquote>
<p>GET /api/courses/12/questions/101 的接口表示获取课程Id=12 的一道Id=101的题目</p>
</blockquote>
<h2 id="服务端无request-session"><a href="#服务端无request-session" class="headerlink" title="服务端无request session"></a>服务端无request session</h2><p>服务端不记录客户端一次会话过程的上下文信息, 如果业务上需要也是由客户端来记录上下文信息， 并在每一次请求中以参数(或cookie)的方式带上<br>所以服务端无状态</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://xiaoyue26.github.io/2017/02/04/HTTP-method-%E8%A7%84%E8%8C%83/" data-id="ck96cxpkg0005maam0li90jo7" class="article-share-link">分享</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/http/" rel="tag">http</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/restful/" rel="tag">restful</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-hive笔记" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/01/22/hive%E7%AC%94%E8%AE%B0/" class="article-date">
  <time datetime="2017-01-22T11:34:41.000Z" itemprop="datePublished">2017-01-22</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/hadoop/">hadoop</a>►<a class="article-category-link" href="/categories/hadoop/hive/">hive</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/01/22/hive%E7%AC%94%E8%AE%B0/">hive笔记</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
        
        <h1 id="hive-小技巧"><a href="#hive-小技巧" class="headerlink" title="hive 小技巧"></a>hive 小技巧</h1><p>GROUP BY xxx WITH CUBE的时候,要区分是维度是total_count还是null,<br>可以用GROUPING__ID.<br>当GROUPING__ID的二进制在某列为0,则为total_count,否则是具体值导致的null. (换句话说就是需要二进制操作,代码会很复杂,需要udf)</p>
<h1 id="hive-1-2-1-bug"><a href="#hive-1-2-1-bug" class="headerlink" title="hive 1.2.1 bug:"></a>hive 1.2.1 bug:</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">1. alter table temp.feng_test1  add COLUMNs (col2 string);</span><br><span class="line">增加一列后,无法读取新的一列的数据.</span><br><span class="line"></span><br><span class="line">现象: 使用alter语句增加一列,重新insert overwrite数据后,新增列的数据始终为null.</span><br><span class="line"></span><br><span class="line">解决方案: </span><br><span class="line">1. 对于外部表,可以通过重建整个表结构解决.</span><br><span class="line">首先保存建表语句,然后drop table,最后重建整个表即可.</span><br><span class="line"></span><br><span class="line">2. 对于有分区的内部表,可以通过重建分区解决,首先使用drop partition语句删除分区和数据,然后重跑这个分区的数据(或者事先备份好数据然后add partition). 注意,区别于直接使用insert overwrite partition语句.</span><br><span class="line">3. 对于无分区的内部表,暂无特别好的办法,只能先把表数据备份到另一个目录,(备份表结构和数据)然后drop table,最后重建表即可.注意,区别于直接使用insert overwrite table语句.</span><br></pre></td></tr></table></figure>

<h1 id="hive传参数"><a href="#hive传参数" class="headerlink" title="hive传参数:"></a>hive传参数:</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive -d DATE&#x3D;1 -e &#39;select $&#123;DATE&#125;&#39;</span><br></pre></td></tr></table></figure>

<h1 id="hive-更新函数"><a href="#hive-更新函数" class="headerlink" title="hive 更新函数:"></a>hive 更新函数:</h1><blockquote>
<p>注意事项: DROP function xxx时,得保证创建函数时用的jar还在,不然可能导致更新函数不成功,每次运行时还是会加载原有的jar包.</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">SELECT thriftparser(answerresults, &quot;com.fenbi.ape.hive.serde.thriftobject.conan.AnswerResults&quot;)</span><br><span class="line">FROM ape.ori_mysql_ape_conan_task_task_report_da</span><br><span class="line">limit 10</span><br><span class="line">;</span><br><span class="line"></span><br><span class="line">drop function thriftparser;</span><br><span class="line"></span><br><span class="line">create function thriftparser AS &#39;com.fenbi.ape.hive.serde.ThriftSerdeUniversalUDF&#39; USING JAR &#39;hdfs:&#x2F;&#x2F;f04&#x2F;lib&#x2F;ape-serde-1.1-SNAPSHOT.jar&#39;;</span><br><span class="line"></span><br><span class="line">reload function;</span><br><span class="line">reload functions;</span><br></pre></td></tr></table></figure>


<p>从8088获取hive查询的详细语句：<br><a href="http://f04:8088/proxy/application_1465276959835_417313/mapreduce/conf/job_1465276959835_417313" target="_blank" rel="noopener">http://f04:8088/proxy/application_1465276959835_417313/mapreduce/conf/job_1465276959835_417313</a><br>具体操作方法是先进入job的ApplicationMaster，具体jobid链接，左侧configuration，然后在右侧下方小字的key输入框，输入hive.query.string进行查询即可。</p>
<p>突然想到，对数据量小的表可以先做Distinct,数据量大的表可能得用group by。<br>前者用一个reduce即可，后者可以用多个reduce,跑得快一点。<br><a href="http://idea.lanyus.com/" target="_blank" rel="noopener">http://idea.lanyus.com/</a><br>需要看的教程:<br>[<a href="https://issues.apache.org/jira/browse/HIVE-591]" target="_blank" rel="noopener">https://issues.apache.org/jira/browse/HIVE-591]</a><br><a href="http://git-scm.com/book/zh/v2" target="_blank" rel="noopener">http://git-scm.com/book/zh/v2</a><br><a href="http://pcottle.github.io/learnGitBranching/?demo" target="_blank" rel="noopener">http://pcottle.github.io/learnGitBranching/?demo</a><br><code>smartGit</code><br><code>derby</code>数据库是什么? 就是一个轻量级的数据库 好多apache项目都默认自带。</p>
<p>查看所有函数/查看指定函数用法。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SHOW FUNCTIONS; </span><br><span class="line">desc function find_in_set;</span><br></pre></td></tr></table></figure>

<ul>
<li><code>sql code style flow</code>:<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span></span><br><span class="line"><span class="keyword">FROM</span></span><br><span class="line"><span class="keyword">WHERE</span></span><br><span class="line"><span class="keyword">GROUP</span></span><br><span class="line"><span class="keyword">HAVING</span></span><br></pre></td></tr></table></figure>

</li>
</ul>
<p><code>hbase</code>是直接查询(KV)；<br><code>hive</code>会转化为<code>map-reduce</code>任务。<br><code>pig</code>是定制<code>reduce</code>部分。</p>
<p><code>hive</code>使用列式存储，使用<code>dt=?</code>指定<code>partition</code>会加快查询速度，像索引一样。<a href="http://blog.csdn.net/dc_726/article/details/41143175" target="_blank" rel="noopener">列式存储基础知识</a><br><img src="http://img.blog.csdn.net/20141115094556515?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZGNfNzI2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="列式存储天生适合压缩"></p>
<ul>
<li>列式存储天生适合压缩(相同数据类型)</li>
<li>列式存储数据库对分布式支持友好</li>
</ul>
<p><img src="http://img.blog.csdn.net/20141115094806194?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZGNfNzI2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="投影等操作的对比"></p>
<ul>
<li>自然连接是一种去重复列后的等值连接，它要求两个关系中进行比较的分量必须是相同的属性组，并且在结果中把重复的属性列去掉。而等值连接并不去掉重复的属性列。</li>
<li>选择-&gt;限制-&gt;<code>where</code>—&gt;指定行;投影-&gt;<code>select</code>-&gt;指定列。</li>
</ul>
<p>列式存储查询流程:<br><img src="http://img.blog.csdn.net/20141115094934319?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZGNfNzI2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="列式存储查询流程"></p>
<ol>
<li>根据<code>where</code>的行限制,去字典表里找到字符串对应数字(只进行一次字符串比较)。</li>
<li>用数字去列表里匹配，匹配上的位置设为1。</li>
<li>把不同列的匹配结果进行位运算得到符合所有条件的记录下标。</li>
<li>使用这个下标，再根据<code>select</code>语句中指定的列,组装出最终的结果集。</li>
</ol>
<hr>
<p><code>$HOME/.hiverc</code>目录下可设定启动脚本。<br>如<code>set hive.metastore.warehouse.dir/=...</code></p>
<p>查看<code>hive</code>版本：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">hive&gt;</span><span class="bash"><span class="built_in">set</span> hive.hwi.war.file;</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">echo</span> <span class="variable">$HIVE_HOME</span></span></span><br><span class="line">/home/maintain/hive/apache-hive-0.14.0-bin</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">终止:</span></span><br><span class="line">ctrl+c (不是win+c)</span><br><span class="line">两次。</span><br><span class="line">若未执行完毕则终止的是jvm;</span><br><span class="line">若执行完毕则返回结果在文件系统里，切断的是与文件系统的联系。</span><br></pre></td></tr></table></figure>

<p>设定变量:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">set foo=bar2;</span><br><span class="line">set hivevar:foo=bar2; #等效</span><br><span class="line">set foo;# 查看结果</span><br></pre></td></tr></table></figure>

<p><code>hive</code>中可使用<code>shell</code>命令等:（也是分号结尾）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">! /bin/echo "hello world";</span><br><span class="line">! pwd</span><br><span class="line">dfs -ls / ;</span><br><span class="line">-- copyright ... #注释以`--`开头</span><br></pre></td></tr></table></figure>

<p>注释以<code>--</code>开头 比较特殊。</p>
<p>各种分隔符<code>p46</code>。</p>
<p>一个概念：<code>读时模式</code>：<br>传统数据库是<code>写时模式</code>，在写入的时候进行模式检查、有效性验证。<br><code>hive</code>是<code>读时模式</code>，就是加载数据的时候才进行验证，尽可能恢复数据的有效性和合法性。对于错误的类型返回<code>null</code>,如数值类型中存放了字符串。</p>
<p><code>hive</code>不支持行级操作、不支持事务。</p>
<p>可以重复使用<code>Use</code>指令，<code>hive</code>没有嵌套数据库。</p>
<p>递归删除数据库<br><code>drop database if exists xxxbase cascade;</code></p>
<p>支持正则:(<code>show databases</code>里用不了)<br><code>show tables &#39;empl.*&#39;;</code><br>mysql 里是:<code>show tables like &#39;%empl%&#39; ;</code></p>
<p>输出表信息:<br><code>describe formatted mydb.employees;</code></p>
<p><code>set hive.stats.reliable=false</code>是什么含义，设定为暂时不可用?<br>这个是把状态收集器关掉，效果是在insert overwrite的时候，不去重。</p>
<p> 查看是管理表还是外部表:<br> <code>describe formatted mydb.employees;</code><br>输出信息的中部有这一项(<code>table_type</code>).</p>
<p>创建相同表结构但没有数据的表:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">not</span> <span class="keyword">exists</span> mydb.employees3</span><br><span class="line"><span class="keyword">Like</span> mydb.employees</span><br><span class="line">Location <span class="string">'/path/to/data'</span>;</span><br></pre></td></tr></table></figure>

<p>创建带分区的表:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> employees(</span><br><span class="line"><span class="keyword">name</span> <span class="keyword">STRING</span>,</span><br><span class="line">salary <span class="built_in">Float</span>,</span><br><span class="line">subordinates <span class="built_in">Array</span>&lt;<span class="keyword">String</span>&gt;,</span><br><span class="line">deductions <span class="keyword">map</span>&lt;<span class="keyword">string</span>,<span class="built_in">float</span>&gt;,</span><br><span class="line">address <span class="keyword">struct</span>&lt;street:<span class="keyword">string</span>,</span><br><span class="line">               city:<span class="keyword">string</span>,</span><br><span class="line">               state:<span class="keyword">string</span>,</span><br><span class="line">               zip:<span class="built_in">int</span>&gt;</span><br><span class="line">)</span><br><span class="line">partitioned <span class="keyword">by</span> (country <span class="keyword">string</span>,state <span class="keyword">string</span>);</span><br></pre></td></tr></table></figure>
<p><code>hive</code>会按照分区创建目录。然后不在字段中存储分区信息。</p>
<p>查看已有的分区设置:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">show</span> <span class="keyword">partitions</span> tmp_tutor_user_profile;</span><br></pre></td></tr></table></figure>

<p>设置查询时是否必须指定分区:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.mapred.mode=<span class="keyword">strict</span>;</span><br><span class="line"><span class="keyword">set</span> hive.mapred.mode=nonstrict;</span><br></pre></td></tr></table></figure>

<p>载入数据的方式创建分区:<code>p60</code></p>
<p><code>hive</code>不储存建表语句?（<code>Navicat for MySQL</code>中的对象信息）。<br><code>show create table test1</code> 里有.</p>
<p>增加分区信息：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> log_messages </span><br><span class="line"><span class="keyword">add</span> <span class="keyword">partition</span></span><br><span class="line">(<span class="keyword">year</span>=<span class="number">2015</span>,<span class="keyword">month</span>=<span class="number">1</span>,<span class="keyword">day</span>=<span class="number">2</span>)</span><br><span class="line">location <span class="string">'hdfs://master_server/data/log/2012/01/02'</span>;</span><br></pre></td></tr></table></figure>

<p><code>emailUtils</code></p>
<ul>
<li>大部分<code>alter</code>操作不会改变数据，只改变元数据。<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> log_messages</span><br><span class="line"><span class="keyword">partition</span>(<span class="keyword">year</span>=<span class="number">2012</span>,<span class="keyword">month</span>=<span class="number">12</span>,<span class="keyword">day</span>=<span class="number">2</span>)</span><br><span class="line"><span class="keyword">set</span> location <span class="string">'s3n://ourbucket/logs/2011/01/02'</span>;</span><br></pre></td></tr></table></figure>
上述命令不会把数据从旧的路径转移或者删除。</li>
</ul>
<hr>
<ul>
<li><p>例外：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> log_messages </span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">if</span> <span class="keyword">exists</span> <span class="keyword">partition</span></span><br><span class="line">(<span class="keyword">year</span>=<span class="number">2012</span>,<span class="keyword">month</span>=<span class="number">12</span>,<span class="keyword">day</span>=<span class="number">2</span>);</span><br></pre></td></tr></table></figure>
<p>上述语句会删除管理表中的数据，而不会删除外部表中的数据。</p>
</li>
<li><p>对字段进行重命名、修改位置、类型和注释：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> log_messages</span><br><span class="line"><span class="keyword">change</span> <span class="keyword">column</span> hms hours_minutes_secends <span class="built_in">INT</span></span><br><span class="line"><span class="keyword">comment</span> <span class="string">'the hours,minutes and seconds part of the timestamp'</span></span><br><span class="line"><span class="keyword">after</span> severity;</span><br></pre></td></tr></table></figure>
</li>
<li><p>装载数据:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">load</span> <span class="keyword">data</span> <span class="keyword">local</span> inpath <span class="string">'$&#123;env:HOME&#125;/california-employees'</span></span><br><span class="line">overwrite <span class="keyword">into</span> <span class="keyword">table</span> employees</span><br><span class="line"><span class="keyword">partition</span> (country=<span class="string">'US'</span>,state=<span class="string">'CA'</span>);</span><br></pre></td></tr></table></figure>
<p>如果分区目录不存在，命令会先创建分区目录然后再将目录装载(拷贝)到该目录下。<code>hive</code>会检查文件格式是否与表结构相符，但不会检查数据是否和表模式匹配。(读时模式)</p>
</li>
</ul>
<p>从<code>hdfs</code>中装载数据时,不使用<code>local</code>关键字。</p>
<p><code>p133</code>中? 存疑. <code>into</code>? <code>table</code>?<br>应该是into.</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">load</span> <span class="keyword">data</span> <span class="keyword">local</span> inpath <span class="string">'log2.txt'</span> <span class="keyword">into</span> weblogs </span><br><span class="line"><span class="keyword">partition</span>(<span class="number">20110102</span>);</span><br></pre></td></tr></table></figure>

<ul>
<li><p>动态分区</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> employees</span><br><span class="line"><span class="keyword">partition</span> (country,state)</span><br><span class="line"><span class="keyword">select</span> ..., se.cnty, se.st</span><br><span class="line"><span class="keyword">from</span> staged_employees se;</span><br></pre></td></tr></table></figure>
<p>混合动态和静态分区:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> employees</span><br><span class="line"><span class="keyword">partition</span> (country=<span class="string">'US'</span>,state)</span><br><span class="line"><span class="keyword">select</span> ..., se.cnty, se.st</span><br><span class="line"><span class="keyword">from</span> staged_employees se</span><br><span class="line"><span class="keyword">where</span> se.cnty=<span class="string">'US'</span></span><br><span class="line">;</span><br></pre></td></tr></table></figure>
<p>静态分区必须在动态分区前。</p>
</li>
<li><p>属性设定:</p>
<table>
   <tr>
    <td>属性名称</td>
    <td>缺省值</td>
    <td>描述</td>
 </tr>
 <tr>
    <td>hive.exec.dynamic</td>
    <td>false</td>
    <td>设置true即开启动态分区功能</td>
 </tr>
 <tr>
    <td>hive.exec.dynamic.mode</td>
    <td>strict</td>
    <td>nonstrict表示运行所有分区都是动态的</td>
 </tr>
 <tr>
    <td>hive.exec.max.dynamic.partitions.pernode</td>
    <td>100</td>
    <td>每个mapper或reducer可以创建的最大动态分区个数</td>
 </tr>
 <tr>
    <td>hive.exec.max.dynamic.partitions</td>
    <td>+1000</td>
    <td>一个语句可以创建的最大动态分区个数</td>
 </tr>
 <tr>
    <td>hive.exec.max.created.files</td>
    <td>100000</td>
    <td>全局可以创建的最大文件个数</td>
 </tr>
</table>
</li>
<li><p>导出数据</p>
</li>
</ul>
<ol>
<li>格式相同:<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -cp source_path target_path</span><br></pre></td></tr></table></figure></li>
<li>格式不同:<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">local</span> <span class="keyword">directory</span> <span class="string">'tmp/ca_employees'</span></span><br><span class="line"><span class="keyword">select</span> <span class="keyword">name</span>, salary, address</span><br><span class="line"><span class="keyword">from</span> employees</span><br><span class="line"><span class="keyword">where</span> se.state=<span class="string">'CA'</span></span><br><span class="line">;</span><br></pre></td></tr></table></figure></li>
<li>多输出目录:<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">from staged_employees se</span><br><span class="line">    <span class="keyword">insert</span> overwrite <span class="keyword">directory</span> <span class="string">'/tmp/or_employees'</span></span><br><span class="line">     <span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">where</span> se.cty=<span class="string">'US'</span> <span class="keyword">and</span> se.st=<span class="string">'OR'</span></span><br><span class="line">    <span class="keyword">insert</span> overwrite <span class="keyword">directory</span> <span class="string">'/tmp/ca_employees'</span></span><br><span class="line">     <span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">where</span> se.cty=<span class="string">'US'</span> <span class="keyword">and</span> se.st=<span class="string">'CA'</span></span><br><span class="line">    <span class="keyword">insert</span> overwrite <span class="keyword">directory</span> <span class="string">'/tmp/il_employees'</span></span><br><span class="line">     <span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">where</span> se.cty=<span class="string">'US'</span> <span class="keyword">and</span> se.st=<span class="string">'IL'</span></span><br><span class="line">;</span><br></pre></td></tr></table></figure>


</li>
</ol>
<ul>
<li>查看结果文件内容:<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">! ls /tmp/ca_employees;</span><br><span class="line">! cat /tmp/ca_employees/000000_0 ;</span><br></pre></td></tr></table></figure>

</li>
</ul>
<p>取整:<code>round (salary)</code><br>数学函数<code>p82</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">byte</span> <span class="keyword">int</span> <span class="keyword">short</span> <span class="keyword">long</span> <span class="number">1</span>,<span class="number">2</span>,<span class="number">4</span>,<span class="number">8</span></span><br><span class="line"><span class="keyword">boolean</span> <span class="keyword">char</span> <span class="keyword">float</span> <span class="keyword">double</span> <span class="number">1</span>,<span class="number">2</span>,<span class="number">4</span>,<span class="number">8</span></span><br></pre></td></tr></table></figure>

<ul>
<li>部分内置函数<table>
   <tr>
    <td>返回值类型</td>
    <td>样式</td>
    <td>描述</td>
 </tr>
 <tr>
    <td>type</td>
    <td>cast(expr as type)</td>
    <td>把expr转换为type类型</td>
 </tr>
  <tr>
    <td>string</td>
    <td>concat(binary s1,binary s2,...)</td>
    <td>拼接字符串</td>
 </tr>
 <tr>
    <td>string</td>
    <td>concat_ws(string separator, string s1,string s2,...)</td>
    <td>使用指定分隔符拼接字符串</td>
 </tr>
</table>

</li>
</ul>
<p><code>set hive.exec.mode.local.auto;</code>这个值为什么是<code>false</code>?</p>
<p>由于浮点数的不准确性，与钱有关或者涉及到比较的关键数字都不使用浮点数，使用<code>string</code>.</p>
<ul>
<li>正则<ul>
<li><code>like</code>使用<code>sql</code>通配符(<code>%abc%</code> )</li>
<li><code>Rlike</code>使用<code>java</code>正则表达式(<code>.*(abc).*</code>)</li>
</ul>
</li>
</ul>
<hr>
<ul>
<li><p>聚合函数、表连接:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="keyword">year</span>(ymd), <span class="keyword">avg</span>(price_close) <span class="keyword">from</span> stocks</span><br><span class="line"><span class="keyword">where</span> <span class="keyword">exchange</span>=<span class="string">'NASDAQ'</span> <span class="keyword">AND</span> symbol=<span class="string">'AAPL'</span></span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> <span class="keyword">year</span>(ymd)</span><br><span class="line"><span class="keyword">having</span> <span class="keyword">avg</span>(price_close)&gt;<span class="number">50.0</span></span><br><span class="line">;</span><br><span class="line"><span class="comment"># 注释:'--'</span></span><br><span class="line"><span class="comment">-- inner join: 表应从小到大排列以便hive优化;</span></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> a.ymd, b.price_close</span><br><span class="line"><span class="keyword">from</span> stocks a <span class="keyword">join</span> stocks b <span class="keyword">on</span> a.ymd=b.ymd</span><br><span class="line"><span class="keyword">where</span> a.symbol=<span class="string">'APPL'</span> </span><br><span class="line"><span class="keyword">AND</span> b.symbol=<span class="string">'IBM'</span></span><br><span class="line">;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- left outer join 左外连接</span></span><br><span class="line"><span class="comment"># 左表中符合where子句的所有记录将返回</span></span><br><span class="line"><span class="comment"># 右表中不符合on连接的列将返回NULL</span></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> a.ymd, b.price_close</span><br><span class="line"><span class="keyword">from</span> stocks a <span class="keyword">left</span> <span class="keyword">outer</span> <span class="keyword">join</span> dividend b <span class="keyword">on</span> a.ymd=b.ymd</span><br><span class="line"><span class="keyword">where</span> a.symbol=<span class="string">'APPL'</span> </span><br><span class="line">;</span><br><span class="line"><span class="comment">-- 执行顺序, 先执行join,再使用where进行过滤。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 嵌套select:</span></span><br><span class="line"><span class="keyword">select</span> s.*, d.* <span class="keyword">from</span></span><br><span class="line">(<span class="keyword">select</span> * <span class="keyword">from</span> stocks <span class="keyword">where</span> ...) s</span><br><span class="line"><span class="keyword">left</span> <span class="keyword">outer</span> <span class="keyword">join</span></span><br><span class="line">(<span class="keyword">select</span> * <span class="keyword">from</span> dividend where...) d</span><br><span class="line"><span class="keyword">on</span> s.ymd=d.ymd</span><br><span class="line">;</span><br><span class="line"></span><br><span class="line"><span class="comment">--类似的, 右外连接 right outer join</span></span><br><span class="line"><span class="comment">-- 全连接 full outer join</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 左半开连接: left semi-join</span></span><br><span class="line"><span class="keyword">select</span> s.* <span class="keyword">from</span> stocks s</span><br><span class="line"><span class="keyword">left</span> <span class="keyword">semi</span> <span class="keyword">join</span></span><br><span class="line">dividends d </span><br><span class="line"><span class="keyword">on</span> s.ymd=d.ymd <span class="keyword">and</span> s.symbol=d.symbol</span><br><span class="line">;</span><br><span class="line"><span class="comment">#返回左边表的记录，用on中的条件进行过滤。</span></span><br><span class="line"><span class="comment">#比inner join(直接join)更高效，但不能返回右表中的数据。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 笛卡尔积: 没有on语句的join</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><code>map-side join</code><br>通过设置<code>set hive.auto.convert.join=true;</code>开启。</p>
</li>
<li><p><code>distribute by</code><br><code>distribute by</code>控制<code>mapper</code>的输出在<code>reducer</code>中是如何划分的。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> stocks s</span><br><span class="line"><span class="keyword">distribute</span> <span class="keyword">by</span> s.symbol</span><br><span class="line"><span class="keyword">sort</span> <span class="keyword">by</span> s.symbol <span class="keyword">asc</span>, s.ymd <span class="keyword">asc</span></span><br><span class="line">;</span><br></pre></td></tr></table></figure>
<p>此处<code>distribute by</code>指定具有相同股票交易码的记录会分发到同一个<code>reducer</code>中进行处理。<code>cluster by s.symbol</code>相当于<code>distribute by s.symbol sort by s.symbol desc</code>的简写,只支持降序。</p>
</li>
</ul>
<p><code>order by</code>保证全局有序;<br><code>sort by</code>只保证每个<code>reducer</code>的任务局部有序。</p>
<ul>
<li><p>抽样查询</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> numbers </span><br><span class="line"><span class="keyword">tableSample</span>(<span class="keyword">bucket</span> <span class="number">3</span> <span class="keyword">out</span> <span class="number">10</span> <span class="keyword">on</span> <span class="keyword">rand</span>())</span><br><span class="line">s;</span><br><span class="line"><span class="comment">-- 指定列分桶:</span></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> numbers </span><br><span class="line"><span class="keyword">tableSample</span>(<span class="keyword">bucket</span> <span class="number">3</span> <span class="keyword">out</span> <span class="number">10</span> <span class="keyword">on</span> <span class="built_in">number</span>)</span><br><span class="line">s;</span><br></pre></td></tr></table></figure>
</li>
<li><p>数据块抽样(百分比)</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> numbersflat <span class="keyword">TableSample</span>(<span class="number">0.1</span> <span class="keyword">percent</span>)</span><br><span class="line">s;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 最小抽样单元是一个hdfs数据，所以数据大小小于128MB时会返回所有数据</span></span><br><span class="line"><span class="comment">-- 不一定适用于所有文件格式</span></span><br></pre></td></tr></table></figure>

</li>
</ul>
<p>哈斯分区是什么? <code>p115</code><br>分隔符的可读性为何这么低还是不清楚。（?）</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 两种顺序调换的意义?</span></span><br><span class="line">from...insert...select...</span><br><span class="line">from...select...</span><br></pre></td></tr></table></figure>


<p>示例文件夹:<br><code>/Users/xiaoyue26/Documents/pipe_warehouse/solar/dwSolarUserStat</code></p>
<ul>
<li>索引<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">Index</span> employees_index</span><br><span class="line"><span class="keyword">on</span> <span class="keyword">Table</span> employees (country)</span><br><span class="line"><span class="keyword">as</span> <span class="string">'org.apache.hadoop.hive.ql.index.compact.CompactIndexHandler'</span></span><br><span class="line"><span class="keyword">with</span> <span class="keyword">Deferred</span> <span class="keyword">Rebuild</span> <span class="comment">#意思不要立刻开始创建索引的数据,只是先声明一个索引</span></span><br><span class="line"><span class="comment">-- 新索引呈空白状态</span></span><br><span class="line">IDXproperties (<span class="string">'creator'</span>=<span class="string">'me'</span>, <span class="string">'created_at'</span>=<span class="string">'some_time'</span>)</span><br><span class="line"><span class="keyword">in</span> <span class="keyword">table</span> employees_index_table <span class="comment">#可选 也可以把索引建成一个文件</span></span><br><span class="line">partitioned <span class="keyword">by</span> (country, <span class="keyword">name</span>)</span><br><span class="line"><span class="keyword">comment</span> <span class="string">'Employees indexed by country and name.'</span></span><br><span class="line">;</span><br></pre></td></tr></table></figure></li>
</ul>
<ol>
<li>排重后值较少的列可使用<code>Bitmap</code>索引(<code>As &#39;BITMAP&#39;</code>)；</li>
<li>重建索引:<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">index</span> employees_index</span><br><span class="line"><span class="keyword">on</span> <span class="keyword">table</span> employees</span><br><span class="line"><span class="keyword">partition</span> (country=<span class="string">'US'</span>)<span class="comment">#指定重建某分区的索引,如果省略会重建所有分区的索引。</span></span><br><span class="line"><span class="keyword">rebuild</span></span><br><span class="line">;</span><br></pre></td></tr></table></figure></li>
<li>显示索引:<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">show</span> formatted <span class="keyword">index</span> <span class="keyword">on</span> employees</span><br><span class="line">;</span><br></pre></td></tr></table></figure></li>
<li>删除索引<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">drop</span> <span class="keyword">index</span> <span class="keyword">if</span> <span class="keyword">exists</span> employees_index</span><br><span class="line"><span class="keyword">on</span> <span class="keyword">table</span> employees</span><br><span class="line">;</span><br></pre></td></tr></table></figure>
如果原表被删除了，对其建立的对应的索引和索引表也会被删除。<br>如果原始表的某个分区被删除了，这个分区对应的分区索引也会被删除。</li>
</ol>
<p>?:书上日期用的是数字’20110102’（<code>int</code>）,为何咱们用的是字符串’2015-11-02’?</p>
<blockquote>
<p><code>NameNode</code>将所有系统元数据信息保存在内存中。一个<code>hdfs</code>实例所能管理的文件总数是有上限的，而<code>MapR</code>和<code>Amazon S3</code>则没有这个限制。</p>
</blockquote>
<p><code>hive</code>数据库和关系型数据库区别:</p>
<table>
<tr>
 <td>关系型</td>
 <td>hive</td>
</tr>
<tr>
 <td>唯一键\主键\自增键</td>
 <td>无</td>
</tr>
<tr>
 <td>三范式(ACID)</td>
 <td>单行中存储一对多关系，一致性较差，但I/O性能高(连续存储)</td>
</tr>
<tr>
 <td>普通数据结构</td>
 <td>集合结构(array,map,struct)</td>
</tr>
</table>
`ACID`:原子性、一致性、隔离性、持久性。


<ul>
<li>一次扫描多次输出<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from history</span><br><span class="line"><span class="keyword">insert</span> overwrite sales </span><br><span class="line">    <span class="keyword">select</span> * <span class="keyword">where</span> <span class="keyword">action</span>=<span class="string">'purchased'</span></span><br><span class="line"><span class="keyword">insert</span> overwrite credits</span><br><span class="line">    <span class="keyword">select</span> * <span class="keyword">where</span> <span class="keyword">action</span>=<span class="string">'returned'</span></span><br><span class="line">;</span><br></pre></td></tr></table></figure>

</li>
</ul>
<blockquote>
<p>ETL，Extraction-Transformation-Loading的缩写，<br>中文名称为数据提取、转换和加载。 </p>
</blockquote>
<blockquote>
<p>ETL工具有：<br>OWB(Oracle Warehouse Builder)、ODI(Oracle Data Integrator)、Informatic PowerCenter、Trinity、AICloudETL、DataStage、Repository Explorer、Beeload、Kettle、DataSpider</p>
</blockquote>
<blockquote>
<p>ETL负责将分散的、异构数据源中的数据如关系数据、平面数据文件等抽取到临时中间层后进行清洗、转换、集成，最后加载到数据仓库或数据集市中，成为联机分析处理、数据挖掘的基础。</p>
</blockquote>
<ul>
<li>引用<code>hiveconf</code>变量:<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ hive -hiveconf dt=2011-01-01</span><br><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> distinct_ip_in_logs</span><br><span class="line"><span class="keyword">partition</span> (hit_data=$&#123;dt&#125;)</span><br><span class="line"><span class="keyword">select</span> <span class="keyword">distinct</span>(ip) <span class="keyword">as</span> ip <span class="keyword">from</span> weblogs</span><br><span class="line"><span class="keyword">where</span> hit_date=<span class="string">'$&#123;hiveconf:dt&#125;'</span></span><br><span class="line">;</span><br></pre></td></tr></table></figure>

</li>
</ul>
<p>如何获得表中已有数据的规模信息(不用<code>count</code>)?<br>先用<code>show create table test1</code>查询到表在hdfs上的location,<br>然后用<code>dfs -du -h hdfs://location1</code>查询到文件大小。</p>
<ul>
<li>分桶数据存储</li>
</ul>
<ol>
<li>建表:<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> weblog (user_id <span class="built_in">INT</span>,<span class="keyword">url</span> <span class="keyword">String</span>, source_ip <span class="keyword">String</span>)</span><br><span class="line">Partitioned <span class="keyword">by</span> (dt <span class="keyword">string</span>)</span><br><span class="line">clustered <span class="keyword">by</span> (user_id) <span class="keyword">into</span> <span class="number">96</span> buckets</span><br><span class="line">;</span><br></pre></td></tr></table></figure>
使用<code>user_id</code>字段作为分桶字段，表数据按字段值哈希值分发到桶中。同一个<code>user_id</code>下的记录通常会存储到同一个桶内。假设用户数比桶数要多，那么桶内就将会包含多个用户的记录。</li>
</ol>
<p><em>结合<code>p109</code>的<code>map-side join</code>学习。</em></p>
<p>2.分桶后插入数据:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.enforce.bucketing=<span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line">From raw_logs</span><br><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> weblog</span><br><span class="line"><span class="keyword">partition</span> (dt=<span class="string">'2009-02-25'</span>)</span><br><span class="line"><span class="keyword">select</span> user_id,<span class="keyword">url</span>,source_ip </span><br><span class="line"><span class="keyword">where</span> dt=<span class="string">'2009-02-25'</span></span><br><span class="line">;</span><br></pre></td></tr></table></figure>

<p>3.分桶表连接优化开启:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.optimize.bucketmapJOIN=<span class="literal">true</span>;</span><br><span class="line"><span class="comment">#待连接的两个表分桶数量呈倍数关系时可优化。</span></span><br><span class="line"><span class="comment"># 且on语句中连接键与分桶键相同。</span></span><br><span class="line"><span class="comment">#sort-merge JOIN:</span></span><br><span class="line"><span class="comment">#分桶数完全相同时:</span></span><br><span class="line"><span class="keyword">set</span> hive.input.format=org.apache.hadoop.hive.ql.io.BucketizedHiveInputFormat;</span><br><span class="line"><span class="keyword">set</span> hive.optimize.bucketmapjoin=<span class="literal">true</span>;</span><br><span class="line"><span class="keyword">set</span> hive.optimize.bucketmapjoin.sortedmerge=<span class="literal">true</span>;</span><br></pre></td></tr></table></figure>

<hr>
<p><a href="http://www.coder4.com/archives/4031" target="_blank" rel="noopener">SerDe</a> 全称是 <code>Serializer and Deserializer</code><br>HDFS files –&gt; InputFileFormat –&gt; ‘&lt;’key, value&gt; –&gt; Deserializer –&gt; Row object<br>Row object –&gt; Serializer –&gt; ‘&lt;’key, value&gt; –&gt; OutputFileFormat –&gt; HDFS files</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">st&#x3D;&gt;start: HDFS files</span><br><span class="line">e&#x3D;&gt;end: 结束 </span><br><span class="line">op1&#x3D;&gt;operation: InputFileFormat</span><br><span class="line">op2&#x3D;&gt;operation: &#39;&lt;&#39;key,value&gt;</span><br><span class="line">op3&#x3D;&gt;operation: Deserializer </span><br><span class="line">op4&#x3D;&gt;operation: Row object</span><br><span class="line">st-&gt;op1-&gt;op2-&gt;op3-&gt;op4-&gt;e</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">explain</span> <span class="keyword">select</span> * <span class="keyword">from</span> tmp_table1 <span class="keyword">limit</span> <span class="number">100</span>;</span><br><span class="line">OK <span class="comment">#执行返回码</span></span><br><span class="line">STAGE DEPENDENCIES:</span><br><span class="line">  Stage-0 is a root stage</span><br><span class="line"></span><br><span class="line">STAGE PLANS:</span><br><span class="line">  Stage: Stage-0</span><br><span class="line">    Fetch Operator</span><br><span class="line">      limit: 100</span><br><span class="line">      Processor Tree:</span><br><span class="line">        TableScan</span><br><span class="line">          alias: tmp_table1</span><br><span class="line">          Statistics: Num rows: 0 Data size: 72 Basic stats: PARTIAL Column stats: NONE</span><br><span class="line">          <span class="keyword">Select</span> <span class="keyword">Operator</span></span><br><span class="line">            expressions: <span class="keyword">id</span> (<span class="keyword">type</span>: <span class="keyword">string</span>), perf (<span class="keyword">type</span>: <span class="keyword">map</span>&lt;<span class="keyword">string</span>,<span class="built_in">int</span>&gt;)</span><br><span class="line">            outputColumnNames: _col0, _col1</span><br><span class="line">            <span class="keyword">Statistics</span>: <span class="keyword">Num</span> <span class="keyword">rows</span>: <span class="number">0</span> <span class="keyword">Data</span> <span class="keyword">size</span>: <span class="number">72</span> Basic stats: <span class="keyword">PARTIAL</span> <span class="keyword">Column</span> stats: <span class="keyword">NONE</span></span><br><span class="line">            <span class="keyword">Limit</span></span><br><span class="line">              <span class="built_in">Number</span> <span class="keyword">of</span> <span class="keyword">rows</span>: <span class="number">100</span></span><br><span class="line">              <span class="keyword">Statistics</span>: <span class="keyword">Num</span> <span class="keyword">rows</span>: <span class="number">0</span> <span class="keyword">Data</span> <span class="keyword">size</span>: <span class="number">72</span> Basic stats: <span class="keyword">PARTIAL</span> <span class="keyword">Column</span> stats: <span class="keyword">NONE</span></span><br><span class="line">              ListSink</span><br><span class="line"></span><br><span class="line"><span class="built_in">Time</span> taken: <span class="number">0.11</span> <span class="keyword">seconds</span>, Fetched: <span class="number">20</span> <span class="keyword">row</span>(s)</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; explain select count(*) from tmp_table1 limit 100;</span><br><span class="line">OK</span><br><span class="line">STAGE DEPENDENCIES:</span><br><span class="line">  Stage-1 is a root stage</span><br><span class="line">  Stage-0 depends on stages: Stage-1</span><br><span class="line"></span><br><span class="line">STAGE PLANS:</span><br><span class="line">  Stage: Stage-1</span><br><span class="line">    Map Reduce</span><br><span class="line">      Map Operator Tree:</span><br><span class="line">          TableScan</span><br><span class="line">            alias: tmp_table1</span><br><span class="line">            Statistics: Num rows: 0 Data size: 72 Basic stats: PARTIAL Column stats: COMPLETE</span><br><span class="line">            <span class="keyword">Select</span> <span class="keyword">Operator</span></span><br><span class="line">              <span class="keyword">Statistics</span>: <span class="keyword">Num</span> <span class="keyword">rows</span>: <span class="number">0</span> <span class="keyword">Data</span> <span class="keyword">size</span>: <span class="number">72</span> Basic stats: <span class="keyword">PARTIAL</span> <span class="keyword">Column</span> stats: <span class="keyword">COMPLETE</span></span><br><span class="line">              <span class="keyword">Group</span> <span class="keyword">By</span> <span class="keyword">Operator</span></span><br><span class="line">                aggregations: <span class="keyword">count</span>()</span><br><span class="line">                <span class="keyword">mode</span>: <span class="keyword">hash</span></span><br><span class="line">                outputColumnNames: _col0</span><br><span class="line">                <span class="keyword">Statistics</span>: <span class="keyword">Num</span> <span class="keyword">rows</span>: <span class="number">1</span> <span class="keyword">Data</span> <span class="keyword">size</span>: <span class="number">8</span> Basic stats: <span class="keyword">COMPLETE</span> <span class="keyword">Column</span> stats: <span class="keyword">COMPLETE</span></span><br><span class="line">                Reduce <span class="keyword">Output</span> <span class="keyword">Operator</span></span><br><span class="line">                  <span class="keyword">sort</span> <span class="keyword">order</span>:</span><br><span class="line">                  <span class="keyword">Statistics</span>: <span class="keyword">Num</span> <span class="keyword">rows</span>: <span class="number">1</span> <span class="keyword">Data</span> <span class="keyword">size</span>: <span class="number">8</span> Basic stats: <span class="keyword">COMPLETE</span> <span class="keyword">Column</span> stats: <span class="keyword">COMPLETE</span></span><br><span class="line">                  TopN <span class="keyword">Hash</span> <span class="keyword">Memory</span> <span class="keyword">Usage</span>: <span class="number">0.3</span></span><br><span class="line">                  <span class="keyword">value</span> expressions: _col0 (<span class="keyword">type</span>: <span class="built_in">bigint</span>)</span><br><span class="line">      Reduce <span class="keyword">Operator</span> Tree:</span><br><span class="line">        <span class="keyword">Group</span> <span class="keyword">By</span> <span class="keyword">Operator</span></span><br><span class="line">          aggregations: <span class="keyword">count</span>(VALUE._col0)</span><br><span class="line">          <span class="keyword">mode</span>: mergepartial</span><br><span class="line">          outputColumnNames: _col0</span><br><span class="line">          <span class="keyword">Statistics</span>: <span class="keyword">Num</span> <span class="keyword">rows</span>: <span class="number">1</span> <span class="keyword">Data</span> <span class="keyword">size</span>: <span class="number">8</span> Basic stats: <span class="keyword">COMPLETE</span> <span class="keyword">Column</span> stats: <span class="keyword">COMPLETE</span></span><br><span class="line">          <span class="keyword">Select</span> <span class="keyword">Operator</span></span><br><span class="line">            expressions: _col0 (<span class="keyword">type</span>: <span class="built_in">bigint</span>)</span><br><span class="line">            outputColumnNames: _col0</span><br><span class="line">            <span class="keyword">Statistics</span>: <span class="keyword">Num</span> <span class="keyword">rows</span>: <span class="number">1</span> <span class="keyword">Data</span> <span class="keyword">size</span>: <span class="number">8</span> Basic stats: <span class="keyword">COMPLETE</span> <span class="keyword">Column</span> stats: <span class="keyword">COMPLETE</span></span><br><span class="line">            <span class="keyword">Limit</span></span><br><span class="line">              <span class="built_in">Number</span> <span class="keyword">of</span> <span class="keyword">rows</span>: <span class="number">100</span></span><br><span class="line">              <span class="keyword">Statistics</span>: <span class="keyword">Num</span> <span class="keyword">rows</span>: <span class="number">1</span> <span class="keyword">Data</span> <span class="keyword">size</span>: <span class="number">8</span> Basic stats: <span class="keyword">COMPLETE</span> <span class="keyword">Column</span> stats: <span class="keyword">COMPLETE</span></span><br><span class="line">              <span class="keyword">File</span> <span class="keyword">Output</span> <span class="keyword">Operator</span></span><br><span class="line">                compressed: <span class="literal">false</span></span><br><span class="line">                <span class="keyword">Statistics</span>: <span class="keyword">Num</span> <span class="keyword">rows</span>: <span class="number">1</span> <span class="keyword">Data</span> <span class="keyword">size</span>: <span class="number">8</span> Basic stats: <span class="keyword">COMPLETE</span> <span class="keyword">Column</span> stats: <span class="keyword">COMPLETE</span></span><br><span class="line">                <span class="keyword">table</span>:</span><br><span class="line">                    <span class="keyword">input</span> <span class="keyword">format</span>: org.apache.hadoop.mapred.TextInputFormat</span><br><span class="line">                    <span class="keyword">output</span> <span class="keyword">format</span>: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</span><br><span class="line">                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</span><br><span class="line"></span><br><span class="line">  Stage: Stage<span class="number">-0</span></span><br><span class="line">    <span class="keyword">Fetch</span> <span class="keyword">Operator</span></span><br><span class="line">      <span class="keyword">limit</span>: <span class="number">100</span></span><br><span class="line">      Processor Tree:</span><br><span class="line">        ListSink</span><br><span class="line"></span><br><span class="line"><span class="built_in">Time</span> taken: <span class="number">0.055</span> <span class="keyword">seconds</span>, Fetched: <span class="number">50</span> <span class="keyword">row</span>(s)</span><br></pre></td></tr></table></figure>

<p><code>explain extended</code>：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">explain</span> <span class="keyword">extended</span> <span class="keyword">select</span> <span class="keyword">count</span>(*) <span class="keyword">from</span> tmp_table1 <span class="keyword">limit</span> <span class="number">100</span>;</span><br><span class="line">OK</span><br><span class="line">ABSTRACT SYNTAX TREE:</span><br><span class="line"></span><br><span class="line">TOK_QUERY</span><br><span class="line">   TOK_FROM</span><br><span class="line">      TOK_TABREF</span><br><span class="line">         TOK_TABNAME</span><br><span class="line">            tmp_table1</span><br><span class="line">   TOK_INSERT</span><br><span class="line">      TOK_DESTINATION</span><br><span class="line">         TOK_DIR</span><br><span class="line">            TOK_TMP_FILE</span><br><span class="line">      TOK_SELECT</span><br><span class="line">         TOK_SELEXPR</span><br><span class="line">            TOK_FUNCTIONSTAR</span><br><span class="line">               count</span><br><span class="line">      TOK_LIMIT</span><br><span class="line">         100</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">STAGE DEPENDENCIES:</span><br><span class="line">  Stage-1 is a root stage</span><br><span class="line">  Stage-0 depends on stages: Stage-1</span><br><span class="line"></span><br><span class="line">STAGE PLANS:</span><br><span class="line">  Stage: Stage-1</span><br><span class="line">    Map Reduce</span><br><span class="line">      Map Operator Tree:</span><br><span class="line">          TableScan</span><br><span class="line">            alias: tmp_table1</span><br><span class="line">            Statistics: Num rows: 0 Data size: 72 Basic stats: PARTIAL Column stats: COMPLETE</span><br><span class="line">            GatherStats: false</span><br><span class="line">            <span class="keyword">Select</span> <span class="keyword">Operator</span></span><br><span class="line">              <span class="keyword">Statistics</span>: <span class="keyword">Num</span> <span class="keyword">rows</span>: <span class="number">0</span> <span class="keyword">Data</span> <span class="keyword">size</span>: <span class="number">72</span> Basic stats: <span class="keyword">PARTIAL</span> <span class="keyword">Column</span> stats: <span class="keyword">COMPLETE</span></span><br><span class="line">              <span class="keyword">Group</span> <span class="keyword">By</span> <span class="keyword">Operator</span></span><br><span class="line">                aggregations: <span class="keyword">count</span>()</span><br><span class="line">                <span class="keyword">mode</span>: <span class="keyword">hash</span></span><br><span class="line">                outputColumnNames: _col0</span><br><span class="line">                <span class="keyword">Statistics</span>: <span class="keyword">Num</span> <span class="keyword">rows</span>: <span class="number">1</span> <span class="keyword">Data</span> <span class="keyword">size</span>: <span class="number">8</span> Basic stats: <span class="keyword">COMPLETE</span> <span class="keyword">Column</span> stats: <span class="keyword">COMPLETE</span></span><br><span class="line">                Reduce <span class="keyword">Output</span> <span class="keyword">Operator</span></span><br><span class="line">                  <span class="keyword">sort</span> <span class="keyword">order</span>:</span><br><span class="line">                  <span class="keyword">Statistics</span>: <span class="keyword">Num</span> <span class="keyword">rows</span>: <span class="number">1</span> <span class="keyword">Data</span> <span class="keyword">size</span>: <span class="number">8</span> Basic stats: <span class="keyword">COMPLETE</span> <span class="keyword">Column</span> stats: <span class="keyword">COMPLETE</span></span><br><span class="line">                  tag: <span class="number">-1</span></span><br><span class="line">                  TopN: <span class="number">100</span></span><br><span class="line">                  TopN <span class="keyword">Hash</span> <span class="keyword">Memory</span> <span class="keyword">Usage</span>: <span class="number">0.3</span></span><br><span class="line">                  <span class="keyword">value</span> expressions: _col0 (<span class="keyword">type</span>: <span class="built_in">bigint</span>)</span><br><span class="line">                  <span class="keyword">auto</span> parallelism: <span class="literal">false</span></span><br><span class="line">      <span class="keyword">Path</span> -&gt; <span class="keyword">Alias</span>:</span><br><span class="line">        hdfs://f04/<span class="keyword">user</span>/hive/warehouse/temp.db/tmp_table1 [tmp_table1]</span><br><span class="line">      <span class="keyword">Path</span> -&gt; <span class="keyword">Partition</span>:</span><br><span class="line">        hdfs://f04/<span class="keyword">user</span>/hive/warehouse/temp.db/tmp_table1</span><br><span class="line">          <span class="keyword">Partition</span></span><br><span class="line">            base <span class="keyword">file</span> <span class="keyword">name</span>: tmp_table1</span><br><span class="line">            <span class="keyword">input</span> <span class="keyword">format</span>: org.apache.hadoop.mapred.TextInputFormat</span><br><span class="line">            <span class="keyword">output</span> <span class="keyword">format</span>: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</span><br><span class="line">            properties:</span><br><span class="line">              COLUMN_STATS_ACCURATE <span class="literal">true</span></span><br><span class="line">              bucket_count <span class="number">-1</span></span><br><span class="line">              colelction.delim ,</span><br><span class="line">              <span class="keyword">columns</span> <span class="keyword">id</span>,perf</span><br><span class="line">              columns.comments</span><br><span class="line">              columns.types <span class="keyword">string</span>:<span class="keyword">map</span>&lt;<span class="keyword">string</span>,<span class="built_in">int</span>&gt;</span><br><span class="line">              field.delim</span><br><span class="line">              file.inputformat org.apache.hadoop.mapred.TextInputFormat</span><br><span class="line">              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</span><br><span class="line">              location hdfs://f04/<span class="keyword">user</span>/hive/warehouse/temp.db/tmp_table1</span><br><span class="line">              mapkey.delim :</span><br><span class="line">              <span class="keyword">name</span> temp.tmp_table1</span><br><span class="line">              numFiles <span class="number">1</span></span><br><span class="line">              serialization.ddl <span class="keyword">struct</span> tmp_table1 &#123; <span class="keyword">string</span> <span class="keyword">id</span>, <span class="keyword">map</span>&lt;<span class="keyword">string</span>,i32&gt; perf&#125;</span><br><span class="line">              serialization.format</span><br><span class="line">              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</span><br><span class="line">              totalSize <span class="number">72</span></span><br><span class="line">              transient_lastDdlTime <span class="number">1438742089</span></span><br><span class="line">            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</span><br><span class="line"></span><br><span class="line">              <span class="keyword">input</span> <span class="keyword">format</span>: org.apache.hadoop.mapred.TextInputFormat</span><br><span class="line">              <span class="keyword">output</span> <span class="keyword">format</span>: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</span><br><span class="line">              properties:</span><br><span class="line">                COLUMN_STATS_ACCURATE <span class="literal">true</span></span><br><span class="line">                bucket_count <span class="number">-1</span></span><br><span class="line">                colelction.delim ,</span><br><span class="line">                <span class="keyword">columns</span> <span class="keyword">id</span>,perf</span><br><span class="line">                columns.comments</span><br><span class="line">                columns.types <span class="keyword">string</span>:<span class="keyword">map</span>&lt;<span class="keyword">string</span>,<span class="built_in">int</span>&gt;</span><br><span class="line">                field.delim</span><br><span class="line">                file.inputformat org.apache.hadoop.mapred.TextInputFormat</span><br><span class="line">                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</span><br><span class="line">                location hdfs://f04/<span class="keyword">user</span>/hive/warehouse/temp.db/tmp_table1</span><br><span class="line">                mapkey.delim :</span><br><span class="line">                <span class="keyword">name</span> temp.tmp_table1</span><br><span class="line">                numFiles <span class="number">1</span></span><br><span class="line">                serialization.ddl <span class="keyword">struct</span> tmp_table1 &#123; <span class="keyword">string</span> <span class="keyword">id</span>, <span class="keyword">map</span>&lt;<span class="keyword">string</span>,i32&gt; perf&#125;</span><br><span class="line">                serialization.format</span><br><span class="line">                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</span><br><span class="line">                totalSize <span class="number">72</span></span><br><span class="line">                transient_lastDdlTime <span class="number">1438742089</span></span><br><span class="line">              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</span><br><span class="line">              <span class="keyword">name</span>: temp.tmp_table1</span><br><span class="line">            <span class="keyword">name</span>: temp.tmp_table1</span><br><span class="line">      Truncated <span class="keyword">Path</span> -&gt; <span class="keyword">Alias</span>:</span><br><span class="line">        /temp.db/tmp_table1 [tmp_table1]</span><br><span class="line">      Needs Tagging: <span class="literal">false</span></span><br><span class="line">      Reduce <span class="keyword">Operator</span> Tree:</span><br><span class="line">        <span class="keyword">Group</span> <span class="keyword">By</span> <span class="keyword">Operator</span></span><br><span class="line">          aggregations: <span class="keyword">count</span>(VALUE._col0)</span><br><span class="line">          <span class="keyword">mode</span>: mergepartial</span><br><span class="line">          outputColumnNames: _col0</span><br><span class="line">          <span class="keyword">Statistics</span>: <span class="keyword">Num</span> <span class="keyword">rows</span>: <span class="number">1</span> <span class="keyword">Data</span> <span class="keyword">size</span>: <span class="number">8</span> Basic stats: <span class="keyword">COMPLETE</span> <span class="keyword">Column</span> stats: <span class="keyword">COMPLETE</span></span><br><span class="line">          <span class="keyword">Select</span> <span class="keyword">Operator</span></span><br><span class="line">            expressions: _col0 (<span class="keyword">type</span>: <span class="built_in">bigint</span>)</span><br><span class="line">            outputColumnNames: _col0</span><br><span class="line">            <span class="keyword">Statistics</span>: <span class="keyword">Num</span> <span class="keyword">rows</span>: <span class="number">1</span> <span class="keyword">Data</span> <span class="keyword">size</span>: <span class="number">8</span> Basic stats: <span class="keyword">COMPLETE</span> <span class="keyword">Column</span> stats: <span class="keyword">COMPLETE</span></span><br><span class="line">            <span class="keyword">Limit</span></span><br><span class="line">              <span class="built_in">Number</span> <span class="keyword">of</span> <span class="keyword">rows</span>: <span class="number">100</span></span><br><span class="line">              <span class="keyword">Statistics</span>: <span class="keyword">Num</span> <span class="keyword">rows</span>: <span class="number">1</span> <span class="keyword">Data</span> <span class="keyword">size</span>: <span class="number">8</span> Basic stats: <span class="keyword">COMPLETE</span> <span class="keyword">Column</span> stats: <span class="keyword">COMPLETE</span></span><br><span class="line">              <span class="keyword">File</span> <span class="keyword">Output</span> <span class="keyword">Operator</span></span><br><span class="line">                compressed: <span class="literal">false</span></span><br><span class="line">                GlobalTableId: <span class="number">0</span></span><br><span class="line">                <span class="keyword">directory</span>: hdfs://f04/home/maintain/hive/hive/tmp/hive-maintain/maintain/<span class="number">13951</span>f1a<span class="number">-3</span>bd6<span class="number">-481</span>f-a901<span class="number">-1</span>b2c185ec877/hive_2015<span class="number">-11</span><span class="number">-05</span>_14<span class="number">-37</span><span class="number">-47</span>_859_3395572406114851553<span class="number">-1</span>/-ext<span class="number">-10001</span></span><br><span class="line">                NumFilesPerFileSink: <span class="number">1</span></span><br><span class="line">                <span class="keyword">Statistics</span>: <span class="keyword">Num</span> <span class="keyword">rows</span>: <span class="number">1</span> <span class="keyword">Data</span> <span class="keyword">size</span>: <span class="number">8</span> Basic stats: <span class="keyword">COMPLETE</span> <span class="keyword">Column</span> stats: <span class="keyword">COMPLETE</span></span><br><span class="line">                Stats Publishing <span class="keyword">Key</span> Prefix: hdfs://f04/home/maintain/hive/hive/tmp/hive-maintain/maintain/<span class="number">13951</span>f1a<span class="number">-3</span>bd6<span class="number">-481</span>f-a901<span class="number">-1</span>b2c185ec877/hive_2015<span class="number">-11</span><span class="number">-05</span>_14<span class="number">-37</span><span class="number">-47</span>_859_3395572406114851553<span class="number">-1</span>/-ext<span class="number">-10001</span>/</span><br><span class="line">                <span class="keyword">table</span>:</span><br><span class="line">                    <span class="keyword">input</span> <span class="keyword">format</span>: org.apache.hadoop.mapred.TextInputFormat</span><br><span class="line">                    <span class="keyword">output</span> <span class="keyword">format</span>: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</span><br><span class="line">                    properties:</span><br><span class="line">                      <span class="keyword">columns</span> _col0</span><br><span class="line">                      columns.types <span class="built_in">bigint</span></span><br><span class="line">                      escape.delim \</span><br><span class="line">                      hive.serialization.extend.nesting.levels <span class="literal">true</span></span><br><span class="line">                      serialization.format <span class="number">1</span></span><br><span class="line">                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</span><br><span class="line">                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</span><br><span class="line">                TotalFiles: <span class="number">1</span></span><br><span class="line">                GatherStats: <span class="literal">false</span></span><br><span class="line">                MultiFileSpray: <span class="literal">false</span></span><br><span class="line"></span><br><span class="line">  Stage: Stage<span class="number">-0</span></span><br><span class="line">    <span class="keyword">Fetch</span> <span class="keyword">Operator</span></span><br><span class="line">      <span class="keyword">limit</span>: <span class="number">100</span></span><br><span class="line">      Processor Tree:</span><br><span class="line">        ListSink</span><br><span class="line"></span><br><span class="line"><span class="built_in">Time</span> taken: <span class="number">0.059</span> <span class="keyword">seconds</span>, Fetched: <span class="number">143</span> <span class="keyword">row</span>(s)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive.exec.reducers.max&#x3D;</span><br><span class="line">(集群总reduce槽位个数*1.5)&#x2F;(执行中的查询平均个数)</span><br></pre></td></tr></table></figure>

<p>若小任务多可开启优化：推测执行和<code>JVM</code>重用。 </p>
<p>虚拟列?</p>
<p>I/O密集型该使用压缩；CPU密集型任务则不然。</p>
<p><code>sequence file</code>存储格式: 压缩且可分。</p>
<p><code>CLI</code>会话中通过<code>set</code>命令设置的属性在同一个会话中会一直生效的。</p>
<hr>
<p><code>show functions;</code>列出所有函数(包括用户自定义函数(<code>UDF</code>))。<br><code>describe function extended concat;</code>展示函数的简单介绍。<br><code>UDTF</code>自定义表生成函数；<br><code>UDAF</code>自定义聚合函数。</p>
<hr>
<p><code>python</code>版<code>map-reduce</code>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># mapper.py:</span></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    words=line.strip().split()</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> words:</span><br><span class="line">        <span class="keyword">print</span> <span class="string">"%s\t"</span> % (word.lower())</span><br><span class="line"><span class="comment">#reducer.py:</span></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line">(last_key, last_count)=(<span class="literal">None</span>,<span class="number">0</span>)</span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    (key,count)=linde.strip().split(<span class="string">"\t"</span>)</span><br><span class="line">    <span class="keyword">if</span> last_key <span class="keyword">and</span> last_key!=key:</span><br><span class="line">        <span class="keyword">print</span> <span class="string">"%s\t%d"</span> % (last_key, last_count)</span><br><span class="line">        (last_key, last_count)=(key, int(count))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        last_key=key</span><br><span class="line">        last_count+=int(count)</span><br><span class="line"><span class="keyword">if</span> last_key:</span><br><span class="line">    <span class="keyword">print</span> <span class="string">"%s\t%d"</span> % (last_key, last_count)</span><br></pre></td></tr></table></figure>
<p>使用<code>transform</code>关键字调用脚本，省得写<code>UDF</code>:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> docs (line <span class="keyword">String</span>)</span><br><span class="line">;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> word_count (word <span class="keyword">String</span>, <span class="keyword">count</span> <span class="built_in">Int</span>)</span><br><span class="line"><span class="keyword">Row</span> <span class="keyword">format</span> <span class="keyword">delimited</span> <span class="keyword">fields</span> teminated <span class="keyword">by</span> <span class="string">'\t'</span></span><br><span class="line">;</span><br><span class="line">from(</span><br><span class="line">    from docs</span><br><span class="line">    <span class="keyword">select</span> transform (line) <span class="keyword">using</span> <span class="string">'$&#123;env:HOME&#125;/mapper.py'</span></span><br><span class="line">    <span class="keyword">as</span> word,<span class="keyword">count</span></span><br><span class="line">    cluster <span class="keyword">by</span> word) wc</span><br><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> word_count</span><br><span class="line"><span class="keyword">select</span> transform (wc.word,wc.count)</span><br><span class="line">    <span class="keyword">using</span> <span class="string">'$&#123;env:HOME&#125;/reducer.py'</span></span><br><span class="line">    <span class="keyword">as</span> word, <span class="keyword">count</span></span><br><span class="line">;</span><br></pre></td></tr></table></figure>

<hr>
<ul>
<li>自定义序列化：<br><code>json SerDe</code>:<code>P214</code><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">external</span> <span class="keyword">table</span> messages(</span><br><span class="line">msg_id <span class="built_in">bigint</span>,</span><br><span class="line">tstamp <span class="keyword">string</span>,</span><br><span class="line"><span class="built_in">text</span> <span class="keyword">string</span>,</span><br><span class="line">user_id <span class="built_in">bigint</span>,</span><br><span class="line">user_name <span class="keyword">string</span></span><br><span class="line">)</span><br><span class="line"><span class="keyword">row</span> <span class="keyword">format</span> SerDe <span class="string">"org.apache.hadoop.hive.contrib.serde2.JsonSerde"</span></span><br><span class="line"><span class="keyword">with</span> serdeProperties(</span><br><span class="line"><span class="string">"msg_id"</span>=<span class="string">"$.id"</span>,</span><br><span class="line"><span class="string">"tstamp"</span>=<span class="string">"$.created_at"</span>,</span><br><span class="line"><span class="string">"text"</span>=<span class="string">"$.text"</span>,</span><br><span class="line"><span class="string">"user_id"</span>=<span class="string">"$.user.id"</span>,</span><br><span class="line"><span class="string">"user_name"</span>=<span class="string">"$.user.name"</span></span><br><span class="line">)</span><br><span class="line">Location <span class="string">'/data/messages'</span></span><br><span class="line">;</span><br></pre></td></tr></table></figure>

</li>
</ul>
<hr>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hive -hiveconf start_date&#x3D;&#39;2015-11-15&#39; -hiveconf end_date&#x3D;&#39;2015-11-21&#39; -f .&#x2F;comments_data.hql</span><br><span class="line"></span><br><span class="line">solarWarehouse</span><br><span class="line">userstat函数</span><br></pre></td></tr></table></figure>


<p>这个地方错好多次了：</p>
<blockquote>
<p>left join 不在on里使用where</p>
</blockquote>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://xiaoyue26.github.io/2017/01/22/hive%E7%AC%94%E8%AE%B0/" data-id="ck96cxpl60026maam3gli7lie" class="article-share-link">分享</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/hive/" rel="tag">hive</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-hive-udf" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/01/15/hive-udf/" class="article-date">
  <time datetime="2017-01-15T11:29:01.000Z" itemprop="datePublished">2017-01-15</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/hadoop/">hadoop</a>►<a class="article-category-link" href="/categories/hadoop/hive/">hive</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/01/15/hive-udf/">hive udf</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
        
        <p>中位数算法:<br><a href="https://segmentfault.com/a/1190000008322873" target="_blank" rel="noopener">https://segmentfault.com/a/1190000008322873</a><br><a href="http://www.voidcn.com/article/p-yzrnuwwi-bdv.html" target="_blank" rel="noopener">http://www.voidcn.com/article/p-yzrnuwwi-bdv.html</a></p>
<h1 id="hive类型和java类型"><a href="#hive类型和java类型" class="headerlink" title="hive类型和java类型"></a>hive类型和java类型</h1><table>
<tr><td>Hive column type</td>    <td>UDF types</td></tr>
<tr><td>string    </td>    
<td>java.lang.String, org.apache.hadoop.io.Text</td></tr>
<tr><td>int    </td>    
<td>int, java.lang.Integer, org.apache.hadoop.io.IntWritable</td></tr>
<tr><td>boolean    </td>    
<td>bool, java.lang.Boolean, org.apache.hadoop.io.BooleanWritable</td></tr>
<tr><td>array<type>    </td>    <td>java.util.List<Java type></td></tr>
<tr><td>map<ktype, vtype>    </td>    
<td>java.util.Map<Java type for K, Java type for V></td></tr>
<tr><td>struct    </td>    <td>Don't use Simple UDF, use GenericUDF</td></tr>
</table>


<h1 id="UDAF"><a href="#UDAF" class="headerlink" title="UDAF"></a>UDAF</h1><p><a href="http://www.cnblogs.com/ggjucheng/archive/2013/02/01/2888051.html" target="_blank" rel="noopener">http://www.cnblogs.com/ggjucheng/archive/2013/02/01/2888051.html</a><br><code>GenericUDAFEvaluator</code>的几种<code>MODE</code>定义如下:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">public static enum Mode &#123;</span><br><span class="line">    &#x2F;**</span><br><span class="line">     * PARTIAL1: 这个是mapreduce的map阶段:从原始数据到部分数据聚合</span><br><span class="line">     * 将会调用iterate()和terminatePartial()</span><br><span class="line">     *&#x2F;</span><br><span class="line">    PARTIAL1,</span><br><span class="line">        &#x2F;**</span><br><span class="line">     * PARTIAL2: 这个是mapreduce的map端的Combiner阶段，负责在map端合并map的数据::从部分数据聚合到部分数据聚合:</span><br><span class="line">     * 将会调用merge() 和 terminatePartial() </span><br><span class="line">     *&#x2F;</span><br><span class="line">    PARTIAL2,</span><br><span class="line">        &#x2F;**</span><br><span class="line">     * FINAL: mapreduce的reduce阶段:从部分数据的聚合到完全聚合 </span><br><span class="line">     * 将会调用merge()和terminate()</span><br><span class="line">     *&#x2F;</span><br><span class="line">    FINAL,</span><br><span class="line">        &#x2F;**</span><br><span class="line">     * COMPLETE: 如果出现了这个阶段，表示mapreduce只有map，没有reduce，所以map端就直接出结果了:从原始数据直接到完全聚合</span><br><span class="line">      * 将会调用 iterate()和terminate()</span><br><span class="line">     *&#x2F;</span><br><span class="line">    COMPLETE</span><br><span class="line">  &#125;;</span><br></pre></td></tr></table></figure>

<p>特别提醒：<br>Merge函数的输入参数是(State other),因为other对象会被复用,因此other里的成员的使用不能是浅拷贝,(比如直接塞到当前state里),可以用深拷贝.(对于List,Map等容器)</p>
<p>系统内置的UDAF函数可以从:<code>FunctionRegistry</code>类中查看.<br>流程控制更为精细的UDAF,AVG:<br><code>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFAverage</code></p>
<p>hive调用java方法:<br>select java_method(“java.lang.Math”,”max”,1,2);</p>
<h1 id="UDF数据类型相关"><a href="#UDF数据类型相关" class="headerlink" title="UDF数据类型相关"></a>UDF数据类型相关</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">select array(1,2,3) -- &#x3D;&gt; [1,2,3]</span><br><span class="line">select array(1,&#39;2&#39;,3) -- &#x3D;&gt; [&#39;1&#39;,&#39;2&#39;,&#39;3&#39;] 只要有一个string,就全是string</span><br><span class="line">select array(1,NULL,3) -- &#x3D;&gt; [1,NULL,3] NULL则不影响类型转换.</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://xiaoyue26.github.io/2017/01/15/hive-udf/" data-id="ck96cxpl50023maamai3w6mig" class="article-share-link">分享</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/hive/" rel="tag">hive</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/java/" rel="tag">java</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-Hive-Serde" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/01/14/Hive-Serde/" class="article-date">
  <time datetime="2017-01-14T11:26:56.000Z" itemprop="datePublished">2017-01-14</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/hadoop/">hadoop</a>►<a class="article-category-link" href="/categories/hadoop/hive/">hive</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/01/14/Hive-Serde/">Hive Serde</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
        
        <h1 id="Serde相关"><a href="#Serde相关" class="headerlink" title="Serde相关"></a>Serde相关</h1><p><a href="https://www.coder4.com/archives/4031" target="_blank" rel="noopener">https://www.coder4.com/archives/4031</a><br>反序列化原理(<code>Deserialize</code>):</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HDFS files –&gt; InputFileFormat –&gt; &lt;key, value&gt; –&gt; Deserializer –&gt; Row object</span><br></pre></td></tr></table></figure>
<p>序列化原理(<code>Serialize</code>):</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Row object –&gt; Serializer –&gt; &lt;key, value&gt; –&gt; OutputFileFormat –&gt; HDFS files</span><br></pre></td></tr></table></figure>
<blockquote>
<p>hive的serde内置:<br>Avro<br>ORC<br>RegEx<br>Thrift<br>Parquet<br>CSV<br>JsonSerDe</p>
</blockquote>
<h3 id="自定义Serde"><a href="#自定义Serde" class="headerlink" title="自定义Serde:"></a>自定义Serde:</h3><blockquote>
<p>需要extends AbstractSerDe, 实现6个方法:<br>initialize<br>,deserialize,getSerializedClass,serialize<br>,getSerDeStats,getObjectInspector<br>参见Hive1.2.1的openCSV实现,可以总结各个方法的作用.</p>
</blockquote>
<p>1.<code>initialize</code>方法:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">读取hadoop配置和表配置(建表语句中的),准备一些和元数据有关的数据.</span><br><span class="line">比如所有列的类型,输出列的size,分隔符等等.将这些信息存到对象里备用.</span><br></pre></td></tr></table></figure>

<p>2.<code>serialize</code>方法:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">序列化. </span><br><span class="line">由原理可知,输入是一个Row对象,输出是一些Key,value对,以便被OutputFileFormat解析.</span><br><span class="line">由于OpenCSV使用的OutputFileFormat是</span><br><span class="line">org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</span><br><span class="line">因此,这个方法的输出要与之吻合.</span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 输入: 行对象 (行数据Obj,行类型ObjOI)</span><br><span class="line">     * 输出: Key,value.  要和hive默认的outputFileFormat吻合.</span><br><span class="line">     * 即要和 org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</span><br><span class="line">     * 的输入相同. 而这个类是忽略Key的,因此这个方法的实际输出只有Value.</span><br><span class="line">     * *&#x2F;</span><br><span class="line">OpenCSV里的大致内容就是把行类型ObjOI转成StructOI,</span><br><span class="line">然后把每一列的类型取出来,再用类型把数据取出来,再把数据全转成String,</span><br><span class="line">传给CSVWriter,写到一个StringWriter里,然后转成一个Text返回.</span><br></pre></td></tr></table></figure>

<p>3.<code>deserialize</code>方法:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">反序列化.</span><br><span class="line">由原理可知,输入是一个Key,Value,输出是一个行对象.</span><br><span class="line">其中Key,Value由InputFileFormat生成,对于OpenCSV来说就是默认的Hive设定:</span><br><span class="line">org.apache.hadoop.mapred.TextInputFormat</span><br><span class="line">输出实际上是一个List&lt;String&gt;. </span><br><span class="line"></span><br><span class="line">OpenCSV里的大致内容就是把输入转成Text再转成String然后用CSVReader读出来,</span><br><span class="line">写到一个String[]里,再存到一个List&lt;String&gt;里(补一些缺的,确保列数一样),然后返回.</span><br></pre></td></tr></table></figure>

<p>4.<code>getObjectInspector</code>方法:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">返回整个表的结构类型OI.</span><br><span class="line">从内容上看返回了StructOI.(包括列名和列数,每一列的类型)</span><br><span class="line">对于OpenCSV来说每一列都是String.</span><br></pre></td></tr></table></figure>

<p>5.<code>getSerializedClass</code>方法:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">获取写的时候返回的类.</span><br><span class="line">对于OpenCSV来说,返回Text.class.</span><br><span class="line">因为它的Serialize方法的下游是hive的</span><br><span class="line">org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</span><br><span class="line">而且Serialize的实现实际上也返回了一个Text.(声明的只是Writable)</span><br></pre></td></tr></table></figure>

<p>6.<code>getSerDeStats</code>方法:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">返回序列化类的写入状态信息,具体包括RawDataSize和RowCount. 也就是原始数据大小和行数.</span><br><span class="line">Hive1.2.1实现的不是很健全.自己用得也很少.</span><br><span class="line">只在两处提取了这个信息:</span><br><span class="line">1. FileSinkOperator. 写入数据的时候获取了一下RawDataSize.</span><br><span class="line">2. MapOperator. 读取数据的时候获取了一下RawDataSize.</span><br><span class="line"></span><br><span class="line">甚至对于openCSV,它直接返回了一个null.</span><br><span class="line">对于Hive1.2.1,我们自定义实现Serde的时候,也可以返回null,因为Hive1.2.1的源码中对于这个返回值都是有null判定的. 但如果要对性能做进一步研究,要记录这两个数据,可以参考</span><br><span class="line">LazySimpleSerDe中的实现.</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://xiaoyue26.github.io/2017/01/14/Hive-Serde/" data-id="ck96cxpkj000dmaam13eoalec" class="article-share-link">分享</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/hive/" rel="tag">hive</a></li></ul>

    </footer>
  </div>
  
</article>
 


  


  <nav id="page-nav">
    <a class="extend prev" rel="prev" href="/page/15/">&amp;laquo; 上一页</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/14/">14</a><a class="page-number" href="/page/15/">15</a><span class="page-number current">16</span><a class="page-number" href="/page/17/">17</a><a class="page-number" href="/page/18/">18</a><span class="space">&hellip;</span><a class="page-number" href="/page/21/">21</a><a class="extend next" rel="next" href="/page/17/">下一页&amp;raquo;</a>
  </nav>
</section>
           
    <aside id="sidebar">
  
    

  
    
  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title recent-posts">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2020/07/22/2020-07/ES%E5%AE%9E%E6%88%98%E7%AC%94%E8%AE%B0/">ES实战笔记</a>
          </li>
        
          <li>
            <a href="/2020/06/19/2020-06/tcp%E8%B0%83%E4%BC%98/">tcp调优</a>
          </li>
        
          <li>
            <a href="/2020/06/15/2020-06/jdk11%E4%B8%8Bg1%E6%94%B6%E9%9B%86%E5%99%A8%E4%BD%BF%E7%94%A8/">jdk11下g1收集器使用</a>
          </li>
        
          <li>
            <a href="/2020/06/08/2020-06/mysql%E5%8F%AF%E9%87%8D%E5%A4%8D%E8%AF%BB%E4%B8%8B%E7%94%A8for-update%E5%AF%BC%E8%87%B4%E7%9A%84%E6%AD%BB%E9%94%81/">mysql可重复读下用for update导致的死锁</a>
          </li>
        
          <li>
            <a href="/2020/05/05/2020-05/BeanCopier%E6%B5%8B%E8%AF%84%E6%8A%A5%E5%91%8A/">BeanCopier测评报告</a>
          </li>
        
      </ul>
    </div>
  </div>

  
    

  
</aside>

      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-left">
      &copy; 2014 - 2020 风梦七&nbsp;|&nbsp;
      主题 <a href="https://github.com/giscafer/hexo-theme-cafe/" target="_blank">Cafe</a>
    </div>
     <div id="footer-right">
      联系方式&nbsp;|&nbsp;296671657@qq.com
    </div>
  </div>
</footer>
 
<script src="/jquery/jquery.min.js"></script>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">首页</a>
  
    <a href="/archives" class="mobile-nav-link">归档</a>
  
    <a href="/about" class="mobile-nav-link">关于</a>
  
</nav>
    <img class="back-to-top-btn" src="/images/fly-to-top.png"/>
<script>
// Elevator script included on the page, already.
window.onload = function() {
  var elevator = new Elevator({
    selector:'.back-to-top-btn',
    element: document.querySelector('.back-to-top-btn'),
    duration: 1000 // milliseconds
  });
}
</script>
      

  
    <script>
      var cloudTieConfig = {
        url: document.location.href, 
        sourceId: "",
        productKey: "e2fb4051c49842688ce669e634bc983f",
        target: "cloud-tie-wrapper"
      };
    </script>
    <script src="https://img1.ws.126.net/f2e/tie/yun/sdk/loader.js"></script>
    

  







<!-- author:forvoid begin -->
<!-- author:forvoid begin -->

<!-- author:forvoid end -->

<!-- author:forvoid end -->


  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      })
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      })
    </script>
    <script type="text/javascript" src="https://cdn.rawgit.com/mathjax/MathJax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


 
<script src="/js/is.js"></script>



  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>


<script src="/js/elevator.js"></script>

  </div>
</body>
</html>