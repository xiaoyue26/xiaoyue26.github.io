<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>笔记本</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="笔记本">
<meta property="og:url" content="http://xiaoyue26.github.io/page/16/index.html">
<meta property="og:site_name" content="笔记本">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="风梦七">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="笔记本" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    
  
  
<link rel="stylesheet" href="/css/style.css">

  

<meta name="generator" content="Hexo 4.2.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    
    <div id="header-inner" class="inner">
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://xiaoyue26.github.io"></form>
      </div>
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">首页</a>
        
          <a class="main-nav-link" href="/archives">归档</a>
        
          <a class="main-nav-link" href="/about">关于</a>
        
      </nav>
      
    </div>
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">笔记本</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">风梦七</a>
        </h2>
      
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-2018-01/java并发编程实战笔记-8章" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/01/01/2018-01/java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98%E7%AC%94%E8%AE%B0-8%E7%AB%A0/" class="article-date">
  <time datetime="2018-01-01T07:34:18.000Z" itemprop="datePublished">2018-01-01</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/java/">java</a>►<a class="article-category-link" href="/categories/java/%E5%B9%B6%E5%8F%91/">并发</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/01/01/2018-01/java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98%E7%AC%94%E8%AE%B0-8%E7%AB%A0/">java并发编程实战笔记-8章</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
        
        <h1 id="线程池的使用"><a href="#线程池的使用" class="headerlink" title="线程池的使用"></a>线程池的使用</h1><p>这章介绍实际应用中配置调优的一些高级选项. 以及各种坑.</p>
<h1 id="8-1-任务与执行策略的隐形耦合"><a href="#8-1-任务与执行策略的隐形耦合" class="headerlink" title="8.1  任务与执行策略的隐形耦合"></a>8.1  任务与执行策略的隐形耦合</h1><p>有些任务需要指定执行策略:</p>
<ol>
<li>依赖性任务: 就是任务之间不独立</li>
<li>线程不封闭的: 就是只能单线程跑的.</li>
<li>对响应时间敏感的: 如GUI. </li>
<li>使用ThreadLocal的: 线程池会重用线程. 因此可能有风险.</li>
</ol>
<h2 id="8-1-1-死锁"><a href="#8-1-1-死锁" class="headerlink" title="8.1.1 死锁"></a>8.1.1 死锁</h2><p>有界线程池不能无限提交. 如果里头的任务都死锁了,线程池也死锁了.</p>
<h2 id="8-1-2-响应时间"><a href="#8-1-2-响应时间" class="headerlink" title="8.1.2 响应时间"></a>8.1.2 响应时间</h2><p>如果任务都很慢,线程池的响应时间自然也慢.<br>可以限时或者增大线程池容量.</p>
<h1 id="8-2-线程池大小公式"><a href="#8-2-线程池大小公式" class="headerlink" title="8.2 线程池大小公式"></a>8.2 线程池大小公式</h1><p>N = cpu数量 = Runtime.getRuntime().availableProcessors();<br>U = 目标cpu利用率<br>W/C= 等待时间和执行时间的比率 (响应度)<br>SIZE = N*U/(1+W/C) </p>
<h1 id="8-3-配置ThreadPoolExecutor"><a href="#8-3-配置ThreadPoolExecutor" class="headerlink" title="8.3 配置ThreadPoolExecutor"></a>8.3 配置ThreadPoolExecutor</h1><p>可以通过Executors获取jdk设计好的一些线程池实现.</p>
<h2 id="8-3-1-线程的创建与取消"><a href="#8-3-1-线程的创建与取消" class="headerlink" title="8.3.1 线程的创建与取消"></a>8.3.1 线程的创建与取消</h2><p>基本大小: 没有任务时候的线程大小.<br>最大大小: 上限.<br>存活时间: 线程空闲时间达到存活时间,则被回收.</p>
<h2 id="8-3-2-管理队列任务"><a href="#8-3-2-管理队列任务" class="headerlink" title="8.3.2 管理队列任务"></a>8.3.2 管理队列任务</h2><p>线程池满了以后,提交的任务进入等待队列.<br>newFixedThreadPool: 无界等待队列 LinkedBlockingQueue<br>newSingleThreadExecutor: 无界等待队列 LinkedBlockingQueue</p>
<p>有界等待队列的话,需要饱和策略. </p>
<h2 id="8-3-3-饱和策略"><a href="#8-3-3-饱和策略" class="headerlink" title="8.3.3 饱和策略"></a>8.3.3 饱和策略</h2><ol>
<li>中止(默认): abort. 抛异常.</li>
<li>调用者运行: 让主线程自己干. 拥塞会外延到TCP层. </li>
<li>丢弃: 抛弃该任务. 不抛异常.</li>
<li>丢弃最老: 丢弃下一个将要执行的.(如果用了优先级队列,就是抛弃优先级最高的,会造成错误.)</li>
</ol>
<h1 id="8-4-扩展ThreadPoolExecutor"><a href="#8-4-扩展ThreadPoolExecutor" class="headerlink" title="8.4 扩展ThreadPoolExecutor"></a>8.4 扩展ThreadPoolExecutor</h1><p>需要实际需求和应用案例才能学会. </p>
<h1 id="8-5-递归算法的并行化"><a href="#8-5-递归算法的并行化" class="headerlink" title="8.5 递归算法的并行化"></a>8.5 递归算法的并行化</h1><p>首先循环可以并行化:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="keyword">final</span> Ele e: eles)&#123;</span><br><span class="line">    exec.execute(</span><br><span class="line">    <span class="keyword">new</span> Runnable()&#123;</span><br><span class="line">      <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span></span>&#123;process(e);&#125;</span><br><span class="line">    &#125;</span><br><span class="line">    );</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>递归也一样, 遍历依然是递归的, 但把每一个节点的计算收集到线程池中,异步计算.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dfs(node,exec,results)&#123;</span><br><span class="line"> exec.execute(...);</span><br><span class="line"> dfs(node.children());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<p>第九章是图形界面,略过.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://xiaoyue26.github.io/2018/01/01/2018-01/java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98%E7%AC%94%E8%AE%B0-8%E7%AB%A0/" data-id="ck96cxpnu00aemaam6euicert" class="article-share-link">分享</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/java/" rel="tag">java</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-2017-12/hive调优之数据倾斜" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/12/26/2017-12/hive%E8%B0%83%E4%BC%98%E4%B9%8B%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C/" class="article-date">
  <time datetime="2017-12-26T11:35:00.000Z" itemprop="datePublished">2017-12-26</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/hadoop/">hadoop</a>►<a class="article-category-link" href="/categories/hadoop/hive/">hive</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/12/26/2017-12/hive%E8%B0%83%E4%BC%98%E4%B9%8B%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C/">hive调优之数据倾斜</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
        
        <p>上一篇中记录了hive调优的一些常规手段. 但对于某些数据集, 常规手段是无能为力的, 例如数据倾斜时.</p>
<p>对于hive而言,数据倾斜就是某个reducer跑得特别慢,这一点可以从日志中reducer开在99%或某个值很久看出,也可以从web ui中查看:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">运行后:</span><br><span class="line">http:&#x2F;&#x2F;xxx:19888&#x2F;jobhistory&#x2F;tasks&#x2F;job_1472710912354_3070682&#x2F;r</span><br><span class="line">运行前:</span><br><span class="line">http:&#x2F;&#x2F;xxx:8088&#x2F;proxy&#x2F;application_1472710912354_3070684&#x2F;mapreduce&#x2F;tasks&#x2F;job_1472710912354_3070684&#x2F;r</span><br></pre></td></tr></table></figure>
<p>如果具体看日志的话,会发现大部分时间在进行外排.<br>对于这种任务最重要的是消除外排,有如下几种优化手段:</p>
<h2 id="1-加内存"><a href="#1-加内存" class="headerlink" title="1. 加内存"></a>1. 加内存</h2><p>最简单粗暴就是给reduce加内存了. 让它别外排:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> mapreduce.reduce.memory.mb=<span class="number">10240</span>;</span><br></pre></td></tr></table></figure>
<p>类似的,如果mapper内存不够,可以减小每个mapper处理的数据量,增大mapper的数量:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> mapreduce.input.fileinputformat.split.maxsize=<span class="number">64000000</span>;</span><br></pre></td></tr></table></figure>

<h2 id="2-倾斜key单独处理"><a href="#2-倾斜key单独处理" class="headerlink" title="2. 倾斜key单独处理"></a>2. 倾斜key单独处理</h2><p>第二种手段也比较简单, 就是把出现倾斜的key找出来,假如很少的话,可以把它们摘出来,单独处理(或遗弃). 开启hive自动消除数据倾斜:(效果有效)</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.optimize.skewjoin = <span class="literal">true</span>;</span><br><span class="line"><span class="keyword">set</span> hive.skewjoin.key=<span class="number">1000</span>;</span><br><span class="line"><span class="keyword">set</span> hive.groupby.skewindata=<span class="literal">true</span>;</span><br><span class="line"><span class="keyword">set</span> hive.groupby.mapaggr.checkinterval=<span class="number">100</span>;</span><br></pre></td></tr></table></figure>

<h2 id="3-局部聚合-1-相同value聚合"><a href="#3-局部聚合-1-相同value聚合" class="headerlink" title="3. 局部聚合(1): 相同value聚合"></a>3. 局部聚合(1): 相同value聚合</h2><p>(没有什么优化是增加一个阶段不能解决的.如果有,就再加一个阶段)<br>为了减少最后汇聚到reducer上的数据量,可以在之前增加一个阶段,对某个key的数据进行局部聚合. </p>
<p>以某次需求为例,需要求各个省市区维度下的丢包率\延迟的50,90,99分位数.数据量每天200G. 分位数计算极其耗时, 尤其是计算周统计数据时, 数据量达到TB级. </p>
<p>在使用了前一篇优化笔记手段以及上述手段后,依然耗时4小时.原来查询最耗时的部分如下:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span>  es</span><br><span class="line">       ,province</span><br><span class="line">       ,city</span><br><span class="line">       ,ipOprator</span><br><span class="line">       ,percentile(xxx,<span class="number">0.5</span>,<span class="number">0.9</span>,<span class="number">0.99</span>)</span><br><span class="line"><span class="keyword">FROM</span> ttt</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> es,province,ipOprator <span class="keyword">with</span> <span class="keyword">cube</span></span><br></pre></td></tr></table></figure>
<p>查看hive的percentile源码实现,其对于同一个key的处理逻辑大致这么几步:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">(依次输入每个value)</span><br><span class="line">1. O(n)</span><br><span class="line">把所有value放进一个Map&lt;value,LongWriteable&gt;里,相同的value则增加map中的计数值;</span><br><span class="line">2. O(nlogn)</span><br><span class="line">在reduce中把map中的所有entry放入一个List中,然后对List根据value值进行全排序(&#96;Collections.sort(entriesList, new MyComparator());&#96;);</span><br><span class="line">3. O(n)</span><br><span class="line">从头开始扫一遍上一步的List, 根据计数器的值总和,分位数,定位到对应的分位数,返回.</span><br></pre></td></tr></table></figure>
<p>将其重写为可以进行局部聚合, 从而略去第一步:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span>  es</span><br><span class="line">       ,province</span><br><span class="line">       ,city</span><br><span class="line">       ,ipOprator</span><br><span class="line">      ,percent_new(c1,<span class="keyword">num</span>,<span class="number">0.5</span>,<span class="number">0.9</span>,<span class="number">0.99</span>)</span><br><span class="line"><span class="keyword">FROM</span> (<span class="keyword">select</span> es,province,ipOprator,c1,<span class="keyword">count</span>(<span class="number">1</span>) <span class="keyword">as</span> <span class="keyword">num</span></span><br><span class="line">    <span class="keyword">FROM</span> xxx</span><br><span class="line">    <span class="keyword">GROUP</span> <span class="keyword">BY</span> es,province,ipOprator,c1</span><br><span class="line">) <span class="keyword">as</span> t </span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> es,province,ipOprator <span class="keyword">with</span> <span class="keyword">cube</span></span><br></pre></td></tr></table></figure>
<p>优化后,时间缩短到30分钟.</p>
<ul>
<li>TODO:<br>优化第二步中的全排序. </li>
</ul>
<h2 id="4-局部聚合2-相同key聚合"><a href="#4-局部聚合2-相同key聚合" class="headerlink" title="4. 局部聚合2: 相同key聚合"></a>4. 局部聚合2: 相同key聚合</h2><p>由于上一案例中的聚合函数是分位数计算,聚合的粒度只能达到相同value聚合,对于其他聚合函数,如最大值,最小值等,如果语义上能对相同key先聚合,问题的规模就可以进一步缩小. 方法是先把相同key的数据分拆成不同的key,加上前缀或后缀 如:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">key -&gt; key_1</span><br><span class="line">key -&gt; key_2</span><br><span class="line">...</span><br><span class="line">key -&gt; key_10</span><br></pre></td></tr></table></figure>
<p>分拆的数量等于并行度,取决于原有的数据集, 然后先进行一阶段聚合,最后去掉前缀后缀,再进行一次聚合得到最后的结果.<br>这种方法的关键就是要求同一个key的聚合计算可以分拆.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://xiaoyue26.github.io/2017/12/26/2017-12/hive%E8%B0%83%E4%BC%98%E4%B9%8B%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C/" data-id="ck96cxpnk0090maam4d5qhboj" class="article-share-link">分享</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/hive/" rel="tag">hive</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-2017-12/hive调优" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/12/25/2017-12/hive%E8%B0%83%E4%BC%98/" class="article-date">
  <time datetime="2017-12-25T08:45:15.000Z" itemprop="datePublished">2017-12-25</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/hadoop/">hadoop</a>►<a class="article-category-link" href="/categories/hadoop/hive/">hive</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/12/25/2017-12/hive%E8%B0%83%E4%BC%98/">hive sql调优</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
        
        <p>这里记录一下hive任务调优的三(n)板斧.</p>
<h1 id="map-join"><a href="#map-join" class="headerlink" title="map join"></a>map join</h1><p>对于存在join的sql,首先最简单的就是开启map join:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.auto.convert.join = <span class="literal">true</span> ; <span class="comment">-- 开启自动转化成mapjoin</span></span><br><span class="line"><span class="keyword">set</span> hive.mapjoin.smalltable.filesize = <span class="number">2500000</span> ; <span class="comment">-- 设置广播小表size</span></span><br></pre></td></tr></table></figure>
<p>sql中足够小的表应该放在join操作左边. 由于小表数据会被广播到各个节点,消除了shuffle运算,提高了运算效率.<br>前提当然是存在足够小的表. 实际业务中一般是各种维度表.</p>
<h1 id="排序消除"><a href="#排序消除" class="headerlink" title="排序消除"></a>排序消除</h1><blockquote>
<p>注: 是否加速取决于数据集.</p>
</blockquote>
<p>排序属于非常耗时的操作(<code>O(nlogn)</code>),所以对于order by,sort by语句,可以从语义上寻找突破口. 例如对于每天最后一次的用户行为,原来的可能是这样写的:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> *</span><br><span class="line">(<span class="keyword">select</span> userid</span><br><span class="line">      ,<span class="keyword">url</span></span><br><span class="line">      ,row_number(<span class="keyword">partition</span> <span class="keyword">by</span> userid <span class="keyword">order</span> <span class="keyword">by</span> <span class="built_in">bigint</span>(<span class="built_in">timestamp</span>)<span class="keyword">DESC</span>) <span class="keyword">as</span> <span class="keyword">rank</span></span><br><span class="line"><span class="keyword">FROM</span> xxxx</span><br><span class="line">)<span class="keyword">AS</span> a </span><br><span class="line"><span class="keyword">where</span> <span class="keyword">rank</span>=<span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>可以改为先求最大时间戳,再进行<code>join</code>(<code>map join</code>):</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span></span><br><span class="line">(<span class="keyword">select</span> userid,<span class="keyword">max</span>(<span class="built_in">bigint</span>(<span class="built_in">timestamp</span>)) <span class="keyword">from</span> xxx <span class="keyword">group</span> <span class="keyword">by</span> userid) <span class="keyword">as</span> a</span><br><span class="line"><span class="keyword">join</span> xxx <span class="keyword">on</span> b </span><br><span class="line">  <span class="keyword">on</span> a.timestamp=b.timestamp</span><br></pre></td></tr></table></figure>
<p>这样更改后虽然消除了排序操作,但是引入了shuffle操作(join)(并且对于hive要laod两遍数据),因此是否加速取决于具体的数据集. 对于任务卡死(或者很慢)在reduce阶段的hive任务,可以尝试进行排序消除.<br>实际经验来看,如果数据量大到导致外排,需要消除<code>order by</code>.</p>
<h1 id="distinct消除-两阶段group-by"><a href="#distinct消除-两阶段group-by" class="headerlink" title="distinct消除(两阶段group by)"></a>distinct消除(两阶段group by)</h1><p>回字有4种写法,而distinct一般有2种.</p>
<h2 id="1-多列或1列去重"><a href="#1-多列或1列去重" class="headerlink" title="1. 多列或1列去重"></a>1. 多列或1列去重</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="keyword">distinct</span> a,b,udf(c1) <span class="keyword">as</span> c2 <span class="keyword">from</span> xxx</span><br></pre></td></tr></table></figure>
<p>由于hive是通过<code>group by</code>实现distinct,上述sql其实等效于:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> a,b,udf(c1) <span class="keyword">from</span> xxx <span class="keyword">group</span> <span class="keyword">by</span> a,b,udf(c1)</span><br></pre></td></tr></table></figure>
<p>可以通过explain查看两者的执行计划是完全一致的.<br>如果能确定udf是单射变换,也就是c1到c2是一对一,而没有多对一,可以等效改写为:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> a,b,udf(c1) <span class="keyword">from</span> xxx <span class="keyword">group</span> <span class="keyword">by</span> a,b,c1</span><br></pre></td></tr></table></figure>
<p>总之,对于这个场景下的distinct使用,如果没有udf,可以不进行消除.</p>
<h2 id="2-聚合函数中使用-如uv计算"><a href="#2-聚合函数中使用-如uv计算" class="headerlink" title="2. 聚合函数中使用(如uv计算)"></a>2. 聚合函数中使用(如uv计算)</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> dt,<span class="keyword">count</span>(<span class="keyword">distinct</span> userid) <span class="keyword">as</span> uv </span><br><span class="line"><span class="keyword">from</span> xxx</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> dt</span><br></pre></td></tr></table></figure>
<p>这种聚合函数中使用distinct属于比较常见的业务查询需求,hive执行时会把所有数据灌到一个reducer中,毫无并行度.<br>可以使用两阶段group by进行优化,写法:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> dt,<span class="keyword">count</span>(<span class="number">1</span>)</span><br><span class="line"><span class="keyword">FROM</span></span><br><span class="line">(<span class="keyword">select</span> <span class="keyword">distinct</span> dt,userid <span class="keyword">from</span> xxx) <span class="keyword">as</span> t </span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> dt</span><br></pre></td></tr></table></figure>
<p>这样去重操作在第一个阶段分担到了多个reducer上,速度提升很多.</p>
<p>实际优化的时候,主要有三种情况阻碍,无法直接改写:</p>
<h3 id="1-同一列不同条件的count-distinct"><a href="#1-同一列不同条件的count-distinct" class="headerlink" title="1. 同一列不同条件的count distinct"></a>1. 同一列不同条件的count distinct</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> dt</span><br><span class="line">,<span class="keyword">count</span>(<span class="keyword">distinct</span> userid) <span class="keyword">as</span> seven_uv</span><br><span class="line">,<span class="keyword">count</span>(<span class="keyword">distinct</span> <span class="keyword">if</span>(c1&gt;xxx,userid,<span class="literal">NULL</span>)) <span class="keyword">as</span> new_uv</span><br><span class="line">,<span class="keyword">count</span>(<span class="keyword">distinct</span> <span class="keyword">if</span>(c2&gt;xxx,userid,<span class="literal">NULL</span>)) <span class="keyword">as</span> query_uv</span><br></pre></td></tr></table></figure>
<p>可以通过增加标记列转化:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> dt</span><br><span class="line">,<span class="keyword">count</span>(userid) <span class="keyword">as</span> seven_uv</span><br><span class="line">,<span class="keyword">count</span>(<span class="keyword">if</span>(is_new=<span class="number">1</span>,userid,<span class="literal">NULL</span>)) <span class="keyword">as</span> new_uv</span><br><span class="line">,<span class="keyword">count</span>(<span class="keyword">if</span>(is_query=<span class="number">1</span>,userid,<span class="literal">NULL</span>)) <span class="keyword">as</span> query_uidnum <span class="comment">-- query_uv</span></span><br><span class="line"><span class="keyword">from</span> </span><br><span class="line">(...</span><br><span class="line">,<span class="keyword">max</span>(<span class="keyword">if</span>(c1&gt;xxx,<span class="number">1</span>,<span class="number">0</span>)) is_new</span><br><span class="line">,<span class="keyword">max</span>(<span class="keyword">if</span>(c2&gt;xxx,<span class="number">1</span>,<span class="number">0</span>)) <span class="keyword">as</span> is_query</span><br><span class="line">...) <span class="keyword">as</span> tt</span><br></pre></td></tr></table></figure>

<h3 id="2-多维聚合-group-by-with-cube"><a href="#2-多维聚合-group-by-with-cube" class="headerlink" title="2. 多维聚合(group by with cube)"></a>2. 多维聚合(group by with cube)</h3><p>可以通过一行变多行,手动维护grouping sets的组合:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">lateral view explode(array('全部',platform)) tt1 as platform_t</span><br><span class="line">lateral view explode(array('全部',version)) tt2 as version_t</span><br><span class="line">lateral view explode(array('全部',vendor)) tt3 as vendor_t</span><br><span class="line">lateral view explode(array('全部',phase)) tt4 as phase_t</span><br><span class="line">GROUP BY platform_t,version_t,vendor_t,phase_t</span><br><span class="line">     ,userid</span><br></pre></td></tr></table></figure>

<h2 id="不同列聚合"><a href="#不同列聚合" class="headerlink" title="不同列聚合."></a>不同列聚合.</h2><p>例如:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">count(distinct userid)</span><br><span class="line">count(distinct deviceid)</span><br></pre></td></tr></table></figure>
<p>这种如果确实出现了reduce卡死,可以进行分拆成两个查询分别计算(load两遍数据),最后join到一起. 代码会比较长. </p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://xiaoyue26.github.io/2017/12/25/2017-12/hive%E8%B0%83%E4%BC%98/" data-id="ck96cxpnl0094maam0f7p0mtm" class="article-share-link">分享</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/hive/" rel="tag">hive</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-2017-12/hive之bug汇总" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/12/20/2017-12/hive%E4%B9%8Bbug%E6%B1%87%E6%80%BB/" class="article-date">
  <time datetime="2017-12-20T10:01:19.000Z" itemprop="datePublished">2017-12-20</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/hadoop/">hadoop</a>►<a class="article-category-link" href="/categories/hadoop/hive/">hive</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/12/20/2017-12/hive%E4%B9%8Bbug%E6%B1%87%E6%80%BB/">hive之bug汇总</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
        
        <p>这里总结一下hive的bug,或者说表现与spark sql不同的feature(bug?).<br>由于hive的distinct实际实现为group by,因此下述的group by相关bug也适用于distinct.</p>
<h1 id="1-列重命名BUG"><a href="#1-列重命名BUG" class="headerlink" title="1. 列重命名BUG"></a>1. 列重命名BUG</h1><blockquote>
<p>导致结果错误.<br>spark-sql能正常处理.</p>
</blockquote>
<p>子查询中重命名列时,如果和原有表中某列名相同,并且where条件中有那一列,取原有表的列值.<br>构造测试用例:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span></span><br><span class="line">(<span class="keyword">SELECT</span> <span class="number">123</span> <span class="keyword">as</span> paperid</span><br><span class="line"><span class="keyword">FROM</span>  temp.feng_test1</span><br><span class="line"><span class="keyword">where</span> paperid=<span class="number">70455</span></span><br><span class="line">)<span class="keyword">AS</span> a</span><br></pre></td></tr></table></figure>
<p>上述查询的结果是70455,而不是我们想象中的123.<br>而这个查询:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span></span><br><span class="line">(<span class="keyword">SELECT</span> <span class="number">123</span> <span class="keyword">as</span> paperid</span><br><span class="line"><span class="keyword">FROM</span>  temp.feng_test1</span><br><span class="line">)<span class="keyword">AS</span> a</span><br></pre></td></tr></table></figure>
<p>或这个查询:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span></span><br><span class="line">(<span class="keyword">SELECT</span> <span class="number">123</span> <span class="keyword">as</span> paperid</span><br><span class="line"><span class="keyword">FROM</span>  (<span class="keyword">select</span> <span class="number">70455</span> <span class="keyword">as</span> paperid) <span class="keyword">as</span> t </span><br><span class="line"><span class="keyword">where</span> paperid=<span class="number">70455</span></span><br><span class="line">)<span class="keyword">AS</span> a</span><br></pre></td></tr></table></figure>
<p>都能正确返回123.</p>
<h1 id="2-GROUP-BY-UDF-Serde复合bug"><a href="#2-GROUP-BY-UDF-Serde复合bug" class="headerlink" title="2. GROUP BY+UDF+Serde复合bug"></a>2. GROUP BY+UDF+Serde复合bug</h1><blockquote>
<p>导致抛异常退出.<br>spark-sql能正常处理.</p>
</blockquote>
<p>GROUP BY,自定义UDF和自定义Serde都能正常独立工作.<br>这是一个多重条件下产生的bug:<br>1.表定义为string,而自定义的serde类放入了long对象;(bug)<br>2.自定义UDF使用简便写法(继承UDF,复杂写法为继承GenericUDF);(正常行为)<br>3.运行如下语句:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> xx</span><br><span class="line"><span class="keyword">from</span> <span class="string">`1中serde的表`</span></span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> <span class="string">`2中udf`</span></span><br></pre></td></tr></table></figure>

<p>这个bug可以说是serde写得有问题导致的,严格来说hive没有太大问题.<br>原因是hive调用简单udf时,是运行时进行反射,填入方法的参数,实参与形参定义不同抛出异常.</p>
<h1 id="3-GROUP-BY-重复列-BUG"><a href="#3-GROUP-BY-重复列-BUG" class="headerlink" title="3. GROUP BY+重复列 BUG"></a>3. GROUP BY+重复列 BUG</h1><blockquote>
<p>导致结果错误.<br>spark-sql能正常处理.</p>
</blockquote>
<p>GROUP BY 时,如果有涉及引用的重复列, 如构造用例中的alist[0],由于hive在各种方面都会重用引用,会导致bug.<br>用例的输出结果为: <code>1,1,1</code>.<br>而不是我们想象中的: <code>1,1,3333</code>.</p>
<p>构造用例如下:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> aid,bid,mistake</span><br><span class="line"><span class="keyword">FROM</span></span><br><span class="line">      (<span class="keyword">SELECT</span> <span class="number">1</span> <span class="keyword">as</span> aid</span><br><span class="line">      )<span class="keyword">AS</span> a</span><br><span class="line"><span class="keyword">JOIN</span></span><br><span class="line">      (<span class="keyword">SELECT</span> alist[<span class="number">0</span>] <span class="keyword">as</span> bid</span><br><span class="line">            ,mistake</span><br><span class="line">      <span class="keyword">FROM</span> (<span class="keyword">SELECT</span> <span class="number">2</span> <span class="keyword">as</span> courseid) <span class="keyword">AS</span> a</span><br><span class="line">      <span class="keyword">JOIN</span> (<span class="keyword">SELECT</span> <span class="number">2</span> <span class="keyword">as</span> courseid</span><br><span class="line">                  ,<span class="string">'3333'</span> <span class="keyword">as</span> mistake</span><br><span class="line">                  ,<span class="built_in">array</span>(<span class="number">1</span>) <span class="keyword">as</span> alist</span><br><span class="line">            ) <span class="keyword">AS</span> b</span><br><span class="line">        <span class="keyword">ON</span> a.courseid=b.courseid</span><br><span class="line">      <span class="keyword">GROUP</span> <span class="keyword">BY</span> alist[<span class="number">0</span>]</span><br><span class="line">              ,alist[<span class="number">0</span>]</span><br><span class="line">              ,mistake</span><br><span class="line">      )<span class="keyword">AS</span> b</span><br><span class="line"> <span class="keyword">ON</span> aid=bid</span><br></pre></td></tr></table></figure>

<h1 id="4-row-number-数据类型溢出-bug"><a href="#4-row-number-数据类型溢出-bug" class="headerlink" title="4. row_number + 数据类型溢出 bug"></a>4. row_number + 数据类型溢出 bug</h1><blockquote>
<p>导致结果错误.<br>spark-sql能正常处理.</p>
</blockquote>
<p>假设tp是一个字符串类型,强行转换成int类型时,如果发生数据溢出,比如值是13位时间戳(1514285700375),排序行为将不可预测.既不是降序也不是升序.</p>
<p>构造错误样例如下:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> userid,phaseid,tp</span><br><span class="line">,row_number()<span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> userid <span class="keyword">order</span> <span class="keyword">by</span> <span class="built_in">int</span>(tp)) <span class="keyword">as</span> <span class="keyword">rank</span></span><br><span class="line"><span class="keyword">from</span> xxxx</span><br></pre></td></tr></table></figure>

<p>正确样例:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> userid,phaseid,tp</span><br><span class="line">,row_number()<span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> userid <span class="keyword">order</span> <span class="keyword">by</span> <span class="built_in">bigint</span>(tp)) <span class="keyword">as</span> <span class="keyword">rank</span></span><br><span class="line"><span class="keyword">from</span> xxxx</span><br></pre></td></tr></table></figure>

<h1 id="5-sort-array-BUG-Feature-函数副作用"><a href="#5-sort-array-BUG-Feature-函数副作用" class="headerlink" title="5. sort_array BUG(Feature) 函数副作用"></a>5. sort_array BUG(Feature) 函数副作用</h1><blockquote>
<p>导致结果错误.<br>spark-sql能正确处理.</p>
</blockquote>
<p>hive中对数组进行排序后,会改变原有数组.(会在原有数组基础上排序)<br>spark-sql则会返回一个深拷贝,不改变原有数组.</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> alist</span><br><span class="line">      ,sort_array(alist) <span class="keyword">as</span> alist2</span><br><span class="line"><span class="keyword">FROM</span></span><br><span class="line">(<span class="keyword">select</span> <span class="built_in">array</span>(<span class="number">1</span>,<span class="number">3</span>,<span class="number">2</span>) <span class="keyword">as</span> alist</span><br><span class="line">)<span class="keyword">AS</span> t</span><br></pre></td></tr></table></figure>


      
    </div>
    <footer class="article-footer">
      <a data-url="http://xiaoyue26.github.io/2017/12/20/2017-12/hive%E4%B9%8Bbug%E6%B1%87%E6%80%BB/" data-id="ck96cxpnj008xmaamc8xl8r5i" class="article-share-link">分享</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/hive/" rel="tag">hive</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-2017-12/mysql调优小记" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/12/07/2017-12/mysql%E8%B0%83%E4%BC%98%E5%B0%8F%E8%AE%B0/" class="article-date">
  <time datetime="2017-12-07T10:49:56.000Z" itemprop="datePublished">2017-12-07</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/mysql/">mysql</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/12/07/2017-12/mysql%E8%B0%83%E4%BC%98%E5%B0%8F%E8%AE%B0/">mysql调优小记</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
        
        <ul>
<li>摘要<blockquote>
<p>mysql表出现慢查询,单表数据量500W<del>700W条. 每天2</del>3W条.<br>措施: </p>
<ol>
<li>优化查询语句; </li>
<li>更改存储引擎.</li>
<li>优化索引.</li>
</ol>
</blockquote>
</li>
</ul>
<h3 id="详情"><a href="#详情" class="headerlink" title="详情"></a>详情</h3><p>同事去塞班岛玩前留了个大坑,导致网站报表卡死刷不开.</p>
<h3 id="STEP-1"><a href="#STEP-1" class="headerlink" title="STEP 1"></a>STEP 1</h3><p>进入后台:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">show</span> <span class="keyword">processlist</span></span><br></pre></td></tr></table></figure>
<p>发现Query很多,<code>show full processlist</code>找出查询语句,发现多表join的时候没有利用到索引.<br>查询语句模式如下:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">explain</span> <span class="keyword">select</span> ...</span><br></pre></td></tr></table></figure>
<p>发现没有用上索引,更改查询语句。</p>
<ul>
<li><p><code>explain</code>查询计划中的<code>type</code>:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">const(system): 根据PRI或Unique key,只取出确定的(一行)数据,常量优化. </span><br><span class="line"></span><br><span class="line">eq_ref: JOIN条件包括了所有索引,并且索引是Unique key. </span><br><span class="line">ref: JOIN条件包括部分索引或不是Unique key.</span><br><span class="line">ref_or_null: WHERE col=exp or col is null</span><br><span class="line"></span><br><span class="line">index_merge: Where id=xx or userid=xxx. 索引合并优化.</span><br><span class="line"></span><br><span class="line">unique_subquery: where col in( <span class="keyword">select</span> <span class="keyword">id</span> <span class="keyword">from</span> xxx). 这里<span class="keyword">id</span>唯一.</span><br><span class="line">index_subquery: 同上,只是<span class="keyword">id</span>不唯一.</span><br><span class="line"></span><br><span class="line"><span class="keyword">range</span>: 索引在某个范围内.</span><br><span class="line"><span class="keyword">all</span>: 扫全表</span><br></pre></td></tr></table></figure>
</li>
<li><p>TODO:<br>研究除了子查询以外的方式使用索引.</p>
</li>
</ul>
<p>此外, 索引对于数据类型敏感, 查询中存在字符串和date类型相等的时候, 无法利用索引,<br>需要将date类型转成字符串.</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dt = date_format(date_sub(current_date, interval 1 day), '%Y-%m-%d')</span><br></pre></td></tr></table></figure>

<h3 id="STEP-2"><a href="#STEP-2" class="headerlink" title="STEP 2"></a>STEP 2</h3><p>检查后台,发现许多连接状态都是:<br><code>waiting for table level lock</code>.<br>进一步发现这几张表的存储引擎是<code>MYISAM</code>,而不是默认的<code>innodb</code>.<br>由于<code>myisam</code>引擎只有表级锁,不符合我们的使用要求.于是我把涉及到的几张表引擎都改为<code>innodb</code>.</p>
<h3 id="STEP-3"><a href="#STEP-3" class="headerlink" title="STEP 3"></a>STEP 3</h3><p>修改后,查询不会卡死(毕竟不扫全表了ORZ),降低到40s,但还是太慢了.<br>进一步检查explain结果,发现<code>key_len</code>太长了.<br>于是重新设计索引, 把筛选度高的放前面(利用最左前缀), 并且根据具体业务\语义,尽量缩短索引字段的长度,<br>实在无法缩短的则取其中一部分. 最后查询缩短到0.04sec,几个报表都是秒出.  </p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://xiaoyue26.github.io/2017/12/07/2017-12/mysql%E8%B0%83%E4%BC%98%E5%B0%8F%E8%AE%B0/" data-id="ck96cxpni008vmaamfhcygtrf" class="article-share-link">分享</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/mysql/" rel="tag">mysql</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-2017-12/sqoop的SQL注入漏洞" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/12/01/2017-12/sqoop%E7%9A%84SQL%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/" class="article-date">
  <time datetime="2017-12-01T13:29:38.000Z" itemprop="datePublished">2017-12-01</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/hadoop/">hadoop</a>►<a class="article-category-link" href="/categories/hadoop/sqoop/">sqoop</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/12/01/2017-12/sqoop%E7%9A%84SQL%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/">sqoop的SQL注入漏洞</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
        
        <p>早上起来发现公司有一个sqoop导表任务挂了,查看日志错误提示大致如下:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">INFO [main] org.apache.sqoop.mapreduce.db.DBRecordReader: Executing query: SELECT id,xxx FROM taname where ( udid &gt;&#x3D; &#39;abc&#39; ) AND ( udid &lt; &#39;xx&#39; ;select pg_sleep(3) --)</span><br><span class="line">ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near &#39;)&#39; at line 1</span><br></pre></td></tr></table></figure>

<p>也就是说sqoop生成的查询语句错了,搜了一下源码没有发现哪里会生成</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> pg_sleep(<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<p>这种语句,而且我们用的是mysql,按理说不应当生成pgsql.<br>而且这个导表任务也不是第一天上线了,此前一直是好好的.</p>
<p>首先按照经验,调整了分隔符配置;查看表结构发现有blob字段,去掉了配置中的direct模式,均没有效果.<br>其次查job的其他日志,发现其他几个mapper都成功了,只有1个mapper挂了,于是调整并行度,把并行度调成1,导表任务就成功了.</p>
<p>回过头来继续研究这个问题.<br>也就是说在分割表数据到几个mapper的时候,划分split的时候,查询语句错了.<br>报错的上一行的日志大致是:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">org.apache.hadoop.mapred.MapTask: Processing split: udid &gt;&#x3D; &#39;xxx&#39; AND udid &lt; &#39;xxx&#39;); select pg_sleep(3) -- &#39;</span><br></pre></td></tr></table></figure>

<p>sqoop划分split的原理:</p>
<ol>
<li><code>--table</code> 按表导: 按主键最大最小取值划分范围,然后按中间值划分split.</li>
<li><code>--query</code> : 按配置中的<code>-- split by</code>参数对应的列取max,min,然后同上.</li>
</ol>
<p>因此如果作为划分列的值中如果有脏数据,sqoop就会被sql注入.<br>因此导致了我们遇到的问题.<br>平时脏数据没有落在分割点上, 今天可能是由于脏数据的比例逐渐上升,终于落在了分割点上,因此导致了任务失败.<br>(<code>pg_sleep</code>一般是用于sql注入.)</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://xiaoyue26.github.io/2017/12/01/2017-12/sqoop%E7%9A%84SQL%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/" data-id="ck96cxpnm0098maam2w3x536l" class="article-share-link">分享</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/sql%E6%B3%A8%E5%85%A5/" rel="tag">sql注入</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/sqoop/" rel="tag">sqoop</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-2017-11/sort命令笔记" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/11/28/2017-11/sort%E5%91%BD%E4%BB%A4%E7%AC%94%E8%AE%B0/" class="article-date">
  <time datetime="2017-11-28T12:51:29.000Z" itemprop="datePublished">2017-11-28</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/shell/">shell</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/11/28/2017-11/sort%E5%91%BD%E4%BB%A4%E7%AC%94%E8%AE%B0/">sort命令笔记</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
        
        <p>语法:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sort [OPTION]... [FILE]...</span><br><span class="line">sort [OPTION]... --files0-from=F</span><br></pre></td></tr></table></figure>

<p>参数:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">-b : 忽略行首空格</span><br><span class="line">-c : 检查文件是否已经按照顺序排列</span><br><span class="line">-d : 忽略除了英文字母,数字,空格以外的字符</span><br><span class="line">-f : 将小写字母视为大写字母</span><br><span class="line">-i : 只考虑040到176之间的ASCII字符,其他的忽略</span><br><span class="line">-m : 合并几个排序好的文件</span><br><span class="line">-n : 按数字大小排列</span><br><span class="line">-o : 输出文件</span><br><span class="line">-r : 倒序排列</span><br><span class="line">-t : 排序时的分隔符</span><br><span class="line">+&lt;起始列&gt;-&lt;结束列&gt;: 排序列范围</span><br></pre></td></tr></table></figure>

<p>示例1:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 默认按第一列的ascii码排序</span></span><br><span class="line">sort log.txt</span><br></pre></td></tr></table></figure>


<p>示例2:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 查看当前mysql线程中的各种状态的数量,按uv最多输出前10个:</span></span><br><span class="line">pipe -e 'show processlist \G' | grep State: |  uniq -c | sort -rn | head -n10</span><br></pre></td></tr></table></figure>


      
    </div>
    <footer class="article-footer">
      <a data-url="http://xiaoyue26.github.io/2017/11/28/2017-11/sort%E5%91%BD%E4%BB%A4%E7%AC%94%E8%AE%B0/" data-id="ck96cxpng008nmaamf3gd0i3x" class="article-share-link">分享</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/shell/" rel="tag">shell</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-2017-11/sed笔记" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/11/28/2017-11/sed%E7%AC%94%E8%AE%B0/" class="article-date">
  <time datetime="2017-11-28T12:44:09.000Z" itemprop="datePublished">2017-11-28</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/shell/">shell</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/11/28/2017-11/sed%E7%AC%94%E8%AE%B0/">sed笔记</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
        
        <p>语法:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Usage: sed [OPTION]... &#123;script-only-if-no-other-script&#125; [input-file]...</span><br></pre></td></tr></table></figure>

<p>动作参数:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">a: 新增</span><br><span class="line">c: 取代</span><br><span class="line">d: 删除</span><br><span class="line">i: 插入</span><br><span class="line">p: 打印</span><br><span class="line">s: 取代</span><br></pre></td></tr></table></figure>


<p>示例1:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 在第四行后添加一行(内容为helloWorld),结果打印到console:</span></span><br><span class="line">sed -e 4a\helloWorld log.txt</span><br><span class="line"><span class="meta">#</span><span class="bash"> 假如文件根本没有第四行,则不会添加.</span></span><br></pre></td></tr></table></figure>


<p>示例2: (-e可以省略)</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 把文件的内容加上行号输出,并且删除第2,3行.</span></span><br><span class="line">nl log.txt | sed '2,3d'</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 删除第3行及之后的行:</span></span><br><span class="line">nl log.txt | sed '3,$d'</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://xiaoyue26.github.io/2017/11/28/2017-11/sed%E7%AC%94%E8%AE%B0/" data-id="ck96cxpnh008pmaam080ybxrd" class="article-share-link">分享</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/shell/" rel="tag">shell</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-2017-11/grep笔记" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/11/28/2017-11/grep%E7%AC%94%E8%AE%B0/" class="article-date">
  <time datetime="2017-11-28T12:24:57.000Z" itemprop="datePublished">2017-11-28</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/shell/">shell</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/11/28/2017-11/grep%E7%AC%94%E8%AE%B0/">grep笔记</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
        
        <p>grep语法:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep [OPTION]... PATTEN [FILE]...</span><br></pre></td></tr></table></figure>

<p>OPTION参数:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-i: 忽略大小写</span><br><span class="line">-v: 反转查找</span><br><span class="line">-w: 只显示全字符合的列</span><br><span class="line">-c或--count: 计算符合范本样式的列数.</span><br></pre></td></tr></table></figure>

<p>示例1:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 计算处于init状态的mysql线程有多少个.</span></span><br><span class="line">pipe -e 'show processlist \G' | grep -c 'State: init'</span><br></pre></td></tr></table></figure>

<p>示例2:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 查找目录/etc/acpi及其目录下所有文件中包含<span class="string">"update"</span>的文件:</span></span><br><span class="line">grep -r update /etc/acpi</span><br></pre></td></tr></table></figure>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://xiaoyue26.github.io/2017/11/28/2017-11/grep%E7%AC%94%E8%AE%B0/" data-id="ck96cxpng008lmaamg8jw5h33" class="article-share-link">分享</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/shell/" rel="tag">shell</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-2017-11/epoll相关基础知识" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/11/06/2017-11/epoll%E7%9B%B8%E5%85%B3%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/" class="article-date">
  <time datetime="2017-11-06T11:52:23.000Z" itemprop="datePublished">2017-11-06</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/java/">java</a>►<a class="article-category-link" href="/categories/java/%E5%B9%B6%E5%8F%91/">并发</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/11/06/2017-11/epoll%E7%9B%B8%E5%85%B3%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/">epoll相关基础知识</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
        
        <h1 id="背景"><a href="#背景" class="headerlink" title="背景:"></a>背景:</h1><p>C10K问题. 并发访问量&gt;=10K =&gt; 维持TCP连接的进程数超过上限.</p>
<ul>
<li>远古解决方案:</li>
</ul>
<ol>
<li>用<code>UDP</code>. (腾讯QQ)</li>
<li><code>select</code>模式. 每个TCP连接占用一个文件描述符, 所以进程能处理的连接最大不能超过1024. </li>
<li><code>poll</code>模式. 每次收到数据需要遍历每一个连接查看哪个连接有数据请求。</li>
</ol>
<p>2002年左右开始的解决方案:</p>
<blockquote>
<p><code>kqueue</code>: FreeBSD<br><code>epoll</code>:  Linux (2.5.44内核)<br><code>IOCP</code>: Windows</p>
</blockquote>
<ul>
<li><p>epoll的编程模型:<br>异步非阻塞回调. <code>Reactor</code>,事件驱动,事件轮询(<code>EventLoop</code>).</p>
</li>
<li><p>新的问题<br><code>epoll</code>编程太繁琐,层层回调/嵌套.</p>
</li>
<li><p>解决方案:</p>
</li>
</ul>
<ol>
<li>默默忍受: 性能最优.</li>
<li>协程,<code>coroutine</code>: 需要解决某个协程密集计算带来的问题.</li>
</ol>
<ul>
<li>协程<br>封装了事件回调,底层库通过保存状态(代码行数,局部变量的值),替程序猿进行回调. 程序猿可以就像一切刚开始的时候那样只写仿佛同步阻塞的代码.</li>
</ul>
<p><code>go</code>语言中具体代码:</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">go</span> doSomething();</span><br><span class="line"><span class="comment">// 类似于 threadPool.submit(new Thread(new Runnable()&#123;run()&#123;doSomething();&#125;&#125;))的效果</span></span><br></pre></td></tr></table></figure>
<p>会提交一个协程到go语言自带的协程池子里。由于go语言每个函数可以作为一个协程，所以语法显得非常简练方便，而且无需操心线程池。<br>此外<code>go</code>中<code>main</code>函数也是一个协程，而且不是守护的。（java中main函数是守护的,会等待所有其他线程运行结束）<br>协程的同步依然需要自己管理，一般是用channel(管道)进行。<br>语法上,协程提供了一个写非阻塞操作的非常简洁的关键字(<code>go</code>)。<br>实现上,协程提供了非常方便的协程池,而且由于是用户态线程,因此每个协程的开销足够小,小到可以将每个函数这么小的粒度作为协程。 </p>
<p>缺陷:<br>由于实现上是使用用户态线程/进程,当某一个协程中有密集计算时,其他协程就不运行了. 每个线程上装配的协程的切换是需要在每次协程中发生中断时进行判断的。</p>
<p>解决方案:</p>
<ul>
<li><code>GoLang</code>: 用户在密集计算的代码中自己<code>yield</code>. </li>
<li><code>ErLang</code>: 无需关心. 由于底层有<code>ErLang</code>自己开发的VM,会自动检测并进行切换.(<code>rabbitmq</code>)</li>
</ul>
<h1 id="具体实现"><a href="#具体实现" class="headerlink" title="具体实现"></a>具体实现</h1><ul>
<li>问题的本质:<br>一个进程处理一个连接, 导致进程开销太大.<br>因此解决思路就是一个进程处理多个连接.也就是:<br><code>IO多路复用</code>. </li>
</ul>
<p>实现1:</p>
<blockquote>
<p>每个进程循环处理多个连接.<br>缺点: 其中一个连接处理卡住会阻塞整个应用. </p>
</blockquote>
<h2 id="select模式"><a href="#select模式" class="headerlink" title="select模式"></a>select模式</h2><p>实现2: (<code>select</code>模式)</p>
<blockquote>
<p>维护一个fd_set状态结构体.<br>阻塞的原因是IO资源的争用,如某个文件句柄是否可读,可写.(锁)<br>告诉内核该进程关心的文件句柄, 让内核检查多个文件句柄.</p>
</blockquote>
<p>进程发送句柄列表=&gt;内核逐个检查状态是否可用. </p>
<p>缺陷:</p>
<blockquote>
<ol>
<li>每个进程有关注的文件句柄上限;</li>
<li>需要重复初始化关心的文件句柄结构体;</li>
<li>逐个排查连接效率低.</li>
</ol>
</blockquote>
<h2 id="poll模式"><a href="#poll模式" class="headerlink" title="poll模式"></a>poll模式</h2><p>实现3:(<code>poll模式</code>)</p>
<blockquote>
<p>设计新的数据结构.<br>通过pollfd数组向内核传递需要关注的事件: 消除文件句柄上限;<br>不同字段区分关注事件和发生事件: 避免重复初始化.</p>
</blockquote>
<p>缺陷:</p>
<blockquote>
<ol>
<li>逐个排查连接效率低.</li>
</ol>
</blockquote>
<h2 id="epoll模式"><a href="#epoll模式" class="headerlink" title="epoll模式"></a>epoll模式</h2><p>实现4: (<code>epoll</code>模式)<br>内核升级到能对每个FD注册回调,进程能够直接知道是哪个句柄状态变化,而不用轮询,监听回调就行了.<br>(linux 2.5.44新增<code>api</code>)<br>事件模型.</p>
<h2 id="epoll具体实现细节"><a href="#epoll具体实现细节" class="headerlink" title="epoll具体实现细节"></a>epoll具体实现细节</h2><p><strong>架构:</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; 一堆事情(IO访问),需要切换到内核态访问相应地址空间.例如把数据从内核地址空间拷贝到用户地址空间. 拷贝完以后触发一个读可用事件.</span><br><span class="line">用户进程-&gt;内核(</span><br><span class="line">    readyList</span><br><span class="line">   ,红黑树&lt;文件描述符(如Socket)&gt;</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p><strong>工作流程:</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">1. 用户进程调用epoll_create;</span><br><span class="line">2. 内核创建readyList,红黑树;</span><br><span class="line">3. 用户进程调用epoll_ctrl,传递监控的句柄(如Socket),以及在上面关注的事件;</span><br><span class="line">4. 内核将句柄插入红黑树;</span><br><span class="line">5. 内核的中断处理程序注册一个回调,如果红黑树中某个句柄的中断到了,</span><br><span class="line">把它对应的事件放到ReadyList. </span><br><span class="line"></span><br><span class="line">--- 另一个流程 --- </span><br><span class="line">1. 用户进程调用epoll_wait</span><br><span class="line">2. 内核从ReadyList返回可回调的事件.</span><br></pre></td></tr></table></figure>

<p><strong>LT模式与ET模式</strong><br>LT模式: 水平触发(JAVA NIO默认),一个句柄上的事件一次没处理完,会再下次调用epoll_wait的时候依然返回它;<br>ET模式: 边缘触发,仅在第一次返回.</p>
<p>LT模式:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1. 用户进程调用epoll_wait;</span><br><span class="line">2. 内核从ReadyList返回数据;&#x2F;&#x2F; 就绪的Socket拷贝到用户态内存</span><br><span class="line">3. 清空ReadyList;</span><br><span class="line">4. 检查Socket句柄,如果有未处理完的事件(数据没读完),将句柄加入ReadyList.</span><br></pre></td></tr></table></figure>
<p>ET模式没有上述的第四步.</p>
<p><strong>LT模式注意事项</strong></p>
<blockquote>
<p>不需要写的话,不要关注写事件.<br>长期关注写事件会导致CPU100%问题. </p>
</blockquote>
<p><strong>ET模式注意事项</strong></p>
<blockquote>
<p>每次都要读到返回EWOULDBLOCK为止. (要读干净)</p>
</blockquote>
<p><strong>epoll为什么使用红黑树</strong><br>因为epoll要求快速找到某个句柄,因此首先是一个Map接口,候选实现:</p>
<ol>
<li>哈希表 O(1)</li>
<li>红黑树 O(lgn)</li>
<li>跳表 近似O(lgn)<br>据说老版本的内核和FreeBSD的Kqueue使用的是哈希表. </li>
</ol>
<p>个人理解现在内核使用红黑树的原因:</p>
<ol>
<li>哈希表. 空间因素,可伸缩性.<br>(1)频繁增删. 哈希表需要预估空间大小, 这个场景下无法做到.<br>间接影响响应时间,假如要resize,原来的数据还得移动.即使用了一致性哈希算法,<br>也难以满足非阻塞的timeout时间限制.(时间不稳定)<br>(2) 百万级连接,哈希表有镂空的空间,太浪费内存.</li>
<li>跳表. 慢于红黑树. 空间也高. </li>
<li>红黑树. 经验判断,内核的其他地方如防火墙也使用红黑树,实践上看性能最优.</li>
</ol>
<p><strong>数据结构:</strong></p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="keyword">union</span> epoll_data &#123;</span><br><span class="line">     <span class="keyword">void</span> *ptr;</span><br><span class="line">     <span class="keyword">int</span> fd; </span><br><span class="line">     <span class="keyword">__uint32_t</span> u32;</span><br><span class="line">     <span class="keyword">__uint64_t</span> u64; </span><br><span class="line">&#125;<span class="keyword">epoll_data_t</span>;  <span class="comment">// &lt;=</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">epoll_event</span> &#123;</span> </span><br><span class="line">    <span class="keyword">__uint32_t</span> events; <span class="comment">/* Epoll events */</span> </span><br><span class="line">    <span class="keyword">epoll_data_t</span> data;<span class="comment">/* User data variable */</span></span><br><span class="line"> &#125;;</span><br></pre></td></tr></table></figure>
<p>C库的API:</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">epoll_create</span><span class="params">(<span class="keyword">int</span> <span class="built_in">size</span>)</span></span>; <span class="comment">// size: 最大句柄数</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">epoll_ctl</span><span class="params">(<span class="keyword">int</span> epfd, <span class="keyword">int</span> op, <span class="keyword">int</span> fd, struct epoll_event *event)</span></span>;  </span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">epoll_wait</span><span class="params">(<span class="keyword">int</span> epfd, struct epoll_event *events,<span class="keyword">int</span> maxevents, <span class="keyword">int</span> timeout)</span></span>;</span><br></pre></td></tr></table></figure>
<p>具体语义:</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">epoll_create: 让内核创建一个epoll item;</span><br><span class="line">epoll_ctl: 修改epoll item: 增加socket句柄,或删除socket句柄,注册回调事件;</span><br><span class="line">epoll_wait: 等待注册的事件发生. </span><br><span class="line">传入的参数epoll_event会从内核那捞回结果.(被回调的事件)</span><br></pre></td></tr></table></figure>


<h2 id="实现5-libevent库"><a href="#实现5-libevent库" class="headerlink" title="实现5: libevent库"></a>实现5: libevent库</h2><p>封装<code>epoll</code>. 统一不同平台api.<br>使用方式:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1. 初始化事件event,定义回调函数f;</span><br><span class="line">2. 将事件加入系统监控事件列表;</span><br><span class="line">3. 监听事件及分发.</span><br></pre></td></tr></table></figure>

<p><strong>NIO的epoll bug</strong><br>部分Linux的2.6的kernel中，poll和epoll对于突然中断的连接socket会对返回的eventSet事件集合置为POLLHUP，也可能是POLLERR，eventSet事件集合发生了变化，这就可能导致Selector会被唤醒。<br>进一步导致jdk中NIO实现中某段代码的死循环.</p>
<p>Netty的解决方案:</p>
<ol>
<li>将select返回值为0进行计数,直到大于阈值<code>EPOLL_BUG_WORKAROUND</code>;</li>
<li>重建Selector. </li>
</ol>
<h1 id="C10M问题"><a href="#C10M问题" class="headerlink" title="C10M问题"></a>C10M问题</h1><ol>
<li><p>数据包经过linux内核协议栈导致性能巨大下降.<br>解决方案:<br>(1)intel的DPDK框架. 直接接管网卡收到的数据包传递到业务代码中进行处理.</p>
</li>
<li><p>存储访问时间消耗. 切换消耗:<br>解决方案:<br>(1) 重新设计操作系统, 包括内存池,cache,内存分页,cpu管理等等.</p>
</li>
</ol>
<h1 id="术语-概念"><a href="#术语-概念" class="headerlink" title="术语/概念"></a>术语/概念</h1><h2 id="缓存IO"><a href="#缓存IO" class="headerlink" title="缓存IO"></a>缓存IO</h2><p>标准IO. 操作系统先将IO数据缓存到文件系统的页缓存(page cache)中,然后再从操作系统内核的缓冲区拷贝到应用程序的地址空间.<br>缺点:<br>重复拷贝带来很大的CPU/内存开销. </p>
<ul>
<li><p>阻塞/非阻塞: </p>
<blockquote>
<p>内核会不会立即回答;</p>
</blockquote>
</li>
<li><p>同步/异步: </p>
<blockquote>
<p>进程会不会等内核回答. </p>
</blockquote>
</li>
</ul>
<h2 id="IO模式"><a href="#IO模式" class="headerlink" title="IO模式"></a>IO模式</h2><ol>
<li>阻塞IO</li>
<li>非阻塞IO</li>
<li>IO多路复用</li>
<li>信号驱动IO</li>
<li>异步IO</li>
</ol>
<h2 id="阻塞IO"><a href="#阻塞IO" class="headerlink" title="阻塞IO"></a>阻塞IO</h2><ol>
<li>进程请求IO数据;</li>
<li>进程阻塞;</li>
<li>内核准备数据,拷贝到内核空间;</li>
<li>拷贝到进程地址;</li>
<li>解除阻塞.</li>
</ol>
<h2 id="非阻塞IO"><a href="#非阻塞IO" class="headerlink" title="非阻塞IO"></a>非阻塞IO</h2><ul>
<li>轮询</li>
</ul>
<ol>
<li>进程请求IO数据;</li>
<li>内核回答不OK;</li>
<li>进程不断轮询;</li>
<li>内核终于准备好了数据,回答OK. </li>
</ol>
<h2 id="IO多路复用"><a href="#IO多路复用" class="headerlink" title="IO多路复用"></a>IO多路复用</h2><p>包括: select,poll,epoll</p>
<blockquote>
<p>一次轮询多个socket,任何一个socket数据搞定的话,内核都会回复一次. </p>
</blockquote>
<h2 id="异步非阻塞IO"><a href="#异步非阻塞IO" class="headerlink" title="异步非阻塞IO"></a>异步非阻塞IO</h2><p>类似于非阻塞, 取消了轮询.<br>进程不等待内核的回复.<br>内核完成准备数据后会通知进程.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://xiaoyue26.github.io/2017/11/06/2017-11/epoll%E7%9B%B8%E5%85%B3%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/" data-id="ck96cxpnf008kmaam77ut6s95" class="article-share-link">分享</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%B9%B6%E5%8F%91/" rel="tag">并发</a></li></ul>

    </footer>
  </div>
  
</article>
 


  


  <nav id="page-nav">
    <a class="extend prev" rel="prev" href="/page/15/">&amp;laquo; 上一页</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/14/">14</a><a class="page-number" href="/page/15/">15</a><span class="page-number current">16</span><a class="page-number" href="/page/17/">17</a><a class="page-number" href="/page/18/">18</a><span class="space">&hellip;</span><a class="page-number" href="/page/23/">23</a><a class="extend next" rel="next" href="/page/17/">下一页&amp;raquo;</a>
  </nav>
</section>
           
    <aside id="sidebar">
  
    

  
    
  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title recent-posts">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2022/09/25/2022-09/nc%E5%91%BD%E4%BB%A4%E7%AC%94%E8%AE%B0/">nc命令笔记</a>
          </li>
        
          <li>
            <a href="/2022/09/25/2022-09/%E8%B0%83%E4%BC%98-%E8%A7%A3%E5%86%B3%E7%BA%BF%E7%A8%8B%E6%B1%A0%E9%80%A0%E6%88%90%E7%9A%84%E8%BF%9B%E7%A8%8B%E5%8D%A1%E9%A1%BF%E3%80%81cpu%E6%AF%9B%E5%88%BA%E9%97%AE%E9%A2%98/">调优-解决线程池造成的进程卡顿、cpu毛刺问题</a>
          </li>
        
          <li>
            <a href="/2022/08/30/2022-08/%E8%B0%83%E4%BC%98-cpu%E6%AF%9B%E5%88%BA%E9%97%AE%E9%A2%98/">调优-cpu毛刺问题</a>
          </li>
        
          <li>
            <a href="/2022/05/31/2022-05/w-tinylfu%E7%BC%93%E5%AD%98%E7%AE%97%E6%B3%95/">w-tinylfu缓存算法</a>
          </li>
        
          <li>
            <a href="/2022/03/25/2022-03/G1%E8%B0%83%E4%BC%98-%E5%A4%8D%E6%9D%82%E4%B8%9A%E5%8A%A1%E6%B2%BB%E7%90%86%E5%B0%8F%E8%AE%B0/">G1调优-复杂业务治理小记</a>
          </li>
        
      </ul>
    </div>
  </div>

  
    

  
</aside>

      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-left">
      &copy; 2014 - 2022 风梦七&nbsp;|&nbsp;
      主题 <a href="https://github.com/giscafer/hexo-theme-cafe/" target="_blank">Cafe</a>
    </div>
     <div id="footer-right">
      联系方式&nbsp;|&nbsp;296671657@qq.com
    </div>
  </div>
</footer>
 
<script src="/jquery/jquery.min.js"></script>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">首页</a>
  
    <a href="/archives" class="mobile-nav-link">归档</a>
  
    <a href="/about" class="mobile-nav-link">关于</a>
  
</nav>
    <img class="back-to-top-btn" src="/images/fly-to-top.png"/>
<script>
// Elevator script included on the page, already.
window.onload = function() {
  var elevator = new Elevator({
    selector:'.back-to-top-btn',
    element: document.querySelector('.back-to-top-btn'),
    duration: 1000 // milliseconds
  });
}
</script>
      

  
    <script>
      var cloudTieConfig = {
        url: document.location.href, 
        sourceId: "",
        productKey: "e2fb4051c49842688ce669e634bc983f",
        target: "cloud-tie-wrapper"
      };
    </script>
    <script src="https://img1.ws.126.net/f2e/tie/yun/sdk/loader.js"></script>
    

  







<!-- author:forvoid begin -->
<!-- author:forvoid begin -->

<!-- author:forvoid end -->

<!-- author:forvoid end -->


  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      })
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      })
    </script>
    <script type="text/javascript" src="https://cdn.rawgit.com/mathjax/MathJax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


 
<script src="/js/is.js"></script>



  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>


<script src="/js/elevator.js"></script>

  </div>
</body>
</html>